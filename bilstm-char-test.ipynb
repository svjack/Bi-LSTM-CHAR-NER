{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle as pkl\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_dict_path = \"args.json\"\n",
    "with open(params_dict_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    params_dict = json.load(f)\n",
    "from collections import namedtuple\n",
    "params_tuple = namedtuple(\"params_tuple\" ,params_dict.keys())\n",
    "for k, v in params_dict.items():\n",
    "    exec(\"params_tuple.{}={}\".format(k, \"'{}'\".format(v) if type(v) == type(\"\") else v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_file_first_rows(file_path, rows= 100):\n",
    "    line_list = []\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        cnt = 0\n",
    "        while True:\n",
    "            line = f.readline()\n",
    "            if not line or cnt >= rows:\n",
    "                break\n",
    "            line_list.append(\"{}\\n\".format(line.strip()))\n",
    "            cnt += 1\n",
    "    return \"\".join(line_list)\n",
    "\n",
    "def identify_sep(file_path):\n",
    "    first_lines_str = show_file_first_rows(file_path)\n",
    "    lines = first_lines_str.split(\"\\n\")\n",
    "    spliters = [\"\\t\", \" \"]\n",
    "    sep_cnt_dict = dict(map(lambda sep: (sep ,sum(map(lambda l: len(l.split(sep)), lines))), spliters))\n",
    "    return list(map(lambda t2: t2[0],sorted(sep_cnt_dict.items(), key = lambda t2: -1 * t2[-1])))[0]\n",
    "\n",
    "import sys, pickle, os, random\n",
    "def produce_tag2label(input_series):\n",
    "    input_series = pd.Series(input_series).dropna()\n",
    "    return dict(map(lambda t2: (t2[1], t2[0]) ,enumerate(input_series.unique().tolist())))\n",
    "\n",
    "def read_corpus_by_pd(corpus_path):\n",
    "    sep = identify_sep(corpus_path)\n",
    "    return pd.read_csv(corpus_path, header = None, delimiter=sep, skip_blank_lines=False)\n",
    "\n",
    "def retrieve_sep_nest_list(corpus_df):\n",
    "    #na_line_where = np.where(pd.isna(corpus_df.iloc[:, -1]))[0]\n",
    "    #na_line_where = np.where(pd.isna(corpus_df.iloc[:, 0]))[0]\n",
    "    na_line_where = np.where(corpus_df.apply(lambda x: np.any(pd.isna(x)), axis = 1))\n",
    "    assert type(na_line_where) == type((0,))\n",
    "    na_line_where = na_line_where[0]\n",
    "    #assert 0 not in na_line_where and (corpus_df.shape[0] - 1) not in na_line_where\n",
    "    assert 0 not in na_line_where\n",
    "    nest_sep_indice_list = []\n",
    "    for idx in range(corpus_df.shape[0]):\n",
    "        if not nest_sep_indice_list:\n",
    "            nest_sep_indice_list.append([idx])\n",
    "        else:\n",
    "            if idx not in na_line_where:\n",
    "                nest_sep_indice_list[-1].append(idx)\n",
    "            else:\n",
    "                nest_sep_indice_list.append([])\n",
    "    nest_sep_indice_list = list(filter(len, nest_sep_indice_list))\n",
    "    return nest_sep_indice_list\n",
    "\n",
    "def read_corpus_by_pd_nest_list(corpus_path):\n",
    "    #### output format [([...], [...]), ] or [([...], [...], [...], [...]), ]\n",
    "    corpus_df = read_corpus_by_pd(corpus_path)\n",
    "    assert corpus_df.shape[1] in (4, 2)\n",
    "    nest_sep_list = retrieve_sep_nest_list(corpus_df)\n",
    "    for sliced_df in map(lambda inner_list: corpus_df.iloc[inner_list, :], nest_sep_list):\n",
    "        ele = list(zip(*sliced_df.values.tolist()))\n",
    "        yield ele\n",
    "        \n",
    "def vocab_build(vocab_path, corpus_path, min_count):\n",
    "    \"\"\"\n",
    "\n",
    "    :param vocab_path:\n",
    "    :param corpus_path:\n",
    "    :param min_count:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    #data = read_corpus(corpus_path)\n",
    "    data = list(read_corpus_by_pd_nest_list(corpus_path))\n",
    "    word2id = {}\n",
    "    #for sent_, tag_ in data:\n",
    "    for t in data:\n",
    "        if len(data[0]) == 2:\n",
    "            sent_, tag_ = t\n",
    "        elif len(data[0]) == 4:\n",
    "            sent_, _, _, tag_ = t\n",
    "        else:\n",
    "            1 / 0\n",
    "        for word in sent_:\n",
    "            if word.isdigit():\n",
    "                word = '<NUM>'\n",
    "            elif ('\\u0041' <= word <='\\u005a') or ('\\u0061' <= word <='\\u007a'):\n",
    "                #word = '<ENG>'\n",
    "                pass\n",
    "            if word not in word2id:\n",
    "                word2id[word] = [len(word2id)+1, 1]\n",
    "            else:\n",
    "                word2id[word][1] += 1\n",
    "    low_freq_words = []\n",
    "    for word, [word_id, word_freq] in word2id.items():\n",
    "        if word_freq < min_count and word != '<NUM>' and word != '<ENG>':\n",
    "            low_freq_words.append(word)\n",
    "    for word in low_freq_words:\n",
    "        del word2id[word]\n",
    "\n",
    "    new_id = 1\n",
    "    for word in word2id.keys():\n",
    "        word2id[word] = new_id\n",
    "        new_id += 1\n",
    "    word2id['<UNK>'] = new_id\n",
    "    word2id['<PAD>'] = 0\n",
    "\n",
    "    print(len(word2id))\n",
    "    with open(vocab_path, 'wb') as fw:\n",
    "        pickle.dump(word2id, fw)\n",
    "\n",
    "def sentence2id(sent, word2id):\n",
    "    \"\"\"\n",
    "\n",
    "    :param sent:\n",
    "    :param word2id:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    sentence_id = []\n",
    "    for word in sent:\n",
    "        if word.isdigit():\n",
    "            word = '<NUM>'\n",
    "        elif ('\\u0041' <= word <= '\\u005a') or ('\\u0061' <= word <= '\\u007a'):\n",
    "            #word = '<ENG>'\n",
    "            pass\n",
    "        if word not in word2id:\n",
    "            word = '<UNK>'\n",
    "        sentence_id.append(word2id[word])\n",
    "    return sentence_id\n",
    "\n",
    "def words_as_char2id(word, char2id):\n",
    "    word_id = []\n",
    "    for char in word:\n",
    "        if char not in char2id:\n",
    "            char = '<UNK>'\n",
    "        word_id.append(char2id[char])\n",
    "    return word_id\n",
    "\n",
    "def read_dictionary(vocab_path):\n",
    "    \"\"\"\n",
    "\n",
    "    :param vocab_path:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    vocab_path = os.path.join(vocab_path)\n",
    "    with open(vocab_path, 'rb') as fr:\n",
    "        word2id = pickle.load(fr)\n",
    "    print('vocab_size:', len(word2id))\n",
    "    return word2id\n",
    "\n",
    "\n",
    "def random_embedding(vocab, embedding_dim):\n",
    "    \"\"\"\n",
    "\n",
    "    :param vocab:\n",
    "    :param embedding_dim:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    embedding_mat = np.random.uniform(-0.25, 0.25, (len(vocab), embedding_dim))\n",
    "    embedding_mat = np.float32(embedding_mat)\n",
    "    return embedding_mat\n",
    "\n",
    "def pad_sequences(sequences, pad_mark=0):\n",
    "    \"\"\"\n",
    "\n",
    "    :param sequences:\n",
    "    :param pad_mark:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    max_len = max(map(lambda x : len(x), sequences))\n",
    "    seq_list, seq_len_list = [], []\n",
    "    for seq in sequences:\n",
    "        seq = list(seq)\n",
    "        seq_ = seq[:max_len] + [pad_mark] * max(max_len - len(seq), 0)\n",
    "        seq_list.append(seq_)\n",
    "        seq_len_list.append(min(len(seq), max_len))\n",
    "    return seq_list, seq_len_list\n",
    "\n",
    "def pad_char_sequences(sequences, char2id):\n",
    "    \"\"\"\n",
    "\n",
    "    :param sequences:\n",
    "    :param pad_mark:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    #### sequences [batch, seq_len, word_len,]\n",
    "    assert \"<PAD>\" in char2id\n",
    "    pad_mark = char2id[\"<PAD>\"]\n",
    "    \n",
    "    #max_len = max(map(lambda x : len(x), sequences))\n",
    "    max_seq_len = max(map(lambda x : len(x), sequences))\n",
    "    max_word_len = max(map(lambda char_nest_list: max(map(lambda char_list: len(char_list), char_nest_list)), sequences))\n",
    "    #print(max_seq_len, max_word_len)\n",
    "    \n",
    "    #seq_list, seq_len_list = [], []\n",
    "    #### [B, S, W], [B,], [B, S]\n",
    "    char_list, seq_len_list, word_len_nest_list = [], [], []\n",
    "    for seq in sequences:\n",
    "        #### [...]\n",
    "        seq = list(seq)\n",
    "        \n",
    "        char_list.append([])\n",
    "        word_len_nest_list.append([])\n",
    "        for word in seq:\n",
    "            word_len_nest_list[-1].append(min(len(word), max_word_len))\n",
    "            word_ = word[:max_word_len] + [pad_mark] * max(max_word_len - len(word), 0)\n",
    "            char_list[-1].append(word_)\n",
    "        \n",
    "        seq_len_list.append(len(char_list[-1]))\n",
    "        for _ in range(max(max_seq_len - len(seq), 0)):\n",
    "            char_list[-1].append([pad_mark] * max_word_len)\n",
    "            word_len_nest_list[-1].append(0)\n",
    "        #seq_ = seq[:max_len] + [pad_mark] * max(max_len - len(seq), 0)\n",
    "        #seq_list.append(seq_)\n",
    "        #seq_len_list.append(min(len(seq), max_len))\n",
    "    #return seq_list, seq_len_list\n",
    "    return char_list, seq_len_list, word_len_nest_list\n",
    "\n",
    "def char2id_build(word2id_pkl_path):\n",
    "    from functools import reduce\n",
    "    with open(word2id_pkl_path, \"rb\") as f:\n",
    "        word2id_dict = pkl.load(f)\n",
    "    char2id_dict = dict(map(lambda t2: (t2[1], t2[0]), enumerate(list(reduce(lambda a, b: a.union(b) ,map(lambda word: set(list(word)),word2id_dict.keys()))))))\n",
    "    padding_idx = len(char2id_dict)\n",
    "    empty_idx = len(char2id_dict) + 1\n",
    "    char2id_dict[\"<PAD>\"] = padding_idx\n",
    "    char2id_dict[\"<UNK>\"] = empty_idx\n",
    "    assert len(char2id_dict) == max(char2id_dict.values()) + 1\n",
    "    assert min(char2id_dict.values()) == 0\n",
    "    print(\"char size {}\".format(len(char2id_dict)))\n",
    "    return char2id_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_yield_multi(data, batch_size, vocab, feature_0_to_label, feature_1_to_label, tag2label, shuffle=False):\n",
    "    \"\"\"\n",
    "\n",
    "    :param data:\n",
    "    :param batch_size:\n",
    "    :param vocab:\n",
    "    :param tag2label:\n",
    "    :param shuffle:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    if shuffle:\n",
    "        random.shuffle(data)\n",
    "\n",
    "    #seqs, labels = [], []\n",
    "    seqs, feature_0, feature_1, labels = [], [], [], []\n",
    "\n",
    "    for (sent_, feat0_, feat1_, tag_) in data:\n",
    "        sent_ = sentence2id(sent_, vocab)\n",
    "        label0_ = [feature_0_to_label[tag] for tag in feat0_]\n",
    "        label1_ = [feature_1_to_label[tag] for tag in feat1_]\n",
    "        label_ = [tag2label[tag] for tag in tag_]\n",
    "\n",
    "        if len(seqs) == batch_size:\n",
    "            #yield seqs, labels\n",
    "            yield seqs, feature_0, feature_1, labels\n",
    "            #seqs, labels = [], []\n",
    "            seqs, feature_0, feature_1, labels = [], [], [], []\n",
    "    \n",
    "        seqs.append(sent_)\n",
    "        feature_0.append(label0_)\n",
    "        feature_1.append(label1_)\n",
    "        labels.append(label_)\n",
    "        \n",
    "    if len(seqs) != 0:\n",
    "        yield seqs, feature_0, feature_1, labels\n",
    "        \n",
    "def batch_yield_multi_with_chars(data, batch_size, vocab, char2id, feature_0_to_label, feature_1_to_label, tag2label, shuffle=False):\n",
    "    \"\"\"\n",
    "\n",
    "    :param data:\n",
    "    :param batch_size:\n",
    "    :param vocab:\n",
    "    :param tag2label:\n",
    "    :param shuffle:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    if shuffle:\n",
    "        random.shuffle(data)\n",
    "\n",
    "    #seqs, labels = [], []\n",
    "    #seqs, feature_0, feature_1, labels = [], [], [], []\n",
    "    chars ,seqs, feature_0, feature_1, labels = [], [], [], [], []\n",
    "\n",
    "    for (sent_, feat0_, feat1_, tag_) in data:\n",
    "        char_ = list(map(lambda word: words_as_char2id(word, char2id), sent_))\n",
    "        \n",
    "        sent_ = sentence2id(sent_, vocab)\n",
    "        label0_ = [feature_0_to_label[tag] for tag in feat0_]\n",
    "        label1_ = [feature_1_to_label[tag] for tag in feat1_]\n",
    "        label_ = [tag2label[tag] for tag in tag_]\n",
    "\n",
    "        if len(seqs) == batch_size:\n",
    "            #yield seqs, labels\n",
    "            #yield seqs, feature_0, feature_1, labels\n",
    "            yield  chars, seqs, feature_0, feature_1, labels\n",
    "            #seqs, labels = [], []\n",
    "            #seqs, feature_0, feature_1, labels = [], [], [], []\n",
    "            chars ,seqs, feature_0, feature_1, labels = [], [], [], [], []\n",
    "        \n",
    "        chars.append(char_)\n",
    "        \n",
    "        seqs.append(sent_)\n",
    "        feature_0.append(label0_)\n",
    "        feature_1.append(label1_)\n",
    "        labels.append(label_)\n",
    "        \n",
    "    if len(seqs) != 0:\n",
    "        #yield seqs, feature_0, feature_1, labels\n",
    "        yield  chars, seqs, feature_0, feature_1, labels\n",
    "        \n",
    "import logging, sys, argparse\n",
    "\n",
    "\n",
    "def str2bool(v):\n",
    "    # copy from StackOverflow\n",
    "    if v.lower() in ('yes', 'true', 't', 'y', '1'):\n",
    "        return True\n",
    "    elif v.lower() in ('no', 'false', 'f', 'n', '0'):\n",
    "        return False\n",
    "    else:\n",
    "        raise argparse.ArgumentTypeError('Boolean value expected.')\n",
    "\n",
    "\n",
    "def get_entity(tag_seq, char_seq):\n",
    "    PER = get_PER_entity(tag_seq, char_seq)\n",
    "    LOC = get_LOC_entity(tag_seq, char_seq)\n",
    "    ORG = get_ORG_entity(tag_seq, char_seq)\n",
    "    return PER, LOC, ORG\n",
    "\n",
    "\n",
    "def get_PER_entity(tag_seq, char_seq):\n",
    "    length = len(char_seq)\n",
    "    PER = []\n",
    "    for i, (char, tag) in enumerate(zip(char_seq, tag_seq)):\n",
    "        if tag == 'B-PER':\n",
    "            if 'per' in locals().keys():\n",
    "                PER.append(per)\n",
    "                del per\n",
    "            per = char\n",
    "            if i+1 == length:\n",
    "                PER.append(per)\n",
    "        if tag == 'I-PER':\n",
    "            per += char\n",
    "            if i+1 == length:\n",
    "                PER.append(per)\n",
    "        if tag not in ['I-PER', 'B-PER']:\n",
    "            if 'per' in locals().keys():\n",
    "                PER.append(per)\n",
    "                del per\n",
    "            continue\n",
    "    return PER\n",
    "\n",
    "\n",
    "def get_LOC_entity(tag_seq, char_seq):\n",
    "    length = len(char_seq)\n",
    "    LOC = []\n",
    "    for i, (char, tag) in enumerate(zip(char_seq, tag_seq)):\n",
    "        if tag == 'B-LOC':\n",
    "            if 'loc' in locals().keys():\n",
    "                LOC.append(loc)\n",
    "                del loc\n",
    "            loc = char\n",
    "            if i+1 == length:\n",
    "                LOC.append(loc)\n",
    "        if tag == 'I-LOC':\n",
    "            loc += char\n",
    "            if i+1 == length:\n",
    "                LOC.append(loc)\n",
    "        if tag not in ['I-LOC', 'B-LOC']:\n",
    "            if 'loc' in locals().keys():\n",
    "                LOC.append(loc)\n",
    "                del loc\n",
    "            continue\n",
    "    return LOC\n",
    "\n",
    "\n",
    "def get_ORG_entity(tag_seq, char_seq):\n",
    "    length = len(char_seq)\n",
    "    ORG = []\n",
    "    for i, (char, tag) in enumerate(zip(char_seq, tag_seq)):\n",
    "        if tag == 'B-ORG':\n",
    "            if 'org' in locals().keys():\n",
    "                ORG.append(org)\n",
    "                del org\n",
    "            org = char\n",
    "            if i+1 == length:\n",
    "                ORG.append(org)\n",
    "        if tag == 'I-ORG':\n",
    "            org += char\n",
    "            if i+1 == length:\n",
    "                ORG.append(org)\n",
    "        if tag not in ['I-ORG', 'B-ORG']:\n",
    "            if 'org' in locals().keys():\n",
    "                ORG.append(org)\n",
    "                del org\n",
    "            continue\n",
    "    return ORG\n",
    "\n",
    "\n",
    "def get_logger(filename):\n",
    "    logger = logging.getLogger('logger')\n",
    "    logger.setLevel(logging.DEBUG)\n",
    "    logging.basicConfig(format='%(message)s', level=logging.DEBUG)\n",
    "    handler = logging.FileHandler(filename)\n",
    "    handler.setLevel(logging.DEBUG)\n",
    "    handler.setFormatter(logging.Formatter('%(asctime)s:%(levelname)s: %(message)s'))\n",
    "    logging.getLogger().addHandler(handler)\n",
    "    return logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict_path = \"model_dict\"\n",
    "with open(model_dict_path, \"rb\") as f:\n",
    "    model_dict = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab_size: 22927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<class '__main__.params_tuple'>\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os, argparse, time, random\n",
    "#from model import BiLSTM_CRF\n",
    "#from utils import str2bool, get_logger, get_entity\n",
    "#from data import read_corpus, read_dictionary, tag2label, random_embedding\n",
    "\n",
    "\n",
    "## Session configuration\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # default: 0\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.2  # need ~700MB GPU memory\n",
    "\n",
    "args = params_tuple\n",
    "args.mode = \"test\"\n",
    "args.mode\n",
    "\n",
    "vocab_path = \"multi_data_path/word2id.pkl\"\n",
    "train_path = \"/home/svjack/temp_dir/BERT-NER/data/train.txt\"\n",
    "test_path = \"/home/svjack/temp_dir/BERT-NER/data/test.txt\"\n",
    "\n",
    "'''\n",
    "import shutil\n",
    "if os.path.exists(vocab_path):\n",
    "    os.remove(vocab_path)\n",
    "    #shutil.rmtree(vocab_path)\n",
    "if not os.path.exists(vocab_path.split(\"/\")[0]):\n",
    "    os.mkdir(vocab_path.split(\"/\")[0])\n",
    "'''\n",
    "\n",
    "#corpus_path = \"/home/svjack/temp_dir/BERT-NER/data/train.txt\"\n",
    "#corpus_path = \"BERT-NER/data/train.txt\"\n",
    "#min_count = 0\n",
    "#vocab_build(vocab_path=vocab_path, corpus_path=corpus_path, min_count=min_count)\n",
    "\n",
    "#train_path = corpus_path\n",
    "#test_path = \"/home/svjack/temp_dir/BERT-NER/data/test.txt\"\n",
    "#test_path = \"BERT-NER/data/test.txt\"\n",
    "#word2id_pkl_path = \"multi_data_path/word2id.pkl\"\n",
    "word2id = read_dictionary(vocab_path)\n",
    "\n",
    "#char2id = char2id_build(word2id_pkl_path)\n",
    "#args.train_data = \"multi_data_path\"\n",
    "\n",
    "args.char_embedding_dim = 100\n",
    "if args.pretrain_embedding == 'random':\n",
    "    embeddings = random_embedding(word2id, args.embedding_dim)\n",
    "else:\n",
    "    embedding_path = 'pretrain_embedding.npy'\n",
    "    embeddings = np.array(np.load(embedding_path), dtype='float32')\n",
    "char_embeddings = random_embedding(model_dict[\"char2id\"], args.char_embedding_dim)\n",
    "\n",
    "## read corpus and get training data\n",
    "if args.mode != 'demo':\n",
    "    #train_path = os.path.join('.', args.train_data, 'train_data')\n",
    "    #test_path = os.path.join('.', args.test_data, 'test_data')\n",
    "    #train_data = read_corpus(train_path)\n",
    "    #test_data = read_corpus(test_path); test_size = len(test_data)\n",
    "    #train_data = read_corpus(train_path)\n",
    "    train_data = list(read_corpus_by_pd_nest_list(train_path))\n",
    "    #test_data = read_corpus(test_path); test_size = len(test_data)\n",
    "    test_data = list(read_corpus_by_pd_nest_list(test_path)); test_size = len(test_data)\n",
    "\n",
    "## paths setting\n",
    "paths = {}\n",
    "timestamp = str(int(time.time())) if args.mode == 'train' else args.demo_model\n",
    "output_path = os.path.join('.', args.train_data+\"_save\", timestamp)\n",
    "if not os.path.exists(output_path): os.makedirs(output_path)\n",
    "summary_path = os.path.join(output_path, \"summaries\")\n",
    "paths['summary_path'] = summary_path\n",
    "if not os.path.exists(summary_path): os.makedirs(summary_path)\n",
    "model_path = os.path.join(output_path, \"checkpoints/\")\n",
    "if not os.path.exists(model_path): os.makedirs(model_path)\n",
    "ckpt_prefix = os.path.join(model_path, \"model\")\n",
    "paths['model_path'] = ckpt_prefix\n",
    "result_path = os.path.join(output_path, \"results\")\n",
    "paths['result_path'] = result_path\n",
    "if not os.path.exists(result_path): os.makedirs(result_path)\n",
    "log_path = os.path.join(result_path, \"log.txt\")\n",
    "paths['log_path'] = log_path\n",
    "get_logger(log_path).info(str(args))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'summary_path': './data_path_save/1597127952/summaries',\n",
       " 'model_path': './data_path_save/1597127952/checkpoints/model',\n",
       " 'result_path': './data_path_save/1597127952/results',\n",
       " 'log_path': './data_path_save/1597127952/results/log.txt'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def conlleval(label_predict, label_path, metric_path):\n",
    "    \"\"\"\n",
    "\n",
    "    :param label_predict:\n",
    "    :param label_path:\n",
    "    :param metric_path:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    eval_perl = \"./conlleval_rev.pl\"\n",
    "    with open(label_path, \"w\") as fw:\n",
    "        line = []\n",
    "        for sent_result in label_predict:\n",
    "            for char, tag, tag_ in sent_result:\n",
    "                tag = '0' if tag == 'O' else tag\n",
    "                char = char.encode(\"utf-8\")\n",
    "                line.append(\"{} {} {}\\n\".format(char, tag, tag_))\n",
    "            line.append(\"\\n\")\n",
    "        fw.writelines(line)\n",
    "    os.system(\"perl {} < {} > {}\".format(eval_perl, label_path, metric_path))\n",
    "    with open(metric_path) as fr:\n",
    "        metrics = [line.strip() for line in fr]\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os, time, sys\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.rnn import LSTMCell\n",
    "from tensorflow.contrib.crf import crf_log_likelihood\n",
    "from tensorflow.contrib.crf import viterbi_decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiLSTM_CRF_MULTI_CHAR(object):\n",
    "    def __init__(self, args, embeddings, char_embeddings, feature_0_to_label, feature_1_to_label, tag2label, vocab, char2id, paths, config):\n",
    "        #self.max_char_capacity = 20\n",
    "        self.char2id = char2id\n",
    "        \n",
    "        self.batch_size = args.batch_size\n",
    "        self.epoch_num = args.epoch\n",
    "        self.hidden_dim = args.hidden_dim\n",
    "        self.embeddings = embeddings\n",
    "        \n",
    "        self.char_embeddings = char_embeddings\n",
    "        \n",
    "        self.filters_list = args.filters_list\n",
    "        self.kernel_list = args.kernel_list\n",
    "        assert len(self.filters_list) == len(self.kernel_list)\n",
    "        \n",
    "        self.CRF = args.CRF\n",
    "        self.update_embedding = args.update_embedding\n",
    "        self.dropout_keep_prob = args.dropout\n",
    "        self.optimizer = args.optimizer\n",
    "        self.lr = args.lr\n",
    "        self.clip_grad = args.clip\n",
    "        self.tag2label = tag2label\n",
    "        self.num_tags = len(tag2label)\n",
    "        self.vocab = vocab\n",
    "        self.shuffle = args.shuffle\n",
    "        self.model_path = paths['model_path']\n",
    "        self.summary_path = paths['summary_path']\n",
    "        self.logger = get_logger(paths['log_path'])\n",
    "        self.result_path = paths['result_path']\n",
    "        self.config = config\n",
    "        \n",
    "        self.feature_0_to_label = feature_0_to_label\n",
    "        self.feature_1_to_label = feature_1_to_label\n",
    "        \n",
    "    def build_graph(self):\n",
    "        self.add_placeholders()\n",
    "        self.lookup_layer_op()\n",
    "        self.biLSTM_layer_op()\n",
    "        self.softmax_pred_op()\n",
    "        self.loss_op()\n",
    "        self.trainstep_op()\n",
    "        self.init_op()\n",
    "    \n",
    "    def add_placeholders(self):\n",
    "        self.char_ids = tf.placeholder(tf.int32, shape = [None, None, None], name = \"char_ids\")\n",
    "        \n",
    "        self.word_ids = tf.placeholder(tf.int32, shape=[None, None], name=\"word_ids\")\n",
    "        self.labels = tf.placeholder(tf.int32, shape=[None, None], name=\"labels\")\n",
    "        self.sequence_lengths = tf.placeholder(tf.int32, shape=[None], name=\"sequence_lengths\")\n",
    "\n",
    "        self.dropout_pl = tf.placeholder(dtype=tf.float32, shape=[], name=\"dropout\")\n",
    "        self.lr_pl = tf.placeholder(dtype=tf.float32, shape=[], name=\"lr\")\n",
    "        \n",
    "        self.feature0 = tf.placeholder(tf.int32, shape=[None, None], name=\"feature0\")\n",
    "        self.feature1 = tf.placeholder(tf.int32, shape=[None, None], name=\"feature1\")\n",
    "\n",
    "    def lookup_layer_op(self):\n",
    "        with tf.variable_scope(\"words\"):\n",
    "            _word_embeddings = tf.Variable(self.embeddings,\n",
    "                                           dtype=tf.float32,\n",
    "                                           trainable=self.update_embedding,\n",
    "                                           name=\"_word_embeddings\")\n",
    "            word_embeddings = tf.nn.embedding_lookup(params=_word_embeddings,\n",
    "                                                     ids=self.word_ids,\n",
    "                                                     name=\"word_embeddings\")\n",
    "            self.word_embeddings =  tf.nn.dropout(word_embeddings, self.dropout_pl)\n",
    "        \n",
    "        with tf.variable_scope(\"chars\"):\n",
    "            '''\n",
    "            _char_embeddings = tf.Variable(self.embeddings,\n",
    "                                           dtype=tf.float32,\n",
    "                                           trainable=self.update_embedding,\n",
    "                                           name=\"_char_embeddings\")\n",
    "            '''\n",
    "            #char_embeddings\n",
    "            _char_embeddings = tf.Variable(self.char_embeddings,\n",
    "                                           dtype=tf.float32,\n",
    "                                           trainable=self.update_embedding,\n",
    "                                           name=\"_char_embeddings\")\n",
    "            char_embeddings = tf.nn.embedding_lookup(params=_char_embeddings,\n",
    "                                                     ids=self.char_ids,\n",
    "                                                     name=\"char_embeddings\")\n",
    "            #### [B, S, W, dim]\n",
    "            self.char_embeddings =  tf.nn.dropout(char_embeddings, self.dropout_pl)\n",
    "        \n",
    "    def produce_char_output(self, char_embeddings, filters, kernel_size, var_scope = None):\n",
    "        assert type(var_scope) == type(\"\")\n",
    "        with tf.variable_scope(var_scope):\n",
    "            conv2d_layer = tf.layers.conv2d(char_embeddings, kernel_size=kernel_size, filters=filters, padding=\"same\", name = \"char_conv\")      \n",
    "    \n",
    "            conv2d_layer_t = tf.transpose(conv2d_layer, [0, 2, 3, 1])\n",
    "            max2d_layer = tf.layers.MaxPooling2D(pool_size=3, strides=2, padding = \"same\", name = \"char_max\")(conv2d_layer_t)\n",
    "            max2d_layer_t = tf.transpose(max2d_layer, [0, 3, 1, 2])\n",
    "            char_output_max = tf.reduce_max(tf.reshape(max2d_layer_t, [tf.shape(max2d_layer_t)[0], tf.shape(max2d_layer_t)[1], -1]), axis = -1, name = \"char_reduce_max\")\n",
    "            char_expand_max = tf.expand_dims(char_output_max, -1)\n",
    "            \n",
    "            char_output_min = tf.reduce_min(tf.reshape(max2d_layer_t, [tf.shape(max2d_layer_t)[0], tf.shape(max2d_layer_t)[1], -1]), axis = -1, name = \"char_reduce_min\")\n",
    "            char_expand_min = tf.expand_dims(char_output_min, -1)\n",
    "            \n",
    "            char_output_mean = tf.reduce_max(tf.reshape(max2d_layer_t, [tf.shape(max2d_layer_t)[0], tf.shape(max2d_layer_t)[1], -1]), axis = -1, name = \"char_reduce_mean\")\n",
    "            char_expand_mean = tf.expand_dims(char_output_mean, -1)\n",
    "            \n",
    "            return tf.concat([char_expand_max, char_expand_min, char_expand_mean], axis = -1)\n",
    "        \n",
    "    def biLSTM_layer_op(self):\n",
    "        with tf.variable_scope(\"bi-lstm\"):\n",
    "            cell_fw = LSTMCell(self.hidden_dim)\n",
    "            cell_bw = LSTMCell(self.hidden_dim)\n",
    "            #### word-embed [B, L, N]\n",
    "            #### feat_0 feat_1 [B, L]\n",
    "            \n",
    "            '''\n",
    "            filters = 3\n",
    "            kernel_size = 3\n",
    "            #fake_char_embedding = tf.convert_to_tensor(np.random.random([B, S, W, dim]))\n",
    "            \n",
    "            conv2d_layer = tf.layers.conv2d(self.char_embeddings, kernel_size=kernel_size, filters=filters, padding=\"same\", name = \"char_conv\")      \n",
    "    \n",
    "            conv2d_layer_t = tf.transpose(conv2d_layer, [0, 2, 3, 1])\n",
    "            max2d_layer = tf.layers.MaxPooling2D(pool_size=3, strides=2, padding = \"same\", name = \"char_max\")(conv2d_layer_t)\n",
    "            max2d_layer_t = tf.transpose(max2d_layer, [0, 3, 1, 2])\n",
    "            char_output = tf.reduce_max(tf.reshape(max2d_layer_t, [tf.shape(max2d_layer_t)[0], tf.shape(max2d_layer_t)[1], -1]), axis = -1, name = \"char_reduce_max\")\n",
    "            char_expand = tf.expand_dims(char_output, -1)\n",
    "            '''\n",
    "            char_output_list = []\n",
    "            for iidx, var_scope_name in map(lambda idx: (idx ,\"char_output_{}\".format(idx)), range(len(args.filters_list))):\n",
    "                #### char_embeddings, filters, kernel_size, var_scope\n",
    "                filters, kernel_size = self.filters_list[iidx], self.kernel_list[iidx]\n",
    "                char_output_list.append(self.produce_char_output(self.char_embeddings ,filters, kernel_size, var_scope = var_scope_name))\n",
    "            char_expand = tf.concat(char_output_list, axis = -1)\n",
    "\n",
    "            feat0_expand = tf.expand_dims(self.feature0, -1)\n",
    "            feat0_expand = tf.cast(feat0_expand, tf.float32)\n",
    "            feat1_expand = tf.expand_dims(self.feature1, -1)\n",
    "            feat1_expand = tf.cast(feat1_expand, tf.float32)\n",
    "            #### [B, S, concat-d]\n",
    "            #inputs = tf.concat([self.word_embeddings, feat0_expand, feat1_expand], axis = -1, name = \"bind_inputs\")\n",
    "            inputs = tf.concat([char_expand ,self.word_embeddings, feat0_expand, feat1_expand], axis = -1, name = \"bind_inputs\")\n",
    "            \n",
    "            '''\n",
    "            (output_fw_seq, output_bw_seq), _ = tf.nn.bidirectional_dynamic_rnn(\n",
    "                cell_fw=cell_fw,\n",
    "                cell_bw=cell_bw,\n",
    "                inputs=self.word_embeddings,\n",
    "                sequence_length=self.sequence_lengths,\n",
    "                dtype=tf.float32)\n",
    "            '''\n",
    "            (output_fw_seq, output_bw_seq), _ = tf.nn.bidirectional_dynamic_rnn(\n",
    "                cell_fw=cell_fw,\n",
    "                cell_bw=cell_bw,\n",
    "                inputs=inputs,\n",
    "                sequence_length=self.sequence_lengths,\n",
    "                dtype=tf.float32)\n",
    "            \n",
    "            output = tf.concat([output_fw_seq, output_bw_seq], axis=-1)\n",
    "            output = tf.nn.dropout(output, self.dropout_pl)\n",
    "\n",
    "        with tf.variable_scope(\"proj\"):\n",
    "            W = tf.get_variable(name=\"W\",\n",
    "                                shape=[2 * self.hidden_dim, self.num_tags],\n",
    "                                initializer=tf.contrib.layers.xavier_initializer(),\n",
    "                                dtype=tf.float32)\n",
    "\n",
    "            b = tf.get_variable(name=\"b\",\n",
    "                                shape=[self.num_tags],\n",
    "                                initializer=tf.zeros_initializer(),\n",
    "                                dtype=tf.float32)\n",
    "\n",
    "            s = tf.shape(output)\n",
    "            output = tf.reshape(output, [-1, 2*self.hidden_dim])\n",
    "            pred = tf.matmul(output, W) + b\n",
    "\n",
    "            self.logits = tf.reshape(pred, [-1, s[1], self.num_tags])\n",
    "            \n",
    "    def loss_op(self):\n",
    "        if self.CRF:\n",
    "            log_likelihood, self.transition_params = crf_log_likelihood(inputs=self.logits,\n",
    "                                                                   tag_indices=self.labels,\n",
    "                                                                   sequence_lengths=self.sequence_lengths)\n",
    "            self.loss = -tf.reduce_mean(log_likelihood)\n",
    "\n",
    "        else:\n",
    "            losses = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=self.logits,\n",
    "                                                                    labels=self.labels)\n",
    "            mask = tf.sequence_mask(self.sequence_lengths)\n",
    "            losses = tf.boolean_mask(losses, mask)\n",
    "            self.loss = tf.reduce_mean(losses)\n",
    "\n",
    "        tf.summary.scalar(\"loss\", self.loss)\n",
    "\n",
    "    def softmax_pred_op(self):\n",
    "        if not self.CRF:\n",
    "            self.labels_softmax_ = tf.argmax(self.logits, axis=-1)\n",
    "            self.labels_softmax_ = tf.cast(self.labels_softmax_, tf.int32)\n",
    "    \n",
    "    def trainstep_op(self):\n",
    "        with tf.variable_scope(\"train_step\"):\n",
    "            self.global_step = tf.Variable(0, name=\"global_step\", trainable=False)\n",
    "            if self.optimizer == 'Adam':\n",
    "                optim = tf.train.AdamOptimizer(learning_rate=self.lr_pl)\n",
    "            elif self.optimizer == 'Adadelta':\n",
    "                optim = tf.train.AdadeltaOptimizer(learning_rate=self.lr_pl)\n",
    "            elif self.optimizer == 'Adagrad':\n",
    "                optim = tf.train.AdagradOptimizer(learning_rate=self.lr_pl)\n",
    "            elif self.optimizer == 'RMSProp':\n",
    "                optim = tf.train.RMSPropOptimizer(learning_rate=self.lr_pl)\n",
    "            elif self.optimizer == 'Momentum':\n",
    "                optim = tf.train.MomentumOptimizer(learning_rate=self.lr_pl, momentum=0.9)\n",
    "            elif self.optimizer == 'SGD':\n",
    "                optim = tf.train.GradientDescentOptimizer(learning_rate=self.lr_pl)\n",
    "            else:\n",
    "                optim = tf.train.GradientDescentOptimizer(learning_rate=self.lr_pl)\n",
    "\n",
    "            grads_and_vars = optim.compute_gradients(self.loss)\n",
    "            \n",
    "            grads_and_vars_clip = [[tf.clip_by_value(g, -self.clip_grad, self.clip_grad), v] for g, v in grads_and_vars]\n",
    "            self.train_op = optim.apply_gradients(grads_and_vars_clip, global_step=self.global_step)\n",
    "\n",
    "    def init_op(self):\n",
    "        self.init_op = tf.global_variables_initializer()\n",
    "\n",
    "    def add_summary(self, sess):\n",
    "        \"\"\"\n",
    "\n",
    "        :param sess:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        self.merged = tf.summary.merge_all()\n",
    "        self.file_writer = tf.summary.FileWriter(self.summary_path, sess.graph)\n",
    "            \n",
    "    def train(self, train, dev):\n",
    "        \"\"\"\n",
    "\n",
    "        :param train:\n",
    "        :param dev:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        saver = tf.train.Saver(tf.global_variables())\n",
    "\n",
    "        with tf.Session(config=self.config) as sess:\n",
    "            sess.run(self.init_op)\n",
    "            self.add_summary(sess)\n",
    "\n",
    "            for epoch in range(self.epoch_num):\n",
    "                self.run_one_epoch(sess, train, dev, self.tag2label, epoch, saver)\n",
    "\n",
    "    def test(self, test):\n",
    "        saver = tf.train.Saver()\n",
    "        with tf.Session(config=self.config) as sess:\n",
    "            self.logger.info('=========== testing ===========')\n",
    "            saver.restore(sess, self.model_path)\n",
    "            label_list, seq_len_list = self.dev_one_epoch(sess, test)\n",
    "            self.evaluate(label_list, seq_len_list, test)\n",
    "    \n",
    "    def get_feed_dict(self, chars ,seqs, feat0, feat1, labels=None, lr=None, dropout=None):\n",
    "        \"\"\"\n",
    "\n",
    "        :param seqs:\n",
    "        :param labels:\n",
    "        :param lr:\n",
    "        :param dropout:\n",
    "        :return: feed_dict\n",
    "        \"\"\"\n",
    "        char_ids, seq_len_list, word_len_nest_list = pad_char_sequences(chars, self.char2id)\n",
    "        \n",
    "        word_ids, seq_len_list = pad_sequences(seqs, pad_mark=0)\n",
    "        feat0_, _ = pad_sequences(feat0, pad_mark=-1)\n",
    "        feat1_, _ = pad_sequences(feat1, pad_mark=-1)\n",
    "        \n",
    "        #feed_dict = {self.word_ids: word_ids,\n",
    "        #             self.sequence_lengths: seq_len_list}\n",
    "        '''\n",
    "        feed_dict = {self.word_ids: word_ids,\n",
    "                     self.sequence_lengths: seq_len_list,\n",
    "                    self.feature0: feat0_,\n",
    "                     self.feature1: feat1_,\n",
    "                    }\n",
    "        '''\n",
    "        #print(np.asarray(char_ids).shape)\n",
    "        #print(\"-\"*100)\n",
    "        \n",
    "        feed_dict = {\n",
    "            self.char_ids: char_ids,\n",
    "            self.word_ids: word_ids,\n",
    "                     self.sequence_lengths: seq_len_list,\n",
    "                    self.feature0: feat0_,\n",
    "                     self.feature1: feat1_,\n",
    "                    }\n",
    "        \n",
    "        if labels is not None:\n",
    "            labels_, _ = pad_sequences(labels, pad_mark=0)\n",
    "            feed_dict[self.labels] = labels_\n",
    "        if lr is not None:\n",
    "            feed_dict[self.lr_pl] = lr\n",
    "        if dropout is not None:\n",
    "            feed_dict[self.dropout_pl] = dropout\n",
    "\n",
    "        return feed_dict, seq_len_list\n",
    "    \n",
    "    #def predict_one_batch(self, sess, seqs, feat0, feat1):\n",
    "    def predict_one_batch(self, sess, chars, seqs, feat0, feat1):\n",
    "        \"\"\"\n",
    "\n",
    "        :param sess:\n",
    "        :param seqs:\n",
    "        :return: label_list\n",
    "                 seq_len_list\n",
    "        \"\"\"\n",
    "        #feed_dict, seq_len_list = self.get_feed_dict(seqs, feat0, feat1, dropout=1.0)\n",
    "        feed_dict, seq_len_list = self.get_feed_dict(chars ,seqs, feat0, feat1, dropout=1.0)\n",
    "        \n",
    "        if self.CRF:\n",
    "            logits, transition_params = sess.run([self.logits, self.transition_params],\n",
    "                                                 feed_dict=feed_dict)\n",
    "            label_list = []\n",
    "            for logit, seq_len in zip(logits, seq_len_list):\n",
    "                viterbi_seq, _ = viterbi_decode(logit[:seq_len], transition_params)\n",
    "                label_list.append(viterbi_seq)\n",
    "            return label_list, seq_len_list\n",
    "\n",
    "        else:\n",
    "            label_list = sess.run(self.labels_softmax_, feed_dict=feed_dict)\n",
    "            return label_list, seq_len_list\n",
    "    \n",
    "    def demo_one(self, sess, sent):\n",
    "        \"\"\"\n",
    "\n",
    "        :param sess:\n",
    "        :param sent: \n",
    "        :return:\n",
    "        \"\"\"\n",
    "        label_list = []\n",
    "        '''\n",
    "        for seqs, labels in batch_yield(sent, self.batch_size, self.vocab, self.tag2label, shuffle=False):\n",
    "        '''\n",
    "        #for seqs, feat0, feat1, labels in batch_yield_multi(sent, self.batch_size, self.vocab, self.feature_0_to_label, self.feature_1_to_label, self.tag2label, shuffle=False):\n",
    "        for chars ,seqs, feat0, feat1, labels in batch_yield_multi_with_chars(sent, self.batch_size, self.vocab, self.char2id, self.feature_0_to_label, self.feature_1_to_label, self.tag2label, shuffle=False):\n",
    "                    \n",
    "            label_list_, _ = self.predict_one_batch(sess, chars, seqs, feat0, feat1)\n",
    "            label_list.extend(label_list_)\n",
    "        label2tag = {}\n",
    "        for tag, label in self.tag2label.items():\n",
    "            label2tag[label] = tag if label != 0 else label\n",
    "        tag = [label2tag[label] for label in label_list[0]]\n",
    "        return tag\n",
    "    \n",
    "    def run_one_epoch(self, sess, train, dev, tag2label, epoch, saver):\n",
    "        \"\"\"\n",
    "\n",
    "        :param sess:\n",
    "        :param train:\n",
    "        :param dev:\n",
    "        :param tag2label:\n",
    "        :param epoch:\n",
    "        :param saver:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        num_batches = (len(train) + self.batch_size - 1) // self.batch_size\n",
    "\n",
    "        start_time = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime())\n",
    "        #batches = batch_yield(train, self.batch_size, self.vocab, self.tag2label, shuffle=self.shuffle)\n",
    "        #batches = batch_yield_multi(train, self.batch_size, self.vocab, self.feature_0_to_label, self.feature_1_to_label, self.tag2label, shuffle=self.shuffle)\n",
    "        batches = batch_yield_multi_with_chars(train, self.batch_size, self.vocab, self.char2id, self.feature_0_to_label, self.feature_1_to_label, self.tag2label, shuffle=self.shuffle)\n",
    "        \n",
    "        #for step, (seqs, labels) in enumerate(batches):\n",
    "        #for step, (seqs, feat0, feat1, labels) in enumerate(batches):\n",
    "        for step, (chars ,seqs, feat0, feat1, labels) in enumerate(batches):\n",
    "            sys.stdout.write(' processing: {} batch / {} batches.'.format(step + 1, num_batches) + '\\r')\n",
    "            step_num = epoch * num_batches + step + 1\n",
    "            '''\n",
    "            feed_dict, _ = self.get_feed_dict(seqs, labels, self.lr, self.dropout_keep_prob)\n",
    "            '''\n",
    "            #feed_dict, _ = self.get_feed_dict(seqs, feat0, feat1, labels, self.lr, self.dropout_keep_prob)\n",
    "            feed_dict, _ = self.get_feed_dict(chars ,seqs, feat0, feat1, labels, self.lr, self.dropout_keep_prob)\n",
    "            _, loss_train, summary, step_num_ = sess.run([self.train_op, self.loss, self.merged, self.global_step],\n",
    "                                                         feed_dict=feed_dict)\n",
    "            #break\n",
    "            if step + 1 == 1 or (step + 1) % 300 == 0 or step + 1 == num_batches:\n",
    "                self.logger.info(\n",
    "                    '{} epoch {}, step {}, loss: {:.4}, global_step: {}'.format(start_time, epoch + 1, step + 1,\n",
    "                                                                                loss_train, step_num))\n",
    "\n",
    "            self.file_writer.add_summary(summary, step_num)\n",
    "            \n",
    "            #print((step + 1, num_batches))\n",
    "            if step + 1 == num_batches:\n",
    "                saver.save(sess, self.model_path, global_step=step_num)\n",
    "        \n",
    "        saver.save(sess, self.model_path, global_step=step_num)\n",
    "        self.logger.info('===========validation / test===========')\n",
    "        label_list_dev, seq_len_list_dev = self.dev_one_epoch(sess, dev)\n",
    "        self.evaluate(label_list_dev, seq_len_list_dev, dev, epoch)\n",
    "\n",
    "    def dev_one_epoch(self, sess, dev):\n",
    "        \"\"\"\n",
    "\n",
    "        :param sess:\n",
    "        :param dev:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        label_list, seq_len_list = [], []\n",
    "        #for seqs, labels in batch_yield(dev, self.batch_size, self.vocab, self.tag2label, shuffle=False):\n",
    "        #for seqs, feat0, feat1, labels in batch_yield_multi(dev, self.batch_size, self.vocab, self.feature_0_to_label, self.feature_1_to_label, self.tag2label, shuffle=False):\n",
    "        for chars ,seqs, feat0, feat1, labels in batch_yield_multi_with_chars(dev, self.batch_size, self.vocab, self.char2id, self.feature_0_to_label, self.feature_1_to_label, self.tag2label, shuffle=False):\n",
    "\n",
    "            #label_list_, seq_len_list_ = self.predict_one_batch(sess, seqs)\n",
    "            label_list_, seq_len_list_ = self.predict_one_batch(sess, chars, seqs, feat0, feat1)\n",
    "            label_list.extend(label_list_)\n",
    "            seq_len_list.extend(seq_len_list_)\n",
    "        return label_list, seq_len_list\n",
    "\n",
    "    def evaluate(self, label_list, seq_len_list, data, epoch=None):\n",
    "        \"\"\"\n",
    "\n",
    "        :param label_list:\n",
    "        :param seq_len_list:\n",
    "        :param data:\n",
    "        :param epoch:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        label2tag = {}\n",
    "        for tag, label in self.tag2label.items():\n",
    "            label2tag[label] = tag if label != 0 else label\n",
    "\n",
    "        model_predict = []\n",
    "        #for label_, (sent, tag) in zip(label_list, data):\n",
    "        for label_, (sent, _, _, tag) in zip(label_list, data):\n",
    "            tag_ = [label2tag[label__] for label__ in label_]\n",
    "            sent_res = []\n",
    "            if  len(label_) != len(sent):\n",
    "                print(sent)\n",
    "                print(len(label_))\n",
    "                print(tag)\n",
    "            for i in range(len(sent)):\n",
    "                sent_res.append([sent[i], tag[i], tag_[i]])\n",
    "            model_predict.append(sent_res)\n",
    "        #print(model_predict)\n",
    "        epoch_num = str(epoch+1) if epoch != None else 'test'\n",
    "        label_path = os.path.join(self.result_path, 'label_' + epoch_num)\n",
    "        metric_path = os.path.join(self.result_path, 'result_metric_' + epoch_num)\n",
    "        for _ in conlleval(model_predict, label_path, metric_path):\n",
    "            self.logger.info(_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'test'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/svjack/temp_dir/colab-model/multi_data_path_save/1597451905/checkpoints/model-1008-252\n"
     ]
    }
   ],
   "source": [
    "ckpt_file = tf.train.latest_checkpoint(\"/home/svjack/temp_dir/colab-model/multi_data_path_save/1597451905/checkpoints/\")\n",
    "print(ckpt_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.filters_list = [3, 5]\n",
    "args.kernel_list = [3, 5]\n",
    "paths['model_path'] = ckpt_file\n",
    "model = BiLSTM_CRF_MULTI_CHAR(args, embeddings, char_embeddings, \n",
    "                              model_dict[\"feature_0_to_label\"], \n",
    "                              model_dict[\"feature_1_to_label\"], \n",
    "                              model_dict[\"tag2label\"], \n",
    "                              word2id, \n",
    "                              model_dict[\"char2id\"], paths, config = config)\n",
    "model.build_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "=========== testing ===========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /home/svjack/temp_dir/colab-model/multi_data_path_save/1597451905/checkpoints/model-1008-252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Restoring parameters from /home/svjack/temp_dir/colab-model/multi_data_path_save/1597451905/checkpoints/model-1008-252\n",
      "processed 50154 tokens with 5648 phrases; found: 5645 phrases; correct: 4652.\n",
      "accuracy:  96.83%; precision:  82.41%; recall:  82.37%; FB1:  82.39\n",
      "LOC: precision:  89.61%; recall:  86.39%; FB1:  87.97  1608\n",
      "MISC: precision:  69.10%; recall:  72.93%; FB1:  70.96  741\n",
      "ORG: precision:  80.08%; recall:  76.22%; FB1:  78.10  1581\n",
      "PER: precision:  83.56%; recall:  88.62%; FB1:  86.01  1715\n"
     ]
    }
   ],
   "source": [
    "model.test(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input = list(batch_yield_multi_with_chars(test_data, model.batch_size, model.vocab, model.char2id, model.feature_0_to_label, model.feature_1_to_label, model.tag2label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/svjack/temp_dir/colab-model/multi_data_path_save/1597451905/checkpoints/model-1008-252\n",
      "INFO:tensorflow:Restoring parameters from /home/svjack/temp_dir/colab-model/multi_data_path_save/1597451905/checkpoints/model-1008-252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Restoring parameters from /home/svjack/temp_dir/colab-model/multi_data_path_save/1597451905/checkpoints/model-1008-252\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session(config=config)\n",
    "saver = tf.train.Saver()\n",
    "print(ckpt_file)\n",
    "saver.restore(sess, ckpt_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "nest_label_list_ = list(map(lambda t4: model.predict_one_batch(sess, t4[0], t4[1], t4[2], t4[3]), map(lambda t5: (t5[0], t5[1], t5[2], t5[3]), test_input)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_nest_label_list_ = list(map(lambda t2: t2[0], nest_label_list_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "nest_input_list_ = list(map(lambda t2: t2[1], test_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "truly_nest_label_list_ = list(map(lambda t2: t2[-1], test_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0     64\n",
       " 1     64\n",
       " 2     64\n",
       " 3     64\n",
       " 4     64\n",
       "       ..\n",
       " 57    64\n",
       " 58    64\n",
       " 59    64\n",
       " 60    64\n",
       " 61     5\n",
       " Length: 62, dtype: int64,\n",
       " 0     64\n",
       " 1     64\n",
       " 2     64\n",
       " 3     64\n",
       " 4     64\n",
       "       ..\n",
       " 57    64\n",
       " 58    64\n",
       " 59    64\n",
       " 60    64\n",
       " 61     5\n",
       " Length: 62, dtype: int64,\n",
       " 0     64\n",
       " 1     64\n",
       " 2     64\n",
       " 3     64\n",
       " 4     64\n",
       "       ..\n",
       " 57    64\n",
       " 58    64\n",
       " 59    64\n",
       " 60    64\n",
       " 61     5\n",
       " Length: 62, dtype: int64]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(map(lambda x: pd.Series(x).map(len), [nest_input_list_, truly_nest_label_list_, pred_nest_label_list_]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "concat_df = pd.concat(list(map(lambda x: pd.Series(reduce(lambda a, b: a + b ,x)), [nest_input_list_, truly_nest_label_list_, pred_nest_label_list_])), axis = 1)\n",
    "concat_df.columns = [\"input\", \"truly\", \"pred\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab, tag2label = model.vocab, model.tag2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "label2tag = dict(map(lambda t2: (t2[1], t2[0]), tag2label.items()))\n",
    "idx2vocab = dict(map(lambda t2: (t2[1], t2[0]), vocab.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>truly</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[1]</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[1817, 658, 22926, 22926, 22926, 3278, 71, 207...</td>\n",
       "      <td>[0, 0, 5, 0, 0, 0, 0, 3, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 3, 0, 3, 0, 0, 3, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[22926, 22926]</td>\n",
       "      <td>[3, 4]</td>\n",
       "      <td>[3, 4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[22926, 71, 845, 1114, 1115, 22926]</td>\n",
       "      <td>[5, 0, 5, 8, 8, 0]</td>\n",
       "      <td>[0, 0, 5, 8, 8, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[1742, 1366, 41, 3293, 162, 201, 6010, 1832, 2...</td>\n",
       "      <td>[5, 0, 0, 0, 0, 0, 2, 7, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[5, 0, 0, 0, 0, 0, 2, 7, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               input  \\\n",
       "0                                                [1]   \n",
       "1  [1817, 658, 22926, 22926, 22926, 3278, 71, 207...   \n",
       "2                                     [22926, 22926]   \n",
       "3                [22926, 71, 845, 1114, 1115, 22926]   \n",
       "4  [1742, 1366, 41, 3293, 162, 201, 6010, 1832, 2...   \n",
       "\n",
       "                                               truly  \\\n",
       "0                                                [0]   \n",
       "1               [0, 0, 5, 0, 0, 0, 0, 3, 0, 0, 0, 0]   \n",
       "2                                             [3, 4]   \n",
       "3                                 [5, 0, 5, 8, 8, 0]   \n",
       "4  [5, 0, 0, 0, 0, 0, 2, 7, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                                pred  \n",
       "0                                                [0]  \n",
       "1               [0, 0, 3, 0, 3, 0, 0, 3, 0, 0, 0, 0]  \n",
       "2                                             [3, 4]  \n",
       "3                                 [0, 0, 5, 8, 8, 0]  \n",
       "4  [5, 0, 0, 0, 0, 0, 2, 7, 0, 0, 0, 0, 0, 0, 0, ...  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concat_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_df[\"input_reverse\"] = concat_df[\"input\"].map(lambda x: list(map(lambda y: idx2vocab[y], x)))\n",
    "concat_df[\"truly_reverse\"] = concat_df[\"truly\"].map(lambda x: list(map(lambda y: label2tag[y], x)))\n",
    "concat_df[\"pred_reverse\"] = concat_df[\"pred\"].map(lambda x: list(map(lambda y: label2tag[y], x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>truly</th>\n",
       "      <th>pred</th>\n",
       "      <th>input_reverse</th>\n",
       "      <th>truly_reverse</th>\n",
       "      <th>pred_reverse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[1]</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[-DOCSTART-]</td>\n",
       "      <td>[O]</td>\n",
       "      <td>[O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[1817, 658, 22926, 22926, 22926, 3278, 71, 207...</td>\n",
       "      <td>[0, 0, 5, 0, 0, 0, 0, 3, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 3, 0, 3, 0, 0, 3, 0, 0, 0, 0]</td>\n",
       "      <td>[SOCCER, -, &lt;UNK&gt;, &lt;UNK&gt;, &lt;UNK&gt;, WIN, ,, CHINA...</td>\n",
       "      <td>[O, O, B-LOC, O, O, O, O, B-PER, O, O, O, O]</td>\n",
       "      <td>[O, O, B-PER, O, B-PER, O, O, B-PER, O, O, O, O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[22926, 22926]</td>\n",
       "      <td>[3, 4]</td>\n",
       "      <td>[3, 4]</td>\n",
       "      <td>[&lt;UNK&gt;, &lt;UNK&gt;]</td>\n",
       "      <td>[B-PER, I-PER]</td>\n",
       "      <td>[B-PER, I-PER]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[22926, 71, 845, 1114, 1115, 22926]</td>\n",
       "      <td>[5, 0, 5, 8, 8, 0]</td>\n",
       "      <td>[0, 0, 5, 8, 8, 0]</td>\n",
       "      <td>[&lt;UNK&gt;, ,, United, Arab, Emirates, &lt;UNK&gt;]</td>\n",
       "      <td>[B-LOC, O, B-LOC, I-LOC, I-LOC, O]</td>\n",
       "      <td>[O, O, B-LOC, I-LOC, I-LOC, O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[1742, 1366, 41, 3293, 162, 201, 6010, 1832, 2...</td>\n",
       "      <td>[5, 0, 0, 0, 0, 0, 2, 7, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[5, 0, 0, 0, 0, 0, 2, 7, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[Japan, began, the, defence, of, their, Asian,...</td>\n",
       "      <td>[B-LOC, O, O, O, O, O, B-MISC, I-MISC, O, O, O...</td>\n",
       "      <td>[B-LOC, O, O, O, O, O, B-MISC, I-MISC, O, O, O...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               input  \\\n",
       "0                                                [1]   \n",
       "1  [1817, 658, 22926, 22926, 22926, 3278, 71, 207...   \n",
       "2                                     [22926, 22926]   \n",
       "3                [22926, 71, 845, 1114, 1115, 22926]   \n",
       "4  [1742, 1366, 41, 3293, 162, 201, 6010, 1832, 2...   \n",
       "\n",
       "                                               truly  \\\n",
       "0                                                [0]   \n",
       "1               [0, 0, 5, 0, 0, 0, 0, 3, 0, 0, 0, 0]   \n",
       "2                                             [3, 4]   \n",
       "3                                 [5, 0, 5, 8, 8, 0]   \n",
       "4  [5, 0, 0, 0, 0, 0, 2, 7, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                                pred  \\\n",
       "0                                                [0]   \n",
       "1               [0, 0, 3, 0, 3, 0, 0, 3, 0, 0, 0, 0]   \n",
       "2                                             [3, 4]   \n",
       "3                                 [0, 0, 5, 8, 8, 0]   \n",
       "4  [5, 0, 0, 0, 0, 0, 2, 7, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                       input_reverse  \\\n",
       "0                                       [-DOCSTART-]   \n",
       "1  [SOCCER, -, <UNK>, <UNK>, <UNK>, WIN, ,, CHINA...   \n",
       "2                                     [<UNK>, <UNK>]   \n",
       "3          [<UNK>, ,, United, Arab, Emirates, <UNK>]   \n",
       "4  [Japan, began, the, defence, of, their, Asian,...   \n",
       "\n",
       "                                       truly_reverse  \\\n",
       "0                                                [O]   \n",
       "1       [O, O, B-LOC, O, O, O, O, B-PER, O, O, O, O]   \n",
       "2                                     [B-PER, I-PER]   \n",
       "3                 [B-LOC, O, B-LOC, I-LOC, I-LOC, O]   \n",
       "4  [B-LOC, O, O, O, O, O, B-MISC, I-MISC, O, O, O...   \n",
       "\n",
       "                                        pred_reverse  \n",
       "0                                                [O]  \n",
       "1   [O, O, B-PER, O, B-PER, O, O, B-PER, O, O, O, O]  \n",
       "2                                     [B-PER, I-PER]  \n",
       "3                     [O, O, B-LOC, I-LOC, I-LOC, O]  \n",
       "4  [B-LOC, O, O, O, O, O, B-MISC, I-MISC, O, O, O...  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concat_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_indices_from_truly_or_pred_list(truly_or_pred_list):\n",
    "    truly_or_pred_array = np.asarray(truly_or_pred_list)\n",
    "    valid_where = np.where(truly_or_pred_array != \"O\")[0]\n",
    "    #print(valid_where)\n",
    "    if valid_where.size:\n",
    "        indice_list = []\n",
    "        labels_list = []\n",
    "        now = -1\n",
    "        for ele in valid_where.tolist():\n",
    "            if not indice_list:\n",
    "                if truly_or_pred_list[ele].startswith(\"B\"):\n",
    "                    indice_list.append([ele])\n",
    "                    labels_list.append([truly_or_pred_list[ele]])\n",
    "                else:\n",
    "                    print(\"skip tag {} as head.\".format(truly_or_pred_list[ele]))\n",
    "            else:\n",
    "                if ele == now + 1:\n",
    "                    if truly_or_pred_list[ele].startswith(\"I\"):\n",
    "                        indice_list[-1].append(ele)\n",
    "                        labels_list[-1].append(truly_or_pred_list[ele])\n",
    "                    else:\n",
    "                        assert truly_or_pred_list[ele].startswith(\"B\")\n",
    "                        indice_list.append([ele])\n",
    "                        labels_list.append([truly_or_pred_list[ele]])\n",
    "                else:\n",
    "                    if truly_or_pred_list[ele].startswith(\"B\"):\n",
    "                        indice_list.append([ele])\n",
    "                        labels_list.append([truly_or_pred_list[ele]])\n",
    "                    else:\n",
    "                        print(\"skip tag {} as head.\".format(truly_or_pred_list[ele]))\n",
    "            now = ele\n",
    "            \n",
    "        indice_list_filtered = []\n",
    "        labels_list_filtered = []\n",
    "        assert len(indice_list) == len(labels_list)\n",
    "        for idx, inner_label_list in enumerate(labels_list):\n",
    "            inner_indice_list = indice_list[idx]\n",
    "            assert len(set(map(lambda x: x.split(\"-\")[0], inner_label_list))) <= 2\n",
    "            assert len(list(filter(lambda x: x.startswith(\"B\"), inner_label_list))) == 1\n",
    "            assert inner_label_list[0].startswith(\"B\")\n",
    "            B_cate = list(filter(lambda x: x.startswith(\"B\"), inner_label_list))[0].split(\"-\")[-1]\n",
    "            req_inner_indice_list = [inner_indice_list[0]]\n",
    "            req_inner_label_list = [inner_label_list[0]]\n",
    "            for iidx, label in enumerate(inner_label_list[1:]):\n",
    "                indice = inner_indice_list[1:][iidx]\n",
    "                if label.endswith(B_cate) and label.startswith(\"I\"):\n",
    "                    req_inner_indice_list.append(indice)\n",
    "                    req_inner_label_list.append(label)\n",
    "                else:\n",
    "                    break\n",
    "            \n",
    "            indice_list_filtered.append(req_inner_indice_list)\n",
    "            labels_list_filtered.append(req_inner_label_list)\n",
    "        \n",
    "        return indice_list_filtered, labels_list_filtered\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skip tag I-PER as head.\n",
      "skip tag I-MISC as head.\n",
      "skip tag I-MISC as head.\n",
      "skip tag I-PER as head.\n",
      "skip tag I-ORG as head.\n",
      "skip tag I-PER as head.\n",
      "skip tag I-PER as head.\n",
      "skip tag I-PER as head.\n",
      "skip tag I-MISC as head.\n",
      "skip tag I-ORG as head.\n",
      "skip tag I-ORG as head.\n",
      "skip tag I-ORG as head.\n",
      "skip tag I-ORG as head.\n",
      "skip tag I-ORG as head.\n",
      "skip tag I-PER as head.\n",
      "skip tag I-ORG as head.\n",
      "skip tag I-PER as head.\n",
      "skip tag I-PER as head.\n",
      "skip tag I-PER as head.\n",
      "skip tag I-ORG as head.\n",
      "skip tag I-PER as head.\n",
      "skip tag I-PER as head.\n",
      "skip tag I-PER as head.\n",
      "skip tag I-PER as head.\n",
      "skip tag I-PER as head.\n",
      "skip tag I-PER as head.\n",
      "skip tag I-ORG as head.\n",
      "skip tag I-ORG as head.\n",
      "skip tag I-ORG as head.\n",
      "skip tag I-PER as head.\n",
      "skip tag I-PER as head.\n",
      "skip tag I-ORG as head.\n",
      "skip tag I-ORG as head.\n",
      "skip tag I-ORG as head.\n",
      "skip tag I-ORG as head.\n",
      "skip tag I-ORG as head.\n",
      "skip tag I-ORG as head.\n",
      "skip tag I-PER as head.\n",
      "skip tag I-ORG as head.\n",
      "skip tag I-ORG as head.\n",
      "skip tag I-MISC as head.\n",
      "skip tag I-MISC as head.\n",
      "skip tag I-MISC as head.\n",
      "skip tag I-MISC as head.\n",
      "skip tag I-MISC as head.\n",
      "skip tag I-MISC as head.\n",
      "skip tag I-MISC as head.\n",
      "skip tag I-PER as head.\n",
      "skip tag I-MISC as head.\n",
      "skip tag I-MISC as head.\n",
      "skip tag I-MISC as head.\n",
      "skip tag I-MISC as head.\n",
      "skip tag I-PER as head.\n",
      "skip tag I-PER as head.\n",
      "skip tag I-PER as head.\n",
      "skip tag I-PER as head.\n",
      "skip tag I-PER as head.\n",
      "skip tag I-PER as head.\n"
     ]
    }
   ],
   "source": [
    "concat_df[\"truly_reverse_decode_prepare\"] = concat_df[\"truly_reverse\"].map(retrieve_indices_from_truly_or_pred_list)\n",
    "concat_df[\"pred_reverse_decode_prepare\"] = concat_df[\"pred_reverse\"].map(retrieve_indices_from_truly_or_pred_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>truly</th>\n",
       "      <th>pred</th>\n",
       "      <th>input_reverse</th>\n",
       "      <th>truly_reverse</th>\n",
       "      <th>pred_reverse</th>\n",
       "      <th>truly_reverse_decode_prepare</th>\n",
       "      <th>pred_reverse_decode_prepare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[1]</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[-DOCSTART-]</td>\n",
       "      <td>[O]</td>\n",
       "      <td>[O]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[1817, 658, 22926, 22926, 22926, 3278, 71, 207...</td>\n",
       "      <td>[0, 0, 5, 0, 0, 0, 0, 3, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 3, 0, 3, 0, 0, 3, 0, 0, 0, 0]</td>\n",
       "      <td>[SOCCER, -, &lt;UNK&gt;, &lt;UNK&gt;, &lt;UNK&gt;, WIN, ,, CHINA...</td>\n",
       "      <td>[O, O, B-LOC, O, O, O, O, B-PER, O, O, O, O]</td>\n",
       "      <td>[O, O, B-PER, O, B-PER, O, O, B-PER, O, O, O, O]</td>\n",
       "      <td>([[2], [7]], [[B-LOC], [B-PER]])</td>\n",
       "      <td>([[2], [4], [7]], [[B-PER], [B-PER], [B-PER]])</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[22926, 22926]</td>\n",
       "      <td>[3, 4]</td>\n",
       "      <td>[3, 4]</td>\n",
       "      <td>[&lt;UNK&gt;, &lt;UNK&gt;]</td>\n",
       "      <td>[B-PER, I-PER]</td>\n",
       "      <td>[B-PER, I-PER]</td>\n",
       "      <td>([[0, 1]], [[B-PER, I-PER]])</td>\n",
       "      <td>([[0, 1]], [[B-PER, I-PER]])</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[22926, 71, 845, 1114, 1115, 22926]</td>\n",
       "      <td>[5, 0, 5, 8, 8, 0]</td>\n",
       "      <td>[0, 0, 5, 8, 8, 0]</td>\n",
       "      <td>[&lt;UNK&gt;, ,, United, Arab, Emirates, &lt;UNK&gt;]</td>\n",
       "      <td>[B-LOC, O, B-LOC, I-LOC, I-LOC, O]</td>\n",
       "      <td>[O, O, B-LOC, I-LOC, I-LOC, O]</td>\n",
       "      <td>([[0], [2, 3, 4]], [[B-LOC], [B-LOC, I-LOC, I-...</td>\n",
       "      <td>([[2, 3, 4]], [[B-LOC, I-LOC, I-LOC]])</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[1742, 1366, 41, 3293, 162, 201, 6010, 1832, 2...</td>\n",
       "      <td>[5, 0, 0, 0, 0, 0, 2, 7, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[5, 0, 0, 0, 0, 0, 2, 7, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[Japan, began, the, defence, of, their, Asian,...</td>\n",
       "      <td>[B-LOC, O, O, O, O, O, B-MISC, I-MISC, O, O, O...</td>\n",
       "      <td>[B-LOC, O, O, O, O, O, B-MISC, I-MISC, O, O, O...</td>\n",
       "      <td>([[0], [6, 7], [15]], [[B-LOC], [B-MISC, I-MIS...</td>\n",
       "      <td>([[0], [6, 7], [15]], [[B-LOC], [B-MISC, I-MIS...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               input  \\\n",
       "0                                                [1]   \n",
       "1  [1817, 658, 22926, 22926, 22926, 3278, 71, 207...   \n",
       "2                                     [22926, 22926]   \n",
       "3                [22926, 71, 845, 1114, 1115, 22926]   \n",
       "4  [1742, 1366, 41, 3293, 162, 201, 6010, 1832, 2...   \n",
       "\n",
       "                                               truly  \\\n",
       "0                                                [0]   \n",
       "1               [0, 0, 5, 0, 0, 0, 0, 3, 0, 0, 0, 0]   \n",
       "2                                             [3, 4]   \n",
       "3                                 [5, 0, 5, 8, 8, 0]   \n",
       "4  [5, 0, 0, 0, 0, 0, 2, 7, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                                pred  \\\n",
       "0                                                [0]   \n",
       "1               [0, 0, 3, 0, 3, 0, 0, 3, 0, 0, 0, 0]   \n",
       "2                                             [3, 4]   \n",
       "3                                 [0, 0, 5, 8, 8, 0]   \n",
       "4  [5, 0, 0, 0, 0, 0, 2, 7, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                       input_reverse  \\\n",
       "0                                       [-DOCSTART-]   \n",
       "1  [SOCCER, -, <UNK>, <UNK>, <UNK>, WIN, ,, CHINA...   \n",
       "2                                     [<UNK>, <UNK>]   \n",
       "3          [<UNK>, ,, United, Arab, Emirates, <UNK>]   \n",
       "4  [Japan, began, the, defence, of, their, Asian,...   \n",
       "\n",
       "                                       truly_reverse  \\\n",
       "0                                                [O]   \n",
       "1       [O, O, B-LOC, O, O, O, O, B-PER, O, O, O, O]   \n",
       "2                                     [B-PER, I-PER]   \n",
       "3                 [B-LOC, O, B-LOC, I-LOC, I-LOC, O]   \n",
       "4  [B-LOC, O, O, O, O, O, B-MISC, I-MISC, O, O, O...   \n",
       "\n",
       "                                        pred_reverse  \\\n",
       "0                                                [O]   \n",
       "1   [O, O, B-PER, O, B-PER, O, O, B-PER, O, O, O, O]   \n",
       "2                                     [B-PER, I-PER]   \n",
       "3                     [O, O, B-LOC, I-LOC, I-LOC, O]   \n",
       "4  [B-LOC, O, O, O, O, O, B-MISC, I-MISC, O, O, O...   \n",
       "\n",
       "                        truly_reverse_decode_prepare  \\\n",
       "0                                               None   \n",
       "1                   ([[2], [7]], [[B-LOC], [B-PER]])   \n",
       "2                       ([[0, 1]], [[B-PER, I-PER]])   \n",
       "3  ([[0], [2, 3, 4]], [[B-LOC], [B-LOC, I-LOC, I-...   \n",
       "4  ([[0], [6, 7], [15]], [[B-LOC], [B-MISC, I-MIS...   \n",
       "\n",
       "                         pred_reverse_decode_prepare  \n",
       "0                                               None  \n",
       "1     ([[2], [4], [7]], [[B-PER], [B-PER], [B-PER]])  \n",
       "2                       ([[0, 1]], [[B-PER, I-PER]])  \n",
       "3             ([[2, 3, 4]], [[B-LOC, I-LOC, I-LOC]])  \n",
       "4  ([[0], [6, 7], [15]], [[B-LOC], [B-MISC, I-MIS...  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concat_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_ner(input_df, input_reverse_col, decode_prepare_col):\n",
    "    assert input_reverse_col in input_df.columns.tolist()\n",
    "    assert decode_prepare_col in input_df.columns.tolist()\n",
    "    input_reverse_list = input_df[input_reverse_col].tolist()\n",
    "    decode_prepare_list = input_df[decode_prepare_col].tolist()\n",
    "    \n",
    "    s0, s1 = input_reverse_list, decode_prepare_list\n",
    "    s0_filtered = []\n",
    "    s1_filtered = []\n",
    "    for i in range(len(s0)):\n",
    "        s0_ele, s1_ele = s0[i], s1[i]\n",
    "        if s0_ele is None or s1_ele is None:\n",
    "            continue\n",
    "        s0_filtered.append(s0_ele)\n",
    "        s1_filtered.append(s1_ele)\n",
    "    input_reverse_list, decode_prepare_list = s0_filtered, s1_filtered\n",
    "    \n",
    "    from collections import defaultdict\n",
    "    ner_entity_set_dict = defaultdict(set)\n",
    "    for idx, decode_prepare in enumerate(decode_prepare_list):\n",
    "        if (not decode_prepare[0]) and (not decode_prepare[1]):\n",
    "            continue\n",
    "        indice_nest_list, labels_nest_list = decode_prepare\n",
    "        input_reverse_array = np.asarray(input_reverse_list[idx])\n",
    "        for iidx, inner_label_list in enumerate(labels_nest_list):\n",
    "            assert len(set(map(lambda x: x.split(\"-\")[0], inner_label_list))) <= 2\n",
    "            assert len(list(filter(lambda x: x.startswith(\"B\"), inner_label_list))) == 1\n",
    "            assert inner_label_list[0].startswith(\"B\")\n",
    "            assert len(set(map(lambda x: x.split(\"-\")[-1], inner_label_list))) == 1\n",
    "            B_cate = list(filter(lambda x: x.startswith(\"B\"), inner_label_list))[0].split(\"-\")[-1]\n",
    "            inner_indice_list = indice_nest_list[iidx]\n",
    "            entity_str = \" \".join(input_reverse_array[inner_indice_list].tolist())\n",
    "            ner_entity_set_dict[B_cate].add(entity_str)\n",
    "    return ner_entity_set_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "truly_decode_ner_dict_set = decode_ner(concat_df.iloc[:10, :], \"input_reverse\", \"truly_reverse_decode_prepare\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(set,\n",
       "            {'LOC': {'<UNK>',\n",
       "              'China',\n",
       "              'Japan',\n",
       "              'Syria',\n",
       "              'United Arab Emirates'},\n",
       "             'PER': {'<UNK> <UNK>', 'CHINA'},\n",
       "             'MISC': {'<UNK>',\n",
       "              'Asian Cup',\n",
       "              'Asian Games',\n",
       "              'Chinese',\n",
       "              'Soviet'}})"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "truly_decode_ner_dict_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_decode_ner_dict_set = decode_ner(concat_df.iloc[:10, :], \"input_reverse\", \"pred_reverse_decode_prepare\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(set,\n",
       "            {'PER': {'<UNK>', '<UNK> <UNK>', 'CHINA'},\n",
       "             'LOC': {'China', 'Japan', 'Syria', 'United Arab Emirates'},\n",
       "             'MISC': {'Asian Cup', 'Asian Games', 'Chinese', 'Soviet'},\n",
       "             'ORG': {'<UNK>'}})"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_decode_ner_dict_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "truly_decode_ner_dict_set = decode_ner(concat_df, \"input_reverse\", \"truly_reverse_decode_prepare\")\n",
    "pred_decode_ner_dict_set = decode_ner(concat_df, \"input_reverse\", \"pred_reverse_decode_prepare\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(set,\n",
       "            {'LOC': {'<UNK>',\n",
       "              '<UNK> <UNK>',\n",
       "              '<UNK> <UNK> <UNK>',\n",
       "              '<UNK> Bay',\n",
       "              '<UNK> California',\n",
       "              '<UNK> Control Centre',\n",
       "              '<UNK> County',\n",
       "              '<UNK> LOUIS',\n",
       "              '<UNK> Mountain',\n",
       "              '<UNK> Oval',\n",
       "              '<UNK> Point',\n",
       "              '<UNK> Pradesh',\n",
       "              '<UNK> STATE',\n",
       "              '<UNK> Street',\n",
       "              'ABIDJAN',\n",
       "              'AMSTERDAM',\n",
       "              'ANKARA',\n",
       "              'ATLANTA',\n",
       "              'ATLANTIC',\n",
       "              'AUSTRALIA',\n",
       "              'AUSTRIA',\n",
       "              'Abidjan',\n",
       "              'Africa',\n",
       "              'Albania',\n",
       "              'Alberta',\n",
       "              'Algeria',\n",
       "              'Algiers',\n",
       "              'Amsterdam',\n",
       "              'Asia',\n",
       "              'Athens',\n",
       "              'Atlanta',\n",
       "              'Australia',\n",
       "              'Austria',\n",
       "              'BANGKOK',\n",
       "              'BEIJING',\n",
       "              'BEIRUT',\n",
       "              'BOMBAY',\n",
       "              'BONN',\n",
       "              'BOSTON',\n",
       "              'BRATISLAVA',\n",
       "              'BRUSSELS',\n",
       "              'BUCHAREST',\n",
       "              'BUDAPEST',\n",
       "              'BUENOS AIRES',\n",
       "              'Bahia <UNK>',\n",
       "              'Balkan',\n",
       "              'Bangui',\n",
       "              'Barcelona',\n",
       "              'Beirut',\n",
       "              'Belarus',\n",
       "              'Belgium',\n",
       "              'Belgrade',\n",
       "              'Bombay',\n",
       "              'Bonn',\n",
       "              'Bratislava',\n",
       "              'Brazil',\n",
       "              'Britain',\n",
       "              'British Columbia',\n",
       "              'Brno',\n",
       "              'Budapest',\n",
       "              'Buenos Aires',\n",
       "              'Bulgaria',\n",
       "              'Burma',\n",
       "              'Burundi',\n",
       "              'CAIRO',\n",
       "              'CAN',\n",
       "              'CANBERRA',\n",
       "              'CHICAGO',\n",
       "              'CINCINNATI',\n",
       "              'CIS',\n",
       "              'COLORADO',\n",
       "              'COPENHAGEN',\n",
       "              'Cairo',\n",
       "              'Calcutta',\n",
       "              'California',\n",
       "              'Canada',\n",
       "              'Canberra',\n",
       "              'Cape Town',\n",
       "              'Cardiff',\n",
       "              'Caribbean',\n",
       "              'Caribs',\n",
       "              'Central Africa',\n",
       "              'Central African Republic',\n",
       "              'Central Asia',\n",
       "              'Chad',\n",
       "              'Chapman Golf Club',\n",
       "              'Charleroi',\n",
       "              'Chicago',\n",
       "              'Chile',\n",
       "              'China',\n",
       "              'Cincinnati',\n",
       "              'Colombia',\n",
       "              'Colorado',\n",
       "              'Columbus',\n",
       "              'Copenhagen',\n",
       "              'Croatia',\n",
       "              'Cuba',\n",
       "              'Czech',\n",
       "              'Czech Republic',\n",
       "              'DAKAR',\n",
       "              'DALLAS',\n",
       "              'DENVER',\n",
       "              'DES MOINES',\n",
       "              'DETROIT',\n",
       "              'DIYARBAKIR',\n",
       "              'DODGE CITY',\n",
       "              'DUBLIN',\n",
       "              'Damascus',\n",
       "              'Denmark',\n",
       "              'East <UNK>',\n",
       "              'Egypt',\n",
       "              'El Salvador',\n",
       "              'England',\n",
       "              'Estonia',\n",
       "              'Ethiopia',\n",
       "              'Europe',\n",
       "              'FRANKFURT',\n",
       "              'Finland',\n",
       "              'Fla.',\n",
       "              'Florence',\n",
       "              'Florida',\n",
       "              'Football',\n",
       "              'France',\n",
       "              'Frankfurt',\n",
       "              'Freiburg',\n",
       "              'GENEVA',\n",
       "              'GLASGOW',\n",
       "              'GREECE',\n",
       "              'GREEN <UNK>',\n",
       "              'Gabon',\n",
       "              'Geneva',\n",
       "              'Germany',\n",
       "              'Goma',\n",
       "              'Grand <UNK>',\n",
       "              'Greece',\n",
       "              'Gulf',\n",
       "              'Gulf Coast',\n",
       "              'Gulf of Mexico',\n",
       "              'HAMBURG',\n",
       "              'HANOVER',\n",
       "              'HARARE',\n",
       "              'HOUSTON',\n",
       "              'Hamburg',\n",
       "              'Hanover',\n",
       "              'Hebron',\n",
       "              'Henry Hub',\n",
       "              'Houston',\n",
       "              'Hungary',\n",
       "              'Illinois',\n",
       "              'India',\n",
       "              'Indian Ocean',\n",
       "              'Indianapolis',\n",
       "              'Indonesia',\n",
       "              'Iran',\n",
       "              'Iraq',\n",
       "              'Ireland',\n",
       "              'Israel',\n",
       "              'Italy',\n",
       "              'Ivory Coast',\n",
       "              'JAKARTA',\n",
       "              'JERUSALEM',\n",
       "              'JOHANNESBURG',\n",
       "              'Jakarta',\n",
       "              'Japan',\n",
       "              'Jerusalem',\n",
       "              'K.T. <UNK>',\n",
       "              'Kansas',\n",
       "              'Kansas City',\n",
       "              'Karachi',\n",
       "              'Karlsruhe',\n",
       "              'Kenya',\n",
       "              'Kinshasa',\n",
       "              'Kremlin',\n",
       "              'Kuwait',\n",
       "              'LA <UNK>',\n",
       "              'LISBON',\n",
       "              'LONDON',\n",
       "              'LOS ANGELES',\n",
       "              'La <UNK>',\n",
       "              'Latin America',\n",
       "              'League',\n",
       "              'Lebanon',\n",
       "              'Leicester',\n",
       "              'Lisbon',\n",
       "              'London',\n",
       "              'London Heathrow',\n",
       "              'Los Angeles',\n",
       "              'Luxembourg',\n",
       "              'MADRID',\n",
       "              'MELBOURNE',\n",
       "              'MEXICO CITY',\n",
       "              'MIAMI',\n",
       "              'MONTREAL',\n",
       "              'MOSCOW',\n",
       "              'Macedonia',\n",
       "              'Madagascar',\n",
       "              'Madrid',\n",
       "              'Malaysia',\n",
       "              'Manchester',\n",
       "              'Maracaibo',\n",
       "              'Mauritania',\n",
       "              'Mauritius',\n",
       "              'Melbourne',\n",
       "              'Melbourne Cricket <UNK>',\n",
       "              'Mexico',\n",
       "              'Mexico City',\n",
       "              'Michigan',\n",
       "              'Milan',\n",
       "              'Minn',\n",
       "              'Minneapolis',\n",
       "              'Mongolia',\n",
       "              'Montana',\n",
       "              'Moscow',\n",
       "              'N. Ireland',\n",
       "              'N.J.',\n",
       "              'N.M.',\n",
       "              'NAIROBI',\n",
       "              'NEW <UNK>',\n",
       "              'NEW DELHI',\n",
       "              'NEW ENGLAND',\n",
       "              'NEW YORK',\n",
       "              'NEW ZEALAND',\n",
       "              'NZ',\n",
       "              'Nairobi',\n",
       "              'Namibia',\n",
       "              'National stadium',\n",
       "              'Nebraska',\n",
       "              'Netherlands',\n",
       "              'New <UNK>',\n",
       "              'New Mexico',\n",
       "              'New York',\n",
       "              'New York City',\n",
       "              'New Zealand',\n",
       "              'Newcastle',\n",
       "              'Nigeria',\n",
       "              'North America',\n",
       "              'North West',\n",
       "              'Northern Ireland',\n",
       "              'Norway',\n",
       "              'OAKLAND',\n",
       "              'Ohio',\n",
       "              'Oslo',\n",
       "              'Ottawa',\n",
       "              'Oxford',\n",
       "              'PACIFIC',\n",
       "              'PAKISTAN',\n",
       "              'PARIS',\n",
       "              'PITTSBURGH',\n",
       "              'POLAND',\n",
       "              'PRAGUE',\n",
       "              'Pacific Coast',\n",
       "              'Pakistan',\n",
       "              'Panhandle',\n",
       "              'Papua New Guinea',\n",
       "              'Paris',\n",
       "              'Philadelphia',\n",
       "              'Philippines',\n",
       "              'Po',\n",
       "              'Poland',\n",
       "              'Port Louis',\n",
       "              'Portsmouth',\n",
       "              'Portugal',\n",
       "              'Prague',\n",
       "              'Prince Rupert',\n",
       "              'RAI',\n",
       "              'RED SEA',\n",
       "              'RIO DE JANEIRO',\n",
       "              'ROME',\n",
       "              'Rangoon',\n",
       "              'Red Sea',\n",
       "              'Republic of Ireland',\n",
       "              'Republic of Padania',\n",
       "              'Rio de Janeiro',\n",
       "              'Romania',\n",
       "              'Rome',\n",
       "              'Rosario',\n",
       "              'Rotterdam',\n",
       "              'Russia',\n",
       "              'Rwanda',\n",
       "              'SAN <UNK>',\n",
       "              'SAN FRANCISCO',\n",
       "              'SAN JOSE',\n",
       "              'SEATTLE',\n",
       "              'SEOUL',\n",
       "              'SHANGHAI',\n",
       "              'SINGAPORE',\n",
       "              'SOFIA',\n",
       "              'SOUTH <UNK>',\n",
       "              'SYDNEY',\n",
       "              'San Francisco',\n",
       "              'Santa <UNK>',\n",
       "              'Santander',\n",
       "              'Santiago',\n",
       "              'Santiago Bernabeu stadium',\n",
       "              'Saudi Arabia',\n",
       "              'Scotland',\n",
       "              'Senegal',\n",
       "              'Sidi <UNK>',\n",
       "              'Singapore',\n",
       "              'Slovakia',\n",
       "              'Slovenia',\n",
       "              'South Africa',\n",
       "              'South America',\n",
       "              'South Korea',\n",
       "              'Soviet Union',\n",
       "              'Spain',\n",
       "              'St Louis',\n",
       "              'St. Louis',\n",
       "              'Sudan',\n",
       "              'Sweden',\n",
       "              'Switzerland',\n",
       "              'Sydney',\n",
       "              'Sydney Cricket <UNK>',\n",
       "              'Syria',\n",
       "              'TALLINN',\n",
       "              'TIRANA',\n",
       "              'TOKYO',\n",
       "              'TORONTO',\n",
       "              'Taiwan',\n",
       "              'Tasmania',\n",
       "              'Texas',\n",
       "              'Thailand',\n",
       "              'Tianjin',\n",
       "              'Timisoara',\n",
       "              'Tirana',\n",
       "              'Tokyo',\n",
       "              'Toronto',\n",
       "              'Turkey',\n",
       "              'U.S',\n",
       "              'U.S.',\n",
       "              'UAE',\n",
       "              'UK',\n",
       "              'US',\n",
       "              'Ukraine',\n",
       "              'United Arab Emirates',\n",
       "              'United Province',\n",
       "              'United States',\n",
       "              'Uruguay',\n",
       "              'VANCOUVER',\n",
       "              'VIENNA',\n",
       "              'Vancouver',\n",
       "              'Vatican',\n",
       "              'Venezuela',\n",
       "              'Victoria',\n",
       "              'Vietnam',\n",
       "              'WARSAW',\n",
       "              'WASHINGTON',\n",
       "              'WELLINGTON',\n",
       "              'WEST <UNK>',\n",
       "              'WINNIPEG',\n",
       "              'Wales',\n",
       "              'Wall St',\n",
       "              'Wall Street',\n",
       "              'Warsaw',\n",
       "              'Washington',\n",
       "              'Wellington',\n",
       "              'West Indies',\n",
       "              'White House',\n",
       "              'Wimbledon',\n",
       "              'Wis',\n",
       "              'Yorkshire',\n",
       "              'Yugoslavia',\n",
       "              'Zaire',\n",
       "              'Zambia',\n",
       "              'Zimbabwe'},\n",
       "             'PER': {'<UNK>',\n",
       "              '<UNK> <UNK>',\n",
       "              '<UNK> <UNK> <UNK>',\n",
       "              '<UNK> <UNK> Marken',\n",
       "              '<UNK> Abdullah <UNK>',\n",
       "              '<UNK> Ambrose',\n",
       "              '<UNK> Andersson',\n",
       "              '<UNK> Bell',\n",
       "              '<UNK> Brenden',\n",
       "              '<UNK> Brenner',\n",
       "              '<UNK> Brown',\n",
       "              '<UNK> Campbell',\n",
       "              '<UNK> Cooper',\n",
       "              '<UNK> Corini',\n",
       "              '<UNK> Dan',\n",
       "              '<UNK> Daniel',\n",
       "              '<UNK> Gross',\n",
       "              '<UNK> Harper',\n",
       "              '<UNK> Harrison',\n",
       "              '<UNK> Honda',\n",
       "              '<UNK> Huber',\n",
       "              '<UNK> Hussain',\n",
       "              '<UNK> Ion',\n",
       "              '<UNK> Kyoko',\n",
       "              '<UNK> Lloyd',\n",
       "              '<UNK> Marco',\n",
       "              '<UNK> Margit <UNK>',\n",
       "              '<UNK> Martin',\n",
       "              '<UNK> Matthew',\n",
       "              '<UNK> Note',\n",
       "              '<UNK> Pizzi',\n",
       "              '<UNK> Putra',\n",
       "              '<UNK> Rashid',\n",
       "              '<UNK> Sakti',\n",
       "              '<UNK> San',\n",
       "              '<UNK> San <UNK> <UNK>',\n",
       "              '<UNK> Sang <UNK>',\n",
       "              '<UNK> Schulz',\n",
       "              '<UNK> Street',\n",
       "              '<UNK> Tanaka',\n",
       "              '<UNK> Thompson',\n",
       "              '<UNK> Townsend',\n",
       "              '<UNK> Vaccari',\n",
       "              '<UNK> Weah',\n",
       "              '<UNK> da Silva',\n",
       "              '<UNK> de <UNK>',\n",
       "              '<UNK> van der',\n",
       "              '<UNK> van der Merwe',\n",
       "              'A. <UNK>',\n",
       "              'A. <UNK> <UNK>',\n",
       "              'Abdul Latif <UNK>',\n",
       "              'Abel <UNK>',\n",
       "              'Abu Ibrahim',\n",
       "              'Adams',\n",
       "              'Adnan Al <UNK>',\n",
       "              'Adrian Ilie',\n",
       "              'Ahmed <UNK>',\n",
       "              'Alan <UNK>',\n",
       "              'Alan Greenspan',\n",
       "              'Alan Shearer',\n",
       "              'Alatas',\n",
       "              'Albert',\n",
       "              'Aleksander Kwasniewski',\n",
       "              'Alessandro <UNK>',\n",
       "              'Alessandro Del <UNK>',\n",
       "              'Alexander <UNK>',\n",
       "              'Alexander Downer',\n",
       "              'Alexandra <UNK>',\n",
       "              'Alexandre <UNK>',\n",
       "              'Ali <UNK>',\n",
       "              'Ali Alatas',\n",
       "              'Allan <UNK>',\n",
       "              'Allan <UNK> <UNK>',\n",
       "              'Ally McCoist',\n",
       "              'Ambrose',\n",
       "              'Andrea <UNK>',\n",
       "              'Andreas <UNK>',\n",
       "              'Andrei <UNK>',\n",
       "              'Andrew',\n",
       "              'Andrew <UNK>',\n",
       "              'Andrew Park',\n",
       "              'Andy <UNK>',\n",
       "              'Anita <UNK>',\n",
       "              'Anke <UNK>',\n",
       "              'Ann <UNK>',\n",
       "              'Antoine <UNK>',\n",
       "              'Anton <UNK>',\n",
       "              'Antonio <UNK>',\n",
       "              'Antonio Folha',\n",
       "              'Arafat',\n",
       "              'Armando',\n",
       "              'Armando <UNK>',\n",
       "              'Artur <UNK>',\n",
       "              'B. Lara',\n",
       "              'B. Young',\n",
       "              'Barbara <UNK>',\n",
       "              'Benito <UNK>',\n",
       "              'Benjamin',\n",
       "              'Benjamin Netanyahu',\n",
       "              'Berisha',\n",
       "              'Bernd <UNK>',\n",
       "              'Bill Brett',\n",
       "              'Bill Clinton',\n",
       "              'Bill Jordan',\n",
       "              'Billy <UNK>',\n",
       "              'Bob <UNK>',\n",
       "              'Bob Woolmer',\n",
       "              'Bobby',\n",
       "              'Bode',\n",
       "              'Bogdan <UNK>',\n",
       "              'Bolger',\n",
       "              'Boris Yeltsin',\n",
       "              'Boutros Boutros-Ghali',\n",
       "              'Boutros-Ghali',\n",
       "              'Bradford Vaughan',\n",
       "              'Brenden',\n",
       "              'Brett <UNK>',\n",
       "              'Brian <UNK>',\n",
       "              'Brian Lara',\n",
       "              'Bruno <UNK>',\n",
       "              'C. <UNK>',\n",
       "              'C. Ambrose',\n",
       "              'C. Cairns',\n",
       "              'C. Harris',\n",
       "              'C. Hooper',\n",
       "              'C. Walsh',\n",
       "              'CHINA',\n",
       "              'COSTA',\n",
       "              'Cairns',\n",
       "              'Carl',\n",
       "              'Carl Hooper',\n",
       "              'Carlo <UNK>',\n",
       "              'Carlos <UNK>',\n",
       "              'Carlos Secretario',\n",
       "              'Caroline Olivier',\n",
       "              'Casey <UNK>',\n",
       "              'Catherine <UNK>',\n",
       "              'Charlton',\n",
       "              'Chen Gang',\n",
       "              'Chirac',\n",
       "              'Chris',\n",
       "              'Chris <UNK>',\n",
       "              'Christian <UNK>',\n",
       "              'Christophe <UNK>',\n",
       "              'Christopher <UNK>',\n",
       "              'Clarence Seedorf',\n",
       "              'Clarence Woolmer',\n",
       "              'Claude <UNK>',\n",
       "              'Clinton',\n",
       "              'Clinton <UNK>',\n",
       "              'Colin <UNK>',\n",
       "              'Consumer Project',\n",
       "              'Costa',\n",
       "              'Courtney Walsh',\n",
       "              'Craig <UNK>',\n",
       "              'Dan <UNK>',\n",
       "              'Dan Crowley',\n",
       "              'Daniel <UNK>',\n",
       "              'Daniel Herbert',\n",
       "              'Daniele <UNK>',\n",
       "              'Dariusz Rosati',\n",
       "              'Darren <UNK>',\n",
       "              'Darren Jackson',\n",
       "              'Dave <UNK>',\n",
       "              'David <UNK>',\n",
       "              'David Wilson',\n",
       "              'Davies',\n",
       "              'Davis Love',\n",
       "              'Dean <UNK>',\n",
       "              'Dean Jones',\n",
       "              'Dejan <UNK>',\n",
       "              'Dejan Savicevic',\n",
       "              'Dennis <UNK>',\n",
       "              'Derek da <UNK>',\n",
       "              'Des <UNK>',\n",
       "              'Desmond <UNK>',\n",
       "              'Dick Spring',\n",
       "              'Diego <UNK>',\n",
       "              'Dieter <UNK>',\n",
       "              'Dietmar <UNK>',\n",
       "              'Dimas',\n",
       "              'Dimas Teixeira',\n",
       "              'Dirk <UNK>',\n",
       "              'Don <UNK>',\n",
       "              'Donna <UNK>',\n",
       "              'Donna Andrews',\n",
       "              'Doug Young',\n",
       "              'Edna Fernandes',\n",
       "              'Eduardo <UNK>',\n",
       "              'Elena <UNK>',\n",
       "              'Enrique',\n",
       "              'Eric <UNK>',\n",
       "              'Erwin Arnold',\n",
       "              'Eugene Morris',\n",
       "              'Evelyn Leopold',\n",
       "              'Eyles',\n",
       "              'Fabio <UNK>',\n",
       "              'Fabrizio Ravanelli',\n",
       "              'Ferguson',\n",
       "              'Fernando <UNK>',\n",
       "              'Fernando Couto',\n",
       "              'Ferrer',\n",
       "              'Filippo <UNK>',\n",
       "              'Florence <UNK>',\n",
       "              'Francesco <UNK>',\n",
       "              'Francis <UNK>',\n",
       "              'Franco <UNK> <UNK>',\n",
       "              'Fraser',\n",
       "              'Frederick',\n",
       "              'Fung Permadi',\n",
       "              'G. <UNK>',\n",
       "              'Garrett',\n",
       "              'Garrett Hines',\n",
       "              'Garry <UNK>',\n",
       "              'Gary <UNK>',\n",
       "              'Geoff Marsh',\n",
       "              'George <UNK>',\n",
       "              'George Weah',\n",
       "              'Gerard Van Velde',\n",
       "              'Gheorghe',\n",
       "              'Gheorghe <UNK>',\n",
       "              'Gianfranco <UNK>',\n",
       "              'Gianluca <UNK>',\n",
       "              'Gianluca Vialli',\n",
       "              'Gilbert Le Gras',\n",
       "              'Giovanni',\n",
       "              'Giuseppe <UNK>',\n",
       "              'Glen <UNK>',\n",
       "              'Glenn <UNK>',\n",
       "              'Glenn McGrath',\n",
       "              'God',\n",
       "              'Gong <UNK>',\n",
       "              'Gong Zhichao',\n",
       "              'Goran Ivanisevic',\n",
       "              'Greenspan',\n",
       "              'Greg <UNK>',\n",
       "              'Greg Reid',\n",
       "              'Guillermo',\n",
       "              'Guy Whittingham',\n",
       "              'Hamid <UNK>',\n",
       "              'Hannes <UNK>',\n",
       "              'Harper',\n",
       "              'Harper Williams',\n",
       "              'Harris',\n",
       "              'Hassan Abbas',\n",
       "              'Hassan Ahmed',\n",
       "              'Havel',\n",
       "              'Healy',\n",
       "              'Helder Cristovao',\n",
       "              'Helmut Kohl',\n",
       "              'Hermawan Susanto',\n",
       "              'Hilary <UNK>',\n",
       "              'Hines',\n",
       "              'Hooper',\n",
       "              'Hosni Mubarak',\n",
       "              'Hu Zhilan',\n",
       "              'Hubert <UNK>',\n",
       "              'Hwang Sun Hong',\n",
       "              'I. Healy',\n",
       "              'Ian <UNK>',\n",
       "              'Ian Harvey',\n",
       "              'Ian Healy',\n",
       "              'Ian Jones',\n",
       "              'Ian Wright',\n",
       "              'Ijaz Ahmad',\n",
       "              'Indra',\n",
       "              'Indra Wijaya',\n",
       "              'Ivan <UNK>',\n",
       "              'Ivan de',\n",
       "              'J. <UNK>',\n",
       "              'J. Adams',\n",
       "              'J. Murray',\n",
       "              'J. Vaughan',\n",
       "              'Jack Charlton',\n",
       "              'Jackson',\n",
       "              'Jacques <UNK>',\n",
       "              'Jacques Chirac',\n",
       "              'James Love',\n",
       "              'Jan <UNK>',\n",
       "              'Jared <UNK>',\n",
       "              'Jason <UNK>',\n",
       "              'Jason Little',\n",
       "              'Javier <UNK>',\n",
       "              'Jean van <UNK>',\n",
       "              'Jeff <UNK>',\n",
       "              'Jeremy <UNK>',\n",
       "              'Jim <UNK>',\n",
       "              'Jim Bolger',\n",
       "              'Jim Courier',\n",
       "              'Jimmy Adams',\n",
       "              'Jiri <UNK>',\n",
       "              'Joao <UNK>',\n",
       "              'Joao Manuel Pinto',\n",
       "              'Joao Vieira Pinto',\n",
       "              'Joe <UNK>',\n",
       "              'John <UNK>',\n",
       "              'John <UNK> <UNK>',\n",
       "              'John Lewis',\n",
       "              'John Major',\n",
       "              'John Mills',\n",
       "              'John Paul',\n",
       "              'Jonathan Wright',\n",
       "              'Jones',\n",
       "              'Jordan',\n",
       "              'Jorge Cadete',\n",
       "              'Jorge Costa',\n",
       "              'Jose <UNK>',\n",
       "              'Jose <UNK> <UNK>',\n",
       "              'Jose Barroso',\n",
       "              'Jose Luis <UNK>',\n",
       "              'Josef <UNK>',\n",
       "              'Joseph <UNK>',\n",
       "              'Juan <UNK>',\n",
       "              'Juan Pizzi',\n",
       "              'Junior Murray',\n",
       "              'Justin',\n",
       "              'Justin <UNK>',\n",
       "              'K. Benjamin',\n",
       "              'Karin <UNK>',\n",
       "              'Kate Pace Lindsay',\n",
       "              'Kennedy',\n",
       "              'Kenneth <UNK>',\n",
       "              'Kenneth Benjamin',\n",
       "              'Khaled <UNK>',\n",
       "              'Kim <UNK>',\n",
       "              'Kim <UNK> <UNK>',\n",
       "              'Kim Do <UNK>',\n",
       "              'Kirsten',\n",
       "              'Klaus',\n",
       "              'Kohl',\n",
       "              'Kristie Marshall',\n",
       "              'Kwasniewski',\n",
       "              'L. <UNK>',\n",
       "              'LITTLE',\n",
       "              'Lara',\n",
       "              'Laurent <UNK>',\n",
       "              'Lee <UNK>',\n",
       "              'Lee Young <UNK>',\n",
       "              'Les Ferdinand',\n",
       "              'Little',\n",
       "              'Lloyd',\n",
       "              'Lorenzo <UNK>',\n",
       "              'Luc Nilis',\n",
       "              'Luis',\n",
       "              'Luis <UNK>',\n",
       "              'Luis Figo',\n",
       "              'M. Bevan',\n",
       "              'M. Taylor',\n",
       "              'M. Wasim',\n",
       "              'M. Waugh',\n",
       "              'Major',\n",
       "              'Marc <UNK>',\n",
       "              'Marcelo',\n",
       "              'Marcelo <UNK>',\n",
       "              'Marcin <UNK>',\n",
       "              'Marco <UNK>',\n",
       "              'Marcus <UNK>',\n",
       "              'Margaret <UNK>',\n",
       "              'Marianne <UNK>',\n",
       "              'Mario <UNK>',\n",
       "              'Mark',\n",
       "              'Mark <UNK>',\n",
       "              'Mark Cairns',\n",
       "              'Mark McNulty',\n",
       "              'Mark Taylor',\n",
       "              'Mark Waugh',\n",
       "              'Mark Woodforde',\n",
       "              'Marshall',\n",
       "              'Marshall <UNK>',\n",
       "              'Martin <UNK> Hansen',\n",
       "              'Martina <UNK>',\n",
       "              'Matthew',\n",
       "              'Matthew <UNK>',\n",
       "              'Matthew Le <UNK>',\n",
       "              'McCoist',\n",
       "              'Merwe',\n",
       "              'Mia <UNK>',\n",
       "              'Michael <UNK>',\n",
       "              'Michael Bevan',\n",
       "              'Michael Frederick',\n",
       "              'Michel <UNK>',\n",
       "              'Mickey <UNK>',\n",
       "              'Miguel <UNK>',\n",
       "              'Mike <UNK>',\n",
       "              'Mike McCurry',\n",
       "              'Milan <UNK>',\n",
       "              'Miller',\n",
       "              'Mills',\n",
       "              'Miriam <UNK>',\n",
       "              'Mohamed <UNK>',\n",
       "              'Mohammed',\n",
       "              'Mohammed <UNK>',\n",
       "              'Mohammed Rashid',\n",
       "              'Moin Khan',\n",
       "              'Moody',\n",
       "              'Morris',\n",
       "              'Mr <UNK>',\n",
       "              'Mubarak',\n",
       "              'Mulder',\n",
       "              'Murray',\n",
       "              'Mushtaq Ahmad',\n",
       "              'N. <UNK>',\n",
       "              'Nabil Abu Rdainah',\n",
       "              'Neil <UNK>',\n",
       "              'Nelson Mandela',\n",
       "              'Nestor <UNK>',\n",
       "              'Netanyahu',\n",
       "              'Nicholas <UNK>',\n",
       "              'Nick <UNK>',\n",
       "              'Nick Price',\n",
       "              'Nicol',\n",
       "              'Nicola <UNK>',\n",
       "              'Nigel Walker',\n",
       "              'Nixon <UNK>',\n",
       "              'Norm <UNK>',\n",
       "              'Note',\n",
       "              'Oceano Cruz',\n",
       "              'Oksana <UNK>',\n",
       "              'Olga <UNK>',\n",
       "              'Oliver Bierhoff',\n",
       "              'Ong Ewe Hock',\n",
       "              'Orlando Pace',\n",
       "              'Oscar <UNK>',\n",
       "              'Oscar Luigi <UNK>',\n",
       "              'P. Reiffel',\n",
       "              'PT <UNK> Duta',\n",
       "              'Pace',\n",
       "              'Pat <UNK>',\n",
       "              'Pat Howard',\n",
       "              'Patrick Vieira',\n",
       "              'Paul <UNK>',\n",
       "              'Paul Gascoigne',\n",
       "              'Paul Justin',\n",
       "              'Paul Reiffel',\n",
       "              'Paul Wright',\n",
       "              'Paulinho Santos',\n",
       "              'Paulo <UNK>',\n",
       "              'Pavel <UNK>',\n",
       "              'Peres',\n",
       "              'Peter <UNK>',\n",
       "              'Peter Nicol',\n",
       "              'Peter van <UNK>',\n",
       "              'Peters',\n",
       "              'Petra <UNK>',\n",
       "              'Phil Gray',\n",
       "              'Philippe <UNK>',\n",
       "              'Pierre <UNK>',\n",
       "              'Pierre Van <UNK>',\n",
       "              'Quentin <UNK>',\n",
       "              'R. <UNK>',\n",
       "              'R. Kennedy',\n",
       "              'R. Ponting',\n",
       "              'Rafael <UNK>',\n",
       "              'Ramon Vega',\n",
       "              'Randy Jones',\n",
       "              'Raphael <UNK>',\n",
       "              'Rashid',\n",
       "              'Rashid <UNK>',\n",
       "              'Raul Gonzalez',\n",
       "              'Ray <UNK>',\n",
       "              'Rdainah',\n",
       "              'Regina <UNK>',\n",
       "              'Reiffel',\n",
       "              'Richard <UNK>',\n",
       "              'Ricky <UNK>',\n",
       "              'Ricky Ponting',\n",
       "              'Rob <UNK>',\n",
       "              'Rob Andrew',\n",
       "              'Robbie <UNK>',\n",
       "              'Robbie Fowler',\n",
       "              'Robert',\n",
       "              'Robert <UNK>',\n",
       "              'Robert Mugabe',\n",
       "              'Roberto <UNK>',\n",
       "              'Roberto Baggio',\n",
       "              'Roberto Carlos',\n",
       "              'Rodney Eyles',\n",
       "              'Roger <UNK>',\n",
       "              'Roger Garcia',\n",
       "              'Ron Ellis',\n",
       "              'Ronaldo',\n",
       "              'Ronny <UNK>',\n",
       "              'Rosati',\n",
       "              'Rosemary Bennett',\n",
       "              'Ross',\n",
       "              'Rubin',\n",
       "              'Rudi <UNK>',\n",
       "              'Rui Barros',\n",
       "              'Rui Correia',\n",
       "              'Rui Costa',\n",
       "              'Ryan Johnson',\n",
       "              'S. <UNK>',\n",
       "              'S. Campbell',\n",
       "              'S. Fleming',\n",
       "              'S. Law',\n",
       "              'Saeed Anwar',\n",
       "              'Saint Nicholas',\n",
       "              'Sali Berisha',\n",
       "              'Salim Malik',\n",
       "              'Sam Payne',\n",
       "              'Sammy <UNK>',\n",
       "              'Santa',\n",
       "              'Santa Claus',\n",
       "              'Saqlain',\n",
       "              'Saqlain Mushtaq',\n",
       "              'Scott <UNK>',\n",
       "              'Scott McCarron',\n",
       "              'Sean <UNK>',\n",
       "              'Sebastien <UNK>',\n",
       "              'Sergey <UNK>',\n",
       "              'Sergi Barjuan',\n",
       "              'Sergio <UNK>',\n",
       "              'Shahid <UNK>',\n",
       "              'Shane <UNK>',\n",
       "              'Shaun Young',\n",
       "              'Shimon Peres',\n",
       "              'Simon Parke',\n",
       "              'Sokol <UNK>',\n",
       "              'Sophia Loren',\n",
       "              'Soren B. Nielsen',\n",
       "              'Stefano <UNK>',\n",
       "              'Stephen <UNK>',\n",
       "              'Stephen Nisbet',\n",
       "              'Steve <UNK>',\n",
       "              'Steve McManaman',\n",
       "              'Steve van <UNK>',\n",
       "              'Steven <UNK>',\n",
       "              'Stuart Law',\n",
       "              'Suharto',\n",
       "              'Sun Jun',\n",
       "              'Sutton',\n",
       "              'Sven <UNK>',\n",
       "              'Svetlana <UNK>',\n",
       "              'T. Moody',\n",
       "              'Tan',\n",
       "              'Tan Kong <UNK>',\n",
       "              'Thomas <UNK>',\n",
       "              'Thomas Stuer-Lauridsen',\n",
       "              'Tiger <UNK>',\n",
       "              'Tim <UNK>',\n",
       "              'Tim Casey',\n",
       "              'Tim Gavin',\n",
       "              'Tom Moody',\n",
       "              'Tony',\n",
       "              'Tony <UNK>',\n",
       "              'Tony Adams',\n",
       "              'Tony Underwood',\n",
       "              'Townsend',\n",
       "              'Troy Benson',\n",
       "              'Troy Vincent',\n",
       "              'Umar',\n",
       "              'Umar Said',\n",
       "              'Umberto Bossi',\n",
       "              'Vaclav Havel',\n",
       "              'Vaclav Klaus',\n",
       "              'Valentin Stefan',\n",
       "              'Van <UNK>',\n",
       "              'Van der <UNK>',\n",
       "              'Vaughan',\n",
       "              'Vialli',\n",
       "              'Victor Sanchez',\n",
       "              'Vieira',\n",
       "              'Viktor <UNK>',\n",
       "              'Vince Lombardi',\n",
       "              'Vitor Baia',\n",
       "              'Vladimir <UNK>',\n",
       "              'Walsh',\n",
       "              'Walter <UNK>',\n",
       "              'Wang Chen',\n",
       "              'Waqar',\n",
       "              'Waqar Younis',\n",
       "              'Wasim',\n",
       "              'Wasim Akram',\n",
       "              'Weah',\n",
       "              'Whittingham',\n",
       "              'Wijaya',\n",
       "              'William Hill',\n",
       "              'Winston Peters',\n",
       "              'Woolmer',\n",
       "              'Wright',\n",
       "              'Yasser Arafat',\n",
       "              'Yeltsin',\n",
       "              'Yevgeny Kafelnikov',\n",
       "              'Young',\n",
       "              'Zeljko Petrovic',\n",
       "              'Zoran <UNK>'},\n",
       "             'MISC': {'<NUM> World Cup',\n",
       "              '<UNK>',\n",
       "              \"<UNK> 's Cup\",\n",
       "              '<UNK> <NUM>',\n",
       "              '<UNK> <UNK>',\n",
       "              '<UNK> A',\n",
       "              '<UNK> Africa',\n",
       "              '<UNK> American',\n",
       "              '<UNK> CLASSIC',\n",
       "              '<UNK> CUP',\n",
       "              '<UNK> Classic',\n",
       "              '<UNK> Convention',\n",
       "              '<UNK> Cup',\n",
       "              '<UNK> Day',\n",
       "              '<UNK> I',\n",
       "              '<UNK> INTERNATIONAL',\n",
       "              '<UNK> Indies',\n",
       "              '<UNK> International',\n",
       "              '<UNK> Queen',\n",
       "              '<UNK> STATE',\n",
       "              '<UNK> Trophy',\n",
       "              'ADRs',\n",
       "              \"AFRICAN CUP WINNERS ' CUP\",\n",
       "              'AMERICAN',\n",
       "              'African',\n",
       "              \"African Cup Winners ' Cup\",\n",
       "              'Africans',\n",
       "              'Albanian',\n",
       "              'Algerian',\n",
       "              'Algerians',\n",
       "              'American',\n",
       "              'Americans',\n",
       "              'Arabic',\n",
       "              'Argentine',\n",
       "              'Asia <UNK> Markets meeting',\n",
       "              'Asian',\n",
       "              'Asian Cup',\n",
       "              'Asian Games',\n",
       "              'Australian',\n",
       "              'Australian Capital <UNK>',\n",
       "              'Austrian',\n",
       "              'BRAZILIAN',\n",
       "              'Bangkok',\n",
       "              'Basque',\n",
       "              'Belgian',\n",
       "              'Brazilian',\n",
       "              'British',\n",
       "              'British <UNK>',\n",
       "              'Bulgarian',\n",
       "              'Burmese',\n",
       "              'But',\n",
       "              'C$',\n",
       "              'CENTRAL DIVISION',\n",
       "              'CZECH',\n",
       "              'Cambodian',\n",
       "              'Canadian',\n",
       "              'Canadians',\n",
       "              \"Champions ' League\",\n",
       "              'Chilean',\n",
       "              'Chinese',\n",
       "              'Christian',\n",
       "              'Christians',\n",
       "              'Communist',\n",
       "              'Conservative',\n",
       "              'Croat',\n",
       "              'Croatian',\n",
       "              'Cup',\n",
       "              'DAX',\n",
       "              'DUTCH',\n",
       "              'Democratic Convention',\n",
       "              'Dow',\n",
       "              'Dubai',\n",
       "              'Dutch',\n",
       "              'ENGLISH',\n",
       "              'ENGLISH F.A. CUP',\n",
       "              'East <UNK>',\n",
       "              'Egyptian',\n",
       "              'English',\n",
       "              'English F.A. Challenge',\n",
       "              'Englishman',\n",
       "              'Estonian',\n",
       "              'Euro',\n",
       "              'European',\n",
       "              \"European Champions ' League\",\n",
       "              'European Cup',\n",
       "              'F.A. Challenge Cup',\n",
       "              'FRENCH',\n",
       "              'French',\n",
       "              'Frenchman',\n",
       "              'Full <UNK>',\n",
       "              'GERMAN',\n",
       "              'GMT',\n",
       "              'GRAND SLAM CUP',\n",
       "              'General Agreement on <UNK> and Trade',\n",
       "              'German',\n",
       "              'German <UNK>',\n",
       "              'Grand Slam Cup',\n",
       "              'Greek',\n",
       "              'Hindu',\n",
       "              'Honda <UNK>',\n",
       "              'Hungarian',\n",
       "              'ISRAELI',\n",
       "              'ITALIAN',\n",
       "              'Indian',\n",
       "              'Indonesian',\n",
       "              'Internet',\n",
       "              'Iran <UNK>',\n",
       "              'Irish',\n",
       "              'Islam',\n",
       "              'Israeli',\n",
       "              'Israelis',\n",
       "              'Italian',\n",
       "              'Italians',\n",
       "              'Japanese',\n",
       "              'Jewish',\n",
       "              'Jews',\n",
       "              'Jones',\n",
       "              'King <UNK>',\n",
       "              'Korean',\n",
       "              'Kurd',\n",
       "              'Kurdish',\n",
       "              'LOMBARDI <UNK>',\n",
       "              'Lebanese',\n",
       "              'Liberian',\n",
       "              'Lombardi <UNK>',\n",
       "              'Mauritian',\n",
       "              'Mexican',\n",
       "              'Montenegrin',\n",
       "              'Moroccan',\n",
       "              'Moslem',\n",
       "              'Moslems',\n",
       "              'NYC',\n",
       "              'NYMEX <UNK>',\n",
       "              'Nazi',\n",
       "              'Nobel',\n",
       "              'Nobel Peace Prize',\n",
       "              'Norwegian',\n",
       "              'Olympic',\n",
       "              'Palestinian',\n",
       "              'Palestinians',\n",
       "              'Polish',\n",
       "              'Portuguese',\n",
       "              'Premier league',\n",
       "              'Princess of <UNK>',\n",
       "              'Real <UNK>',\n",
       "              'Roman',\n",
       "              'Roman Catholic',\n",
       "              'Rose Bowl',\n",
       "              'Royal <UNK>',\n",
       "              'Russian',\n",
       "              'Rwandan',\n",
       "              'SCOTTISH',\n",
       "              'SCOTTISH PREMIER DIVISION',\n",
       "              'SHEFFIELD <UNK>',\n",
       "              'SPANISH',\n",
       "              'SWISS',\n",
       "              'Scottish',\n",
       "              'Scottish Cup',\n",
       "              'Scottish premier',\n",
       "              'Sheffield <UNK>',\n",
       "              'Slovak',\n",
       "              'Social Democrats',\n",
       "              'South African',\n",
       "              'South Korean',\n",
       "              'Soviet',\n",
       "              'Spanish',\n",
       "              'Super G',\n",
       "              'Swede',\n",
       "              'Swiss',\n",
       "              'Syrian',\n",
       "              'Syrians',\n",
       "              'Thai',\n",
       "              'Thai <UNK>',\n",
       "              'Treasuries',\n",
       "              'Turkish',\n",
       "              'Tutsi',\n",
       "              'U.S.-based',\n",
       "              'UEFA <UNK>',\n",
       "              'UEFA Cup',\n",
       "              'US$',\n",
       "              'Uruguayan',\n",
       "              'WORLD CUP',\n",
       "              'WORLD GRAND PRIX',\n",
       "              'WORLD SERIES',\n",
       "              'Warsaw <UNK>',\n",
       "              'Welsh',\n",
       "              'Winter Olympics',\n",
       "              'World Championships',\n",
       "              'World Cup',\n",
       "              'World Grand Prix',\n",
       "              'World Open',\n",
       "              'World Series',\n",
       "              'World War Two',\n",
       "              'World cup',\n",
       "              'Yugoslav',\n",
       "              'ZIMBABWE OPEN',\n",
       "              'Zairean',\n",
       "              'Zimbabwe Open'},\n",
       "             'ORG': {'1. FC Cologne',\n",
       "              '<NUM> Munich',\n",
       "              '<UNK>',\n",
       "              \"<UNK> 's\",\n",
       "              '<UNK> ( Rangoon ) University',\n",
       "              '<UNK> <UNK>',\n",
       "              '<UNK> <UNK> <UNK>',\n",
       "              '<UNK> <UNK> <UNK> <UNK> SA',\n",
       "              '<UNK> <UNK> Hospital',\n",
       "              '<UNK> <UNK> Inc',\n",
       "              '<UNK> <UNK> Ltd',\n",
       "              '<UNK> <UNK> Party',\n",
       "              '<UNK> <UNK> Sport',\n",
       "              '<UNK> <UNK> and Co Inc',\n",
       "              '<UNK> AG',\n",
       "              '<UNK> Bank',\n",
       "              '<UNK> Bay',\n",
       "              '<UNK> Bilbao',\n",
       "              '<UNK> Board',\n",
       "              '<UNK> Board of India',\n",
       "              '<UNK> Bologna',\n",
       "              '<UNK> City',\n",
       "              '<UNK> Club',\n",
       "              '<UNK> Co Ltd',\n",
       "              '<UNK> Communications Corporation',\n",
       "              '<UNK> Company <UNK>',\n",
       "              '<UNK> Data',\n",
       "              '<UNK> Data Systems',\n",
       "              '<UNK> Freedom Party',\n",
       "              '<UNK> GIANTS',\n",
       "              '<UNK> Group',\n",
       "              '<UNK> Hanover',\n",
       "              '<UNK> Institute of Technology',\n",
       "              '<UNK> MADRID',\n",
       "              '<UNK> Marketing & <UNK> Inc',\n",
       "              '<UNK> Milan',\n",
       "              '<UNK> Minerals Ltd',\n",
       "              '<UNK> Mining Co',\n",
       "              '<UNK> Mining Corp',\n",
       "              '<UNK> NV',\n",
       "              '<UNK> Nickel',\n",
       "              '<UNK> Plus',\n",
       "              '<UNK> ROMANIA',\n",
       "              '<UNK> STATE',\n",
       "              '<UNK> SV',\n",
       "              '<UNK> Telegraph and <UNK> Corp',\n",
       "              '<UNK> Town',\n",
       "              '<UNK> Trust & Banking Co',\n",
       "              '<UNK> Vale',\n",
       "              '<UNK> Wood',\n",
       "              '<UNK> Workers Group',\n",
       "              '<UNK> Zagreb',\n",
       "              '<UNK> and <UNK>',\n",
       "              '<UNK> and <UNK> Commission',\n",
       "              '<UNK> of the <UNK>',\n",
       "              'AA',\n",
       "              'AC Milan',\n",
       "              'AMR Corp.',\n",
       "              'ANC',\n",
       "              'AS Roma',\n",
       "              'ATLANTA',\n",
       "              'AZ Alkmaar',\n",
       "              'Aberdeen',\n",
       "              'Action <UNK> Cos Inc',\n",
       "              'African National Congress',\n",
       "              'Airdrieonians',\n",
       "              'Ajax',\n",
       "              'Ajax Amsterdam',\n",
       "              'Alba Berlin',\n",
       "              'Albanian Football Association',\n",
       "              'Albion',\n",
       "              'All Black',\n",
       "              'Alloa',\n",
       "              'American',\n",
       "              'American <UNK> Medical Association',\n",
       "              'American Airlines',\n",
       "              'Antwerp',\n",
       "              'Arab <UNK>',\n",
       "              'Arbroath',\n",
       "              'Arizona',\n",
       "              'Arizona State',\n",
       "              'Arminia Bielefeld',\n",
       "              'Arsenal',\n",
       "              'Association',\n",
       "              'Association of <UNK> Asian Nations',\n",
       "              'Aston',\n",
       "              'Aston Villa',\n",
       "              'Atalanta',\n",
       "              'Atletico Madrid',\n",
       "              'Atletico Mineiro',\n",
       "              'Austria I',\n",
       "              'Austria III',\n",
       "              'Auxerre',\n",
       "              'Ayr',\n",
       "              'BA',\n",
       "              'BALTIMORE',\n",
       "              'BARCELONA',\n",
       "              'BBC',\n",
       "              'BOJ',\n",
       "              'BOSTON',\n",
       "              'Bank of Japan',\n",
       "              'Barcelona',\n",
       "              'Barnet',\n",
       "              'Barnsley',\n",
       "              'Barrick',\n",
       "              'Barrick Gold Corp',\n",
       "              'Basketball Association',\n",
       "              'Bastia',\n",
       "              'Bath',\n",
       "              'Bayer Leverkusen',\n",
       "              'Bayern Munich',\n",
       "              'Benfica',\n",
       "              'Berwick',\n",
       "              'Betar Jerusalem',\n",
       "              'Birmingham',\n",
       "              'Blackburn',\n",
       "              'Blackpool',\n",
       "              'Bochum',\n",
       "              'Bologna',\n",
       "              'Bolton',\n",
       "              'Bordeaux',\n",
       "              'Borussia <UNK>',\n",
       "              'Borussia Dortmund',\n",
       "              'Boston',\n",
       "              'Bournemouth',\n",
       "              'Bradford',\n",
       "              'Braga',\n",
       "              'Brazilian <UNK> <UNK> Society',\n",
       "              'Brechin',\n",
       "              'Brentford',\n",
       "              'Brighton',\n",
       "              'Bristol',\n",
       "              'Bristol City',\n",
       "              'Bristol Rovers',\n",
       "              'Britain I',\n",
       "              'British Airways',\n",
       "              'British Airways Plc',\n",
       "              'Brussels Newsroom',\n",
       "              'Bucharest Newsroom',\n",
       "              'Buenos Aires Newsroom',\n",
       "              'Buffalo',\n",
       "              'Buffalo <UNK>',\n",
       "              'Bundesbank',\n",
       "              'Burnley',\n",
       "              'Bury',\n",
       "              'CALGARY',\n",
       "              'CBOT',\n",
       "              'CHICAGO',\n",
       "              'CINCINNATI',\n",
       "              'CLEVELAND',\n",
       "              'COLORADO',\n",
       "              'CSKA Moscow',\n",
       "              'Cabinet',\n",
       "              'Caen',\n",
       "              'Cagliari',\n",
       "              'Cambridge',\n",
       "              'Cambridge United',\n",
       "              'Canada I',\n",
       "              'Canadian Grain Commission',\n",
       "              'Canadian Wheat Board',\n",
       "              'Cannes',\n",
       "              'Cardiff',\n",
       "              'Carlisle',\n",
       "              'Catholic Church',\n",
       "              'Celtic',\n",
       "              'Celtic Glasgow',\n",
       "              'Chamber',\n",
       "              'Chamber of <UNK>',\n",
       "              'Charleroi',\n",
       "              'Charlton',\n",
       "              'Chelsea',\n",
       "              'Chester',\n",
       "              'Chesterfield',\n",
       "              'Chicago Board of Trade',\n",
       "              'Chicago Newsdesk',\n",
       "              'China Steel',\n",
       "              'Civil Aviation Administration of China',\n",
       "              'Civil Aviation Authority',\n",
       "              'Cleveland',\n",
       "              'Clyde',\n",
       "              'Clydebank',\n",
       "              'Colchester',\n",
       "              'Commerce Ministry',\n",
       "              'Commission',\n",
       "              'Communications and Transportation Ministry',\n",
       "              'Coventry',\n",
       "              'Cowdenbeath',\n",
       "              'Credit Suisse',\n",
       "              'Crewe',\n",
       "              'Crystal Palace',\n",
       "              'Czech <UNK> Democratic Party',\n",
       "              'Czech Republic I',\n",
       "              'DALLAS',\n",
       "              'DENVER',\n",
       "              'DETROIT',\n",
       "              'Dallas <UNK>',\n",
       "              'Darlington',\n",
       "              'De Graafschap Doetinchem',\n",
       "              'Democratic <UNK> Alliance',\n",
       "              'Department of <UNK>',\n",
       "              'Department of Transport',\n",
       "              'Deportivo <UNK>',\n",
       "              'Derby',\n",
       "              'Doetinchem',\n",
       "              'Doncaster',\n",
       "              'Duma',\n",
       "              'Dumbarton',\n",
       "              'Dundee',\n",
       "              'Dundee United',\n",
       "              'Dunfermline',\n",
       "              'Dynamo Moscow',\n",
       "              'EPA',\n",
       "              'ETA',\n",
       "              'EU',\n",
       "              'East',\n",
       "              'East Fife',\n",
       "              'East Stirling',\n",
       "              'Economic Planning Agency',\n",
       "              'El Mundo',\n",
       "              'Elf',\n",
       "              'Estudiantes',\n",
       "              'Estudiantes Madrid',\n",
       "              'European Commission',\n",
       "              'European Union',\n",
       "              'Everton',\n",
       "              'Exeter',\n",
       "              'FBI',\n",
       "              'FC Hansa Rostock',\n",
       "              'FC St. Pauli',\n",
       "              'FDP',\n",
       "              'FIFA',\n",
       "              'FLORIDA',\n",
       "              'FSA',\n",
       "              'Falkirk',\n",
       "              'Fed',\n",
       "              'Federal Reserve',\n",
       "              'Feyenoord',\n",
       "              'Fife',\n",
       "              'Finance',\n",
       "              'Finance Ministry',\n",
       "              'Fiorentina',\n",
       "              'First Union Capital Markets Corp.',\n",
       "              'Florida Supreme Court',\n",
       "              'Foreign Affairs',\n",
       "              'Foreign Affairs Department',\n",
       "              'Foreign Ministry',\n",
       "              'Forfar',\n",
       "              'Fortuna <UNK>',\n",
       "              'Fortuna Sittard',\n",
       "              'Frankfurt Newsroom',\n",
       "              'Freiburg',\n",
       "              'Fulham',\n",
       "              'Galatasaray',\n",
       "              'General Administration of Customs',\n",
       "              'General Assembly',\n",
       "              'Genoa',\n",
       "              'German I',\n",
       "              'Germany III',\n",
       "              'Gillingham',\n",
       "              'Glentoran',\n",
       "              'Goias',\n",
       "              'Goldman , Sachs',\n",
       "              'Graafschap Doetinchem',\n",
       "              'Green Bay <UNK>',\n",
       "              'Greenock Morton',\n",
       "              'Gremio',\n",
       "              'Grimsby',\n",
       "              'Groningen',\n",
       "              'Guingamp',\n",
       "              'HOUSTON',\n",
       "              'Hamilton',\n",
       "              'Hansa Rostock',\n",
       "              'Hapoel <UNK>',\n",
       "              \"Hapoel Beit She'an\",\n",
       "              'Hapoel Haifa',\n",
       "              'Hapoel Jerusalem',\n",
       "              'Hapoel Kfar Sava',\n",
       "              'Hapoel Petah Tikva',\n",
       "              'Hapoel Taibe',\n",
       "              'Hapoel Tel Aviv',\n",
       "              'Hartlepool',\n",
       "              'Hearts',\n",
       "              'Heerenveen',\n",
       "              'Hereford',\n",
       "              'Hibernian',\n",
       "              'Honda',\n",
       "              'Honda Motor Co Ltd',\n",
       "              'House of Commons',\n",
       "              'House of Representatives',\n",
       "              'Huddersfield',\n",
       "              'Hull',\n",
       "              'Hungarian Democratic Union',\n",
       "              'Hyundai Heavy',\n",
       "              'Indiana',\n",
       "              'Indianapolis <UNK>',\n",
       "              'Indonesian Mines and Energy Ministry',\n",
       "              'Information Technology Association of America',\n",
       "              'Institute of <UNK> Studies',\n",
       "              'Inter',\n",
       "              'Interfax',\n",
       "              'International <UNK> Federation',\n",
       "              'International Bonds',\n",
       "              'International Confederation of Free Trade <UNK>',\n",
       "              'International Finance Bureau',\n",
       "              'International Labour Organisation',\n",
       "              'International Monetary Fund',\n",
       "              'Internazionale',\n",
       "              'Inverness <UNK>',\n",
       "              'Ipswich',\n",
       "              'Irish Republican Army',\n",
       "              'Ironi Rishon',\n",
       "              'Ironi Rishon Lezion',\n",
       "              'Italy I',\n",
       "              'Itar-Tass',\n",
       "              'JACKSONVILLE',\n",
       "              'John Lewis UK',\n",
       "              'Juventus',\n",
       "              'KANSAS CITY',\n",
       "              'Karlsruhe',\n",
       "              'Kilmarnock',\n",
       "              'Kurdistan Workers Party',\n",
       "              'LA <UNK>',\n",
       "              'LEEDS',\n",
       "              'LOS ANGELES',\n",
       "              'La <UNK>',\n",
       "              'Labour',\n",
       "              'Lazio',\n",
       "              'Le Havre',\n",
       "              'League',\n",
       "              'Lech',\n",
       "              'Leeds',\n",
       "              'Leeds United',\n",
       "              'Leicester',\n",
       "              'Lens',\n",
       "              'Leyton Orient',\n",
       "              'Lille',\n",
       "              'Lincoln',\n",
       "              'Liverpool',\n",
       "              'Livingston',\n",
       "              'Ljubljana',\n",
       "              'Lloyds Shipping',\n",
       "              'London Irish',\n",
       "              'London Newsroom',\n",
       "              'London Stock Exchange',\n",
       "              'Luton',\n",
       "              'Lyon',\n",
       "              'MANCHESTER UNITED',\n",
       "              'MIAMI',\n",
       "              'MILWAUKEE',\n",
       "              'MINNESOTA',\n",
       "              'MONTREAL',\n",
       "              \"MOODY 'S\",\n",
       "              'MSV Duisburg',\n",
       "              'Maccabi Haifa',\n",
       "              'Maccabi Herzliya',\n",
       "              'Maccabi Petah Tikva',\n",
       "              'Maccabi Tel Aviv',\n",
       "              'Manchester City',\n",
       "              'Manchester United',\n",
       "              'Manitoba',\n",
       "              'Manitoba Pork',\n",
       "              'Mansfield',\n",
       "              'Marseille',\n",
       "              'Metz',\n",
       "              'Miami <UNK>',\n",
       "              'Middlesbrough',\n",
       "              'Milan',\n",
       "              'Millwall',\n",
       "              'Mines and Energy Ministry',\n",
       "              'Minnesota',\n",
       "              'Monaco',\n",
       "              'Montpellier',\n",
       "              'Montreal',\n",
       "              'Montrose',\n",
       "              'Moscow Newsroom',\n",
       "              'Motherwell',\n",
       "              'Movement for a Democratic Slovakia',\n",
       "              'Munich Re',\n",
       "              'NAC Breda',\n",
       "              'NATO',\n",
       "              'NBA',\n",
       "              'NEC Nijmegen',\n",
       "              'NEW <UNK>',\n",
       "              'NEW ENGLAND',\n",
       "              'NEW YORK',\n",
       "              'NYMEX',\n",
       "              'NZ First',\n",
       "              'Nancy',\n",
       "              'Nantes',\n",
       "              'Napoli',\n",
       "              'National',\n",
       "              'National <UNK> Control Association',\n",
       "              'National Air <UNK> Services Ltd',\n",
       "              'National Alliance',\n",
       "              'National Basketball',\n",
       "              'National Bucharest',\n",
       "              'National Football League',\n",
       "              'National Hockey',\n",
       "              'National Hockey League',\n",
       "              'National League for Democracy',\n",
       "              'National University of Singapore',\n",
       "              'National Weather Service',\n",
       "              'Nebraska',\n",
       "              'New Jersey',\n",
       "              'New Mexico <UNK> Association',\n",
       "              'New South Wales',\n",
       "              'New South Wales Supreme Court',\n",
       "              'New York',\n",
       "              'New York <UNK>',\n",
       "              'New York Commodities',\n",
       "              'New York Commodities Desk',\n",
       "              'New York Power Desk',\n",
       "              'New York Stock Exchange',\n",
       "              'New Zealand First',\n",
       "              'Newcastle',\n",
       "              'Nice',\n",
       "              'Northampton',\n",
       "              'Northern League',\n",
       "              'Norwich',\n",
       "              'Nottingham Forest',\n",
       "              'Notts County',\n",
       "              'O Globo',\n",
       "              'OAKLAND',\n",
       "              'OIC',\n",
       "              'OTTAWA',\n",
       "              'Office of Fair Trade',\n",
       "              'Office of Fair Trading',\n",
       "              'Ohio State',\n",
       "              'Oldham',\n",
       "              'Olympiakos',\n",
       "              'Olympic Airways',\n",
       "              'Organisation of the Islamic Conference',\n",
       "              'Orlando',\n",
       "              'Otelul Galati',\n",
       "              'Ottawa',\n",
       "              'Oxford',\n",
       "              'PA',\n",
       "              'PGA',\n",
       "              'PHILADELPHIA',\n",
       "              'PHOENIX',\n",
       "              'PITTSBURGH',\n",
       "              'PKK',\n",
       "              'PLO',\n",
       "              'PSV',\n",
       "              'PSV Eindhoven',\n",
       "              'PT <UNK> <UNK>',\n",
       "              'PT <UNK> Indonesia',\n",
       "              'Palestine Liberation Organisation',\n",
       "              'Palestinian Authority',\n",
       "              'Paris Saint-Germain',\n",
       "              'Paris St Germain',\n",
       "              'Parma',\n",
       "              'Partick',\n",
       "              'Partizan',\n",
       "              'Partizan Belgrade',\n",
       "              'Perugia',\n",
       "              'Peterborough',\n",
       "              'Philadelphia',\n",
       "              'Philadelphia <UNK>',\n",
       "              'Piacenza',\n",
       "              'Pittsburgh',\n",
       "              'Plymouth',\n",
       "              'Port Vale',\n",
       "              'Porto',\n",
       "              'Portsmouth',\n",
       "              'Portuguesa',\n",
       "              'Prague Newsroom',\n",
       "              'Preston',\n",
       "              'Prudential Securities <UNK>',\n",
       "              \"Queen 's Park\",\n",
       "              'Queen of South',\n",
       "              'Queens Park Rangers',\n",
       "              'RAO <UNK> <UNK>',\n",
       "              'REUTER',\n",
       "              'RKC Waalwijk',\n",
       "              'RTRS',\n",
       "              'RUGBY UNION',\n",
       "              'Racing Santander',\n",
       "              'Radical Democrats',\n",
       "              'Radio Romania',\n",
       "              'Raith',\n",
       "              'Rangers',\n",
       "              'Rangoon University',\n",
       "              'Rapid Vienna',\n",
       "              'Reading',\n",
       "              'Real',\n",
       "              'Real <UNK>',\n",
       "              'Real Madrid',\n",
       "              'Red Cross',\n",
       "              'Reggiana',\n",
       "              'Rennes',\n",
       "              'Reuter',\n",
       "              'Reuters',\n",
       "              'Riga Newsroom',\n",
       "              'Rochdale',\n",
       "              'Roda JC Kerkrade',\n",
       "              'Roma',\n",
       "              'Rosenborg',\n",
       "              'Ross County',\n",
       "              'Rotherham',\n",
       "              'Russian Weather Service',\n",
       "              'S&P',\n",
       "              'SAN <UNK>',\n",
       "              'SAN DIEGO',\n",
       "              'SAN FRANCISCO',\n",
       "              'SAN JOSE',\n",
       "              'SC Freiburg',\n",
       "              'SEATTLE',\n",
       "              'ST LOUIS',\n",
       "              'SV <NUM> Munich',\n",
       "              'Salamanca',\n",
       "              'Sale <UNK> School',\n",
       "              'Salomon',\n",
       "              'Salomon Brothers',\n",
       "              'Sampdoria',\n",
       "              'Santa <UNK>',\n",
       "              'Santa <UNK> Pacific Gold Corp',\n",
       "              'Scarborough',\n",
       "              'Schalke',\n",
       "              'Schalke <NUM>',\n",
       "              'Scunthorpe',\n",
       "              'Security Council',\n",
       "              'Senate',\n",
       "              'Sheffield United',\n",
       "              'Sheffield Wednesday',\n",
       "              'Shrewsbury',\n",
       "              'Singapore Newsroom',\n",
       "              'Social Democratic Union',\n",
       "              'Social Movement',\n",
       "              'South African <UNK> Ltd',\n",
       "              'South Lebanon Army',\n",
       "              'Southampton',\n",
       "              'Southend',\n",
       "              'Sparta Rotterdam',\n",
       "              'Split',\n",
       "              'Sporting',\n",
       "              'St <UNK> X High School',\n",
       "              'St Albans',\n",
       "              'St Johnstone',\n",
       "              'St Mirren',\n",
       "              'State Council',\n",
       "              'State Department',\n",
       "              'State Law and Order <UNK> Council',\n",
       "              'State Street Bank and Trust Company',\n",
       "              'Statistics Canada',\n",
       "              'Steaua',\n",
       "              'Steaua Bucharest',\n",
       "              'Stenhousemuir',\n",
       "              'Stirling',\n",
       "              'Stockport',\n",
       "              'Stoke',\n",
       "              'Stranraer',\n",
       "              'Strasbourg',\n",
       "              'Sumitomo',\n",
       "              'Sumitomo Bank',\n",
       "              'Sunderland',\n",
       "              'Swansea',\n",
       "              'Swindon',\n",
       "              'Switzerland I',\n",
       "              'Sydney Newsroom',\n",
       "              'TORONTO',\n",
       "              'TWA',\n",
       "              'Tallinna <UNK>',\n",
       "              'Tasmania',\n",
       "              'Tass',\n",
       "              'The Super <UNK>',\n",
       "              'Toronto',\n",
       "              'Torquay',\n",
       "              'Tottenham',\n",
       "              'Trade and Industry',\n",
       "              'Tranmere',\n",
       "              'Treasury',\n",
       "              'Twente Enschede',\n",
       "              'Tychy',\n",
       "              'U.N.',\n",
       "              'U.N. General Assembly',\n",
       "              'U.S. Court of Appeals',\n",
       "              'U.S. Municipal Desk',\n",
       "              'U.S. Senate Banking Committee',\n",
       "              'U.S. Supreme Court',\n",
       "              'U.S. Treasury',\n",
       "              'UEFA',\n",
       "              'UNITED NATIONS',\n",
       "              'USA I',\n",
       "              'USA III',\n",
       "              'USDA',\n",
       "              'Udinese',\n",
       "              'Union Bank of Switzerland',\n",
       "              'United City Bank',\n",
       "              'United Nations',\n",
       "              'United States I',\n",
       "              'United States III',\n",
       "              'University of <UNK>',\n",
       "              'Utrecht',\n",
       "              'VANCOUVER',\n",
       "              'Valencia',\n",
       "              'Vancouver',\n",
       "              'Vancouver <UNK>',\n",
       "              'Verona',\n",
       "              'VfB Stuttgart',\n",
       "              'VfL Bochum',\n",
       "              'Vicenza',\n",
       "              'Victoria',\n",
       "              'Villa',\n",
       "              'Virginia <UNK>',\n",
       "              'Vitesse Arnhem',\n",
       "              'Volendam',\n",
       "              'WASHINGTON',\n",
       "              'Wall Street Desk',\n",
       "              'Walsall',\n",
       "              'Warsaw Newsroom',\n",
       "              'Washington <UNK>',\n",
       "              'Watford',\n",
       "              'Wednesday',\n",
       "              'Werder Bremen',\n",
       "              'West Bromwich',\n",
       "              'West Ham',\n",
       "              'West Hartlepool',\n",
       "              'Wigan',\n",
       "              'Willem II Tilburg',\n",
       "              'Wimbledon',\n",
       "              'Wolverhampton',\n",
       "              'World Trade Organisation',\n",
       "              'Wrexham',\n",
       "              'Wycombe',\n",
       "              'Xinhua',\n",
       "              'York',\n",
       "              'Zafririm Holon'}})"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "truly_decode_ner_dict_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(set,\n",
       "            {'PER': {'<UNK>',\n",
       "              '<UNK> <UNK>',\n",
       "              '<UNK> <UNK> <UNK>',\n",
       "              '<UNK> <UNK> Marken',\n",
       "              '<UNK> Abdullah <UNK>',\n",
       "              '<UNK> Ambrose',\n",
       "              '<UNK> Andersson',\n",
       "              '<UNK> Bell',\n",
       "              '<UNK> Bologna',\n",
       "              '<UNK> Brenden',\n",
       "              '<UNK> Brenner',\n",
       "              '<UNK> Brown',\n",
       "              '<UNK> Campbell',\n",
       "              '<UNK> Convention',\n",
       "              '<UNK> Cooper',\n",
       "              '<UNK> Corini',\n",
       "              '<UNK> Dan',\n",
       "              '<UNK> Daniel',\n",
       "              '<UNK> Gross',\n",
       "              '<UNK> Harper',\n",
       "              '<UNK> Harrison',\n",
       "              '<UNK> Huber',\n",
       "              '<UNK> Hussain',\n",
       "              '<UNK> Ion',\n",
       "              '<UNK> Kyoko',\n",
       "              '<UNK> Lloyd',\n",
       "              '<UNK> Marco',\n",
       "              '<UNK> Margit <UNK>',\n",
       "              '<UNK> Marken',\n",
       "              '<UNK> Martin',\n",
       "              '<UNK> Matthew',\n",
       "              '<UNK> Matthew <UNK>',\n",
       "              '<UNK> Nickel',\n",
       "              '<UNK> Pizzi',\n",
       "              '<UNK> Plus',\n",
       "              '<UNK> Point',\n",
       "              '<UNK> Pradesh',\n",
       "              '<UNK> Putra',\n",
       "              '<UNK> Rashid',\n",
       "              '<UNK> Sakti',\n",
       "              '<UNK> San <UNK> <UNK>',\n",
       "              '<UNK> Sang <UNK>',\n",
       "              '<UNK> Tanaka',\n",
       "              '<UNK> Thompson',\n",
       "              '<UNK> Townsend',\n",
       "              '<UNK> Vaccari',\n",
       "              '<UNK> Weah',\n",
       "              '<UNK> Zagreb',\n",
       "              '<UNK> de <UNK>',\n",
       "              '<UNK> van der',\n",
       "              '<UNK> van der Merwe',\n",
       "              'A. <UNK>',\n",
       "              'A. <UNK> <UNK>',\n",
       "              'Abdul Latif <UNK>',\n",
       "              'Abel <UNK>',\n",
       "              'Abu Ibrahim',\n",
       "              'Adams',\n",
       "              'Adnan Al <UNK>',\n",
       "              'Adrian Ilie',\n",
       "              'Ahmed <UNK>',\n",
       "              'Alan <UNK>',\n",
       "              'Alan Greenspan',\n",
       "              'Alan Shearer',\n",
       "              'Alatas',\n",
       "              'Albert',\n",
       "              'Aleksander Kwasniewski',\n",
       "              'Alessandro <UNK>',\n",
       "              'Alessandro Del <UNK>',\n",
       "              'Alexander <UNK>',\n",
       "              'Alexander Downer',\n",
       "              'Alexandra <UNK>',\n",
       "              'Alexandre <UNK>',\n",
       "              'Ali <UNK>',\n",
       "              'Ali Alatas',\n",
       "              'All Black',\n",
       "              'Allan <UNK>',\n",
       "              'Allan <UNK> <UNK>',\n",
       "              'Ally McCoist',\n",
       "              'Ambrose',\n",
       "              'Andrea <UNK>',\n",
       "              'Andreas <UNK>',\n",
       "              'Andrei <UNK>',\n",
       "              'Andrew',\n",
       "              'Andrew <UNK>',\n",
       "              'Andrew Park',\n",
       "              'Andy <UNK>',\n",
       "              'Anita <UNK>',\n",
       "              'Anke <UNK>',\n",
       "              'Ann <UNK>',\n",
       "              'Antoine <UNK>',\n",
       "              'Anton <UNK>',\n",
       "              'Antonio <UNK>',\n",
       "              'Antonio Folha',\n",
       "              'Arafat',\n",
       "              'Arizona',\n",
       "              'Armando',\n",
       "              'Armando <UNK>',\n",
       "              'Artur <UNK>',\n",
       "              'B. Lara',\n",
       "              'B. Young',\n",
       "              'Barbara <UNK>',\n",
       "              'Benito <UNK>',\n",
       "              'Benjamin',\n",
       "              'Benjamin Netanyahu',\n",
       "              'Berisha',\n",
       "              'Bernd <UNK>',\n",
       "              'Bill Brett',\n",
       "              'Bill Clinton',\n",
       "              'Bill Jordan',\n",
       "              'Billy <UNK>',\n",
       "              'Bob <UNK>',\n",
       "              'Bob Woolmer',\n",
       "              'Bobby',\n",
       "              'Bode',\n",
       "              'Bogdan <UNK>',\n",
       "              'Bolger',\n",
       "              'Boris Yeltsin',\n",
       "              'Boutros Boutros-Ghali',\n",
       "              'Boutros-Ghali',\n",
       "              'Brenden',\n",
       "              'Brett <UNK>',\n",
       "              'Brian <UNK>',\n",
       "              'Brian Lara',\n",
       "              'Bruno <UNK>',\n",
       "              'Business',\n",
       "              'C. <UNK>',\n",
       "              'C. Ambrose',\n",
       "              'C. Cairns',\n",
       "              'C. Harris',\n",
       "              'C. Hooper',\n",
       "              'C. Walsh',\n",
       "              'CHINA',\n",
       "              'Cairns',\n",
       "              'Carl',\n",
       "              'Carl Hooper',\n",
       "              'Carlo <UNK>',\n",
       "              'Carlos <UNK>',\n",
       "              'Carlos Secretario',\n",
       "              'Caroline Olivier',\n",
       "              'Casey <UNK>',\n",
       "              'Catherine <UNK>',\n",
       "              'Charlton',\n",
       "              'Chen Gang',\n",
       "              'Chirac',\n",
       "              'Chris',\n",
       "              'Chris <UNK>',\n",
       "              'Christian <UNK>',\n",
       "              'Christophe <UNK>',\n",
       "              'Christopher <UNK>',\n",
       "              'Clarence Seedorf',\n",
       "              'Clarence Woolmer',\n",
       "              'Claude <UNK>',\n",
       "              'Clinton',\n",
       "              'Clinton <UNK>',\n",
       "              'Colin <UNK>',\n",
       "              'Courtney Walsh',\n",
       "              'Craig <UNK>',\n",
       "              'Croat <UNK> <UNK>',\n",
       "              'DENVER',\n",
       "              'Dan <UNK>',\n",
       "              'Dan Crowley',\n",
       "              'Daniel <UNK>',\n",
       "              'Daniel Herbert',\n",
       "              'Daniele <UNK>',\n",
       "              'Dariusz Rosati',\n",
       "              'Darren <UNK>',\n",
       "              'Darren Jackson',\n",
       "              'Date',\n",
       "              'Dave <UNK>',\n",
       "              'David <UNK>',\n",
       "              'David Wilson',\n",
       "              'Davies',\n",
       "              'Davis Love',\n",
       "              'Dean <UNK>',\n",
       "              'Dean Jones',\n",
       "              'Dejan <UNK>',\n",
       "              'Dejan Savicevic',\n",
       "              'Dennis <UNK>',\n",
       "              'Deportivo <UNK>',\n",
       "              'Derek da <UNK>',\n",
       "              'Desmond <UNK>',\n",
       "              'Dick Spring',\n",
       "              'Diego <UNK>',\n",
       "              'Dieter <UNK>',\n",
       "              'Dietmar <UNK>',\n",
       "              'Dimas',\n",
       "              'Dimas Teixeira',\n",
       "              'Dirk <UNK>',\n",
       "              'Don <UNK>',\n",
       "              'Donna <UNK>',\n",
       "              'Donna Andrews',\n",
       "              'Double',\n",
       "              'Doug Young',\n",
       "              'Edna Fernandes',\n",
       "              'Eduardo <UNK>',\n",
       "              'El Salvador',\n",
       "              'Elena <UNK>',\n",
       "              'Enrique',\n",
       "              'Eric <UNK>',\n",
       "              'Erwin Arnold',\n",
       "              'Eugene Morris',\n",
       "              'Evelyn Leopold',\n",
       "              'Fabio <UNK>',\n",
       "              'Fabrizio Ravanelli',\n",
       "              'Ferguson',\n",
       "              'Fernando <UNK>',\n",
       "              'Fernando <UNK> <UNK>',\n",
       "              'Fernando Couto',\n",
       "              'Ferrer',\n",
       "              'Filippo <UNK>',\n",
       "              'Florence <UNK>',\n",
       "              'Francesco <UNK>',\n",
       "              'Francis <UNK>',\n",
       "              'Franco <UNK> <UNK>',\n",
       "              'Fraser',\n",
       "              'Frederick',\n",
       "              'Fung Permadi',\n",
       "              'G. <UNK>',\n",
       "              'Garrett',\n",
       "              'Garrett Hines',\n",
       "              'Garry <UNK>',\n",
       "              'Gary <UNK>',\n",
       "              'Geoff Marsh',\n",
       "              'George <UNK>',\n",
       "              'George Weah',\n",
       "              'Gerard Van Velde',\n",
       "              'Germany III',\n",
       "              'Gheorghe',\n",
       "              'Gheorghe <UNK>',\n",
       "              'Gianfranco <UNK>',\n",
       "              'Gianluca <UNK>',\n",
       "              'Gianluca Vialli',\n",
       "              'Gilbert Le Gras',\n",
       "              'Giovanni',\n",
       "              'Giuseppe <UNK>',\n",
       "              'Glen <UNK>',\n",
       "              'Glenn <UNK>',\n",
       "              'Glenn McGrath',\n",
       "              'God',\n",
       "              'Gong <UNK>',\n",
       "              'Gong Zhichao',\n",
       "              'Goran Ivanisevic',\n",
       "              'Green Bay',\n",
       "              'Greenspan',\n",
       "              'Greg <UNK>',\n",
       "              'Greg Reid',\n",
       "              'Guillermo',\n",
       "              'Guy Whittingham',\n",
       "              'Hamid <UNK>',\n",
       "              'Hannes <UNK>',\n",
       "              'Harper',\n",
       "              'Harper Williams',\n",
       "              'Harris',\n",
       "              'Hassan Abbas',\n",
       "              'Hassan Ahmed',\n",
       "              'Havel',\n",
       "              'Healy',\n",
       "              'Helder Cristovao',\n",
       "              'Helmut Kohl',\n",
       "              'Henry Hub',\n",
       "              'Hermawan Susanto',\n",
       "              'Hilary <UNK>',\n",
       "              'Hooper',\n",
       "              'Hosni Mubarak',\n",
       "              'Hu Zhilan',\n",
       "              'Hubert <UNK>',\n",
       "              'I. Healy',\n",
       "              'Ian <UNK>',\n",
       "              'Ian Harvey',\n",
       "              'Ian Healy',\n",
       "              'Ian Jones',\n",
       "              'Ian Wright',\n",
       "              'Ijaz Ahmad',\n",
       "              'Indra Wijaya',\n",
       "              'Ivan <UNK>',\n",
       "              'Ivan de',\n",
       "              'J. <UNK>',\n",
       "              'J. Adams',\n",
       "              'J. Murray',\n",
       "              'J. Vaughan',\n",
       "              'Jack Charlton',\n",
       "              'Jackson',\n",
       "              'Jacques <UNK>',\n",
       "              'Jacques Chirac',\n",
       "              'James Love',\n",
       "              'Jan <UNK>',\n",
       "              'Jared <UNK>',\n",
       "              'Jason <UNK>',\n",
       "              'Jason Little',\n",
       "              'Javier <UNK>',\n",
       "              'Jean van <UNK>',\n",
       "              'Jeff <UNK>',\n",
       "              'Jeremy <UNK>',\n",
       "              'Jim <UNK>',\n",
       "              'Jim Bolger',\n",
       "              'Jim Courier',\n",
       "              'Jimmy Adams',\n",
       "              'Jiri <UNK>',\n",
       "              'Joao <UNK>',\n",
       "              'Joao Manuel Pinto',\n",
       "              'Joao Vieira Pinto',\n",
       "              'Joe <UNK>',\n",
       "              'John <UNK>',\n",
       "              'John <UNK> <UNK>',\n",
       "              'John Lewis Partnership',\n",
       "              'John Lewis UK',\n",
       "              'John Major',\n",
       "              'John Mills Jr',\n",
       "              'Jonathan Wright',\n",
       "              'Jones',\n",
       "              'Jorge Cadete',\n",
       "              'Jorge Costa',\n",
       "              'Jose <UNK>',\n",
       "              'Jose <UNK> <UNK>',\n",
       "              'Jose Barroso',\n",
       "              'Jose Luis <UNK>',\n",
       "              'Josef <UNK>',\n",
       "              'Joseph <UNK>',\n",
       "              'Juan <UNK>',\n",
       "              'Juan Pizzi',\n",
       "              'Junior Murray',\n",
       "              'Justin',\n",
       "              'Justin <UNK>',\n",
       "              'K. Benjamin',\n",
       "              'K.T. <UNK>',\n",
       "              'Karin <UNK>',\n",
       "              'Kate Pace Lindsay',\n",
       "              'Kennedy',\n",
       "              'Kenneth <UNK>',\n",
       "              'Kenneth Benjamin',\n",
       "              'Khaled <UNK>',\n",
       "              'Kim',\n",
       "              'Kim <UNK>',\n",
       "              'Kim <UNK> <UNK>',\n",
       "              'Kim Do <UNK>',\n",
       "              'Kirsten',\n",
       "              'Klaus',\n",
       "              'Kohl',\n",
       "              'Kristie Marshall',\n",
       "              'Kwasniewski',\n",
       "              'L. <UNK>',\n",
       "              'Lara',\n",
       "              'Laurent <UNK>',\n",
       "              'Lee <UNK>',\n",
       "              'Lee Young <UNK>',\n",
       "              'Les Ferdinand',\n",
       "              'Lombardi',\n",
       "              'Lombardi <UNK>',\n",
       "              'Lorenzo <UNK>',\n",
       "              'Luc Nilis',\n",
       "              'Luis',\n",
       "              'Luis <UNK>',\n",
       "              'Luis Figo',\n",
       "              'M. Bevan',\n",
       "              'M. Taylor',\n",
       "              'M. Wasim',\n",
       "              'M. Waugh',\n",
       "              'Major',\n",
       "              'Marc <UNK>',\n",
       "              'Marcelo',\n",
       "              'Marcelo <UNK>',\n",
       "              'Marcin <UNK>',\n",
       "              'Marco <UNK>',\n",
       "              'Marcus <UNK>',\n",
       "              'Margaret <UNK>',\n",
       "              'Marianne <UNK>',\n",
       "              'Mario <UNK>',\n",
       "              'Mark',\n",
       "              'Mark <UNK>',\n",
       "              'Mark Cairns',\n",
       "              'Mark McNulty',\n",
       "              'Mark Taylor',\n",
       "              'Mark Waugh',\n",
       "              'Mark Woodforde',\n",
       "              'Marshall <UNK>',\n",
       "              'Martin <UNK> Hansen',\n",
       "              'Martina <UNK>',\n",
       "              'Matthew',\n",
       "              'Matthew <UNK>',\n",
       "              'Matthew Le <UNK>',\n",
       "              'McCoist',\n",
       "              'Merwe',\n",
       "              'Mia <UNK>',\n",
       "              'Michael <UNK>',\n",
       "              'Michael Bevan',\n",
       "              'Michael Frederick',\n",
       "              'Michel <UNK>',\n",
       "              'Mickey <UNK>',\n",
       "              'Miguel <UNK>',\n",
       "              'Mike <UNK>',\n",
       "              'Mike McCurry',\n",
       "              'Milan <UNK>',\n",
       "              'Miller',\n",
       "              'Miriam <UNK>',\n",
       "              'Mohamed <UNK>',\n",
       "              'Mohammed',\n",
       "              'Mohammed <UNK>',\n",
       "              'Mohammed Rashid',\n",
       "              'Moin Khan',\n",
       "              'Morris',\n",
       "              'Mubarak',\n",
       "              'Mulder',\n",
       "              'Murray',\n",
       "              'Mushtaq Ahmad',\n",
       "              'N. <UNK>',\n",
       "              'N. Ireland',\n",
       "              'Nabil Abu Rdainah',\n",
       "              'Neil <UNK>',\n",
       "              'Nelson Mandela',\n",
       "              'Nestor <UNK>',\n",
       "              'Netanyahu',\n",
       "              'Nicholas <UNK>',\n",
       "              'Nick <UNK>',\n",
       "              'Nick Price',\n",
       "              'Nicol',\n",
       "              'Nicola <UNK>',\n",
       "              'Nigel Walker',\n",
       "              'Nixon <UNK>',\n",
       "              'Norm <UNK>',\n",
       "              'Oceano Cruz',\n",
       "              'Oksana <UNK>',\n",
       "              'Olga <UNK>',\n",
       "              'Oliver Bierhoff',\n",
       "              'Ong Ewe Hock',\n",
       "              'Orlando',\n",
       "              'Orlando Pace',\n",
       "              'Oscar <UNK>',\n",
       "              'Oscar Luigi <UNK>',\n",
       "              'P. Reiffel',\n",
       "              'Pat <UNK>',\n",
       "              'Pat Howard',\n",
       "              'Patrick Vieira',\n",
       "              'Paul <UNK>',\n",
       "              'Paul Gascoigne',\n",
       "              'Paul Justin',\n",
       "              'Paul Reiffel',\n",
       "              'Paul Wright',\n",
       "              'Paulinho Santos',\n",
       "              'Paulo <UNK>',\n",
       "              'Pavel <UNK>',\n",
       "              'Peres',\n",
       "              'Perugia',\n",
       "              'Peter <UNK>',\n",
       "              'Peter Nicol',\n",
       "              'Peter van <UNK>',\n",
       "              'Peters',\n",
       "              'Petra <UNK>',\n",
       "              'Phil Gray',\n",
       "              'Philippe <UNK>',\n",
       "              'Pierre <UNK>',\n",
       "              'Pierre Van <UNK>',\n",
       "              'Play',\n",
       "              'Pope',\n",
       "              'Pope John Paul',\n",
       "              'Prince Rupert',\n",
       "              'Quentin <UNK>',\n",
       "              'R. <UNK>',\n",
       "              'R. Kennedy',\n",
       "              'R. Ponting',\n",
       "              'REUTER',\n",
       "              'Rafael <UNK>',\n",
       "              'Ramon Vega',\n",
       "              'Randy Jones',\n",
       "              'Raphael <UNK>',\n",
       "              'Rashid',\n",
       "              'Rashid <UNK>',\n",
       "              'Raul Gonzalez',\n",
       "              'Ray <UNK>',\n",
       "              'Rdainah',\n",
       "              'Regina <UNK>',\n",
       "              'Reiffel',\n",
       "              'Richard <UNK>',\n",
       "              'Ricky <UNK>',\n",
       "              'Ricky Ponting',\n",
       "              'Rob <UNK>',\n",
       "              'Rob Andrew',\n",
       "              'Robbie <UNK>',\n",
       "              'Robbie Fowler',\n",
       "              'Robert',\n",
       "              'Robert <UNK>',\n",
       "              'Robert Mugabe',\n",
       "              'Roberto <UNK>',\n",
       "              'Roberto Baggio',\n",
       "              'Roberto Carlos',\n",
       "              'Rodney Eyles',\n",
       "              'Roger <UNK>',\n",
       "              'Roger Garcia',\n",
       "              'Ron Ellis',\n",
       "              'Ronaldo',\n",
       "              'Ronny <UNK>',\n",
       "              'Rosati',\n",
       "              'Rosemary Bennett',\n",
       "              'Ross',\n",
       "              'Rubin',\n",
       "              'Rudi <UNK>',\n",
       "              'Rui Barros',\n",
       "              'Rui Correia',\n",
       "              'Rui Costa',\n",
       "              'Ryan Johnson',\n",
       "              'S. <UNK>',\n",
       "              'S. Campbell',\n",
       "              'S. Fleming',\n",
       "              'S. Law',\n",
       "              'Saeed Anwar',\n",
       "              'Saint Nicholas',\n",
       "              'Sali Berisha',\n",
       "              'Salim Malik',\n",
       "              'Sam Payne',\n",
       "              'Sammy <UNK>',\n",
       "              'Santa <UNK>',\n",
       "              'Saqlain',\n",
       "              'Saqlain Mushtaq',\n",
       "              'Scott <UNK>',\n",
       "              'Scott McCarron',\n",
       "              'Sean <UNK>',\n",
       "              'Sebastien <UNK>',\n",
       "              'Sergey <UNK>',\n",
       "              'Sergi Barjuan',\n",
       "              'Sergio <UNK>',\n",
       "              'Shahid <UNK>',\n",
       "              'Shane <UNK>',\n",
       "              'Shaun Young',\n",
       "              'Shimon Peres',\n",
       "              'Sidi <UNK>',\n",
       "              'Simon Parke',\n",
       "              'Sophia Loren',\n",
       "              'Soren B. Nielsen',\n",
       "              'Stefano <UNK>',\n",
       "              'Stephen <UNK>',\n",
       "              'Stephen Nisbet',\n",
       "              'Steve <UNK>',\n",
       "              'Steve McManaman',\n",
       "              'Steve van <UNK>',\n",
       "              'Steven <UNK>',\n",
       "              'Stuart Law',\n",
       "              'Suharto',\n",
       "              'Sun Hong',\n",
       "              'Sutton',\n",
       "              'Sven <UNK>',\n",
       "              'Svetlana <UNK>',\n",
       "              'T. Moody',\n",
       "              'Tallinna <UNK>',\n",
       "              'Tan',\n",
       "              'Tan Kong <UNK>',\n",
       "              'Tel Aviv',\n",
       "              'Thomas <UNK>',\n",
       "              'Thomas Stuer-Lauridsen',\n",
       "              'Tim <UNK>',\n",
       "              'Tim Casey',\n",
       "              'Tim Gavin',\n",
       "              'Tom Moody',\n",
       "              'Tony',\n",
       "              'Tony <UNK>',\n",
       "              'Tony Adams',\n",
       "              'Tony Underwood',\n",
       "              'Townsend',\n",
       "              'Troy Benson',\n",
       "              'Troy Vincent',\n",
       "              'Umar',\n",
       "              'Umar Said',\n",
       "              'Umberto Bossi',\n",
       "              'United States III',\n",
       "              'Vaclav Havel',\n",
       "              'Vaclav Klaus',\n",
       "              'Valentin Stefan',\n",
       "              'Van <UNK>',\n",
       "              'Van der',\n",
       "              'Vaughan',\n",
       "              'Verona',\n",
       "              'Vialli',\n",
       "              'Victor Sanchez',\n",
       "              'Vieira',\n",
       "              'Vietnam',\n",
       "              'Viktor <UNK>',\n",
       "              'Villa',\n",
       "              'Vince Lombardi',\n",
       "              'Virginia <UNK>',\n",
       "              'Vitor Baia',\n",
       "              'Vladimir <UNK>',\n",
       "              'Walsh <UNK>',\n",
       "              'Walter <UNK>',\n",
       "              'Wang Chen',\n",
       "              'Waqar',\n",
       "              'Waqar Younis',\n",
       "              'Wasim',\n",
       "              'Wasim Akram',\n",
       "              'Weah',\n",
       "              'Whittingham',\n",
       "              'Wijaya',\n",
       "              'William Hill',\n",
       "              'Winston Peters',\n",
       "              'Woolmer',\n",
       "              'Wright',\n",
       "              'Yasser Arafat',\n",
       "              'Yeltsin',\n",
       "              'Yevgeny Kafelnikov',\n",
       "              'Young',\n",
       "              'Zeljko Petrovic',\n",
       "              'Zoran <UNK>',\n",
       "              'van <UNK>'},\n",
       "             'LOC': {'<UNK>',\n",
       "              '<UNK> <UNK>',\n",
       "              '<UNK> <UNK> Hospital',\n",
       "              '<UNK> Africa',\n",
       "              '<UNK> Bay',\n",
       "              '<UNK> California',\n",
       "              '<UNK> Control Centre',\n",
       "              '<UNK> Norway',\n",
       "              '<UNK> Oval',\n",
       "              '<UNK> STATE',\n",
       "              'ABIDJAN',\n",
       "              'AMSTERDAM',\n",
       "              'ANKARA',\n",
       "              'ATLANTA',\n",
       "              'AUSTRALIA',\n",
       "              'AUSTRIA',\n",
       "              'Abidjan',\n",
       "              'Africa',\n",
       "              'Alatas',\n",
       "              'Albania',\n",
       "              'Alberta',\n",
       "              'Algeria',\n",
       "              'Algiers',\n",
       "              'Amsterdam',\n",
       "              'Antwerp',\n",
       "              'Arabic',\n",
       "              'Asia',\n",
       "              'Asia <UNK> Markets',\n",
       "              'Athens',\n",
       "              'Atlanta',\n",
       "              'Australia',\n",
       "              'Austria',\n",
       "              'BA',\n",
       "              'BANGKOK',\n",
       "              'BEIJING',\n",
       "              'BEIRUT',\n",
       "              'BOMBAY',\n",
       "              'BONN',\n",
       "              'BOSTON',\n",
       "              'BRATISLAVA',\n",
       "              'BRUSSELS',\n",
       "              'BUCHAREST',\n",
       "              'BUDAPEST',\n",
       "              'BUENOS AIRES',\n",
       "              'Balkan',\n",
       "              'Bangkok',\n",
       "              'Bangui',\n",
       "              'Barcelona',\n",
       "              'Beirut',\n",
       "              'Belarus',\n",
       "              'Belgium',\n",
       "              'Belgrade',\n",
       "              'Bombay',\n",
       "              'Bonn',\n",
       "              'Bratislava',\n",
       "              'Bratislava <UNK>',\n",
       "              'Brazil',\n",
       "              'Britain',\n",
       "              'British Columbia',\n",
       "              'Brno',\n",
       "              'Budapest',\n",
       "              'Budapest Bank',\n",
       "              'Buenos Aires',\n",
       "              'Buffalo',\n",
       "              'Bulgaria',\n",
       "              'Burma',\n",
       "              'Burundi',\n",
       "              'CAIRO',\n",
       "              'CANBERRA',\n",
       "              'CHICAGO',\n",
       "              'CINCINNATI',\n",
       "              'CIS',\n",
       "              'CITY',\n",
       "              'COLORADO',\n",
       "              'COPENHAGEN',\n",
       "              'COSTA',\n",
       "              'Cairo',\n",
       "              'Calcutta',\n",
       "              'California',\n",
       "              'Canada',\n",
       "              'Cape Town',\n",
       "              'Cardiff',\n",
       "              'Caribbean',\n",
       "              'Caribs',\n",
       "              'Central Africa',\n",
       "              'Central African Republic',\n",
       "              'Central Asia',\n",
       "              'Chad',\n",
       "              'Charleroi',\n",
       "              'Charlton',\n",
       "              'Chicago',\n",
       "              'Chile',\n",
       "              'China',\n",
       "              'Colombia',\n",
       "              'Colorado',\n",
       "              'Columbus',\n",
       "              'Copenhagen',\n",
       "              'Costa',\n",
       "              'Croatia',\n",
       "              'Cuba',\n",
       "              'Czech',\n",
       "              'Czech Republic',\n",
       "              'DAKAR',\n",
       "              'DALLAS',\n",
       "              'DES MOINES',\n",
       "              'DETROIT',\n",
       "              'DIYARBAKIR',\n",
       "              'DUBLIN',\n",
       "              'Damascus',\n",
       "              'Denmark',\n",
       "              'Doetinchem',\n",
       "              'Dubai',\n",
       "              'East',\n",
       "              'East <UNK>',\n",
       "              'East Coast',\n",
       "              'Egypt',\n",
       "              'England',\n",
       "              'Estonia',\n",
       "              'Ethiopia',\n",
       "              'Europe',\n",
       "              'FRANKFURT',\n",
       "              'Far North',\n",
       "              'Finland',\n",
       "              'Fla.',\n",
       "              'Florida',\n",
       "              'France',\n",
       "              'Frankfurt',\n",
       "              'GENEVA',\n",
       "              'GLASGOW',\n",
       "              'GREECE',\n",
       "              'Gabon',\n",
       "              'Geneva',\n",
       "              'Germany',\n",
       "              'Goma',\n",
       "              'Greece',\n",
       "              'Greenspan',\n",
       "              'Gulf',\n",
       "              'Gulf Coast',\n",
       "              'Gulf of Mexico',\n",
       "              'HANOVER',\n",
       "              'HARARE',\n",
       "              'HOUSTON',\n",
       "              'Hamburg',\n",
       "              'Hebron',\n",
       "              'Hibernian',\n",
       "              'Hines',\n",
       "              'Hospital',\n",
       "              'Hungary',\n",
       "              'Illinois',\n",
       "              'India',\n",
       "              'Indian Ocean',\n",
       "              'Indonesia',\n",
       "              'Inter',\n",
       "              'Iran',\n",
       "              'Iran <UNK>',\n",
       "              'Iraq',\n",
       "              'Ireland',\n",
       "              'Israel',\n",
       "              'Italy',\n",
       "              'Ivory Coast',\n",
       "              'JAKARTA',\n",
       "              'JERUSALEM',\n",
       "              'JOHANNESBURG',\n",
       "              'Jakarta',\n",
       "              'Japan',\n",
       "              'Jerusalem',\n",
       "              'Jordan',\n",
       "              'Kansas',\n",
       "              'Kansas City',\n",
       "              'Karachi',\n",
       "              'Kenya',\n",
       "              'Kinshasa',\n",
       "              'Kremlin',\n",
       "              'Kuwait',\n",
       "              'LA',\n",
       "              'LISBON',\n",
       "              'LITTLE',\n",
       "              'LONDON',\n",
       "              'LOS ANGELES',\n",
       "              'La <UNK>',\n",
       "              'Lara',\n",
       "              'Latin America',\n",
       "              'Lebanon',\n",
       "              'Leicester',\n",
       "              'Lisbon',\n",
       "              'Little',\n",
       "              'London',\n",
       "              'London Heathrow',\n",
       "              'Los Angeles',\n",
       "              'Luxembourg',\n",
       "              'MADRID',\n",
       "              'MANCHESTER UNITED',\n",
       "              'MELBOURNE',\n",
       "              'MEXICO CITY',\n",
       "              'MIAMI',\n",
       "              'MIDEAST',\n",
       "              'MONTREAL',\n",
       "              'MOSCOW',\n",
       "              'Macedonia',\n",
       "              'Madagascar',\n",
       "              'Malaysia',\n",
       "              'Man',\n",
       "              'Manchester',\n",
       "              'Manitoba',\n",
       "              'Manitoba Pork',\n",
       "              'Matthew',\n",
       "              'Mauritania',\n",
       "              'Mauritius',\n",
       "              'Melbourne',\n",
       "              'Melbourne Cricket <UNK>',\n",
       "              'Mexico',\n",
       "              'Mexico City',\n",
       "              'Michigan',\n",
       "              'Mills',\n",
       "              'Minn',\n",
       "              'Minneapolis',\n",
       "              'Mongolia',\n",
       "              'Montana',\n",
       "              'Moscow',\n",
       "              'N.J.',\n",
       "              'NAIROBI',\n",
       "              'NEW',\n",
       "              'NEW <UNK>',\n",
       "              'NEW DELHI',\n",
       "              'NEW ENGLAND',\n",
       "              'NEW YORK',\n",
       "              'NEW ZEALAND',\n",
       "              'NZ',\n",
       "              'Nairobi',\n",
       "              'Namibia',\n",
       "              'National',\n",
       "              'National Football',\n",
       "              'Natural',\n",
       "              'Nebraska',\n",
       "              'Netherlands',\n",
       "              'New Mexico',\n",
       "              'New South Wales',\n",
       "              'New York',\n",
       "              'New York City',\n",
       "              'New Zealand',\n",
       "              'Nigeria',\n",
       "              'North America',\n",
       "              'North West',\n",
       "              'Northern Ireland',\n",
       "              'Norway',\n",
       "              'OAKLAND',\n",
       "              'OTTAWA',\n",
       "              'Ohio',\n",
       "              'Ohio State',\n",
       "              'Oslo',\n",
       "              'Ottawa',\n",
       "              'PAKISTAN',\n",
       "              'PARIS',\n",
       "              'PITTSBURGH',\n",
       "              'POLAND',\n",
       "              'PRAGUE',\n",
       "              'Pacific Coast',\n",
       "              'Pakistan',\n",
       "              'Panhandle',\n",
       "              'Papua',\n",
       "              'Paris',\n",
       "              'Philadelphia',\n",
       "              'Po River',\n",
       "              'Poland',\n",
       "              'Port Louis',\n",
       "              'Portugal',\n",
       "              'Prague',\n",
       "              'RED SEA',\n",
       "              'RIO DE JANEIRO',\n",
       "              'ROME',\n",
       "              'Radio',\n",
       "              'Rangoon',\n",
       "              'Red Sea',\n",
       "              'Republic of Ireland',\n",
       "              'Republic of Padania',\n",
       "              'Rio de Janeiro',\n",
       "              'Romania',\n",
       "              'Rome',\n",
       "              'Rosario Bahia <UNK>',\n",
       "              'Rosenborg',\n",
       "              'Rotterdam',\n",
       "              'Russia',\n",
       "              'Rwanda',\n",
       "              'SAN <UNK>',\n",
       "              'SAN FRANCISCO',\n",
       "              'SAN JOSE',\n",
       "              'SEATTLE',\n",
       "              'SEOUL',\n",
       "              'SHANGHAI',\n",
       "              'SHEFFIELD',\n",
       "              'SINGAPORE',\n",
       "              'SOFIA',\n",
       "              'SYDNEY',\n",
       "              'Salamanca',\n",
       "              'San Francisco',\n",
       "              'Santa',\n",
       "              'Santa <UNK>',\n",
       "              'Santander',\n",
       "              'Santiago',\n",
       "              'Santiago Bernabeu',\n",
       "              'Saudi Arabia',\n",
       "              'Scotland',\n",
       "              'Senegal',\n",
       "              'Singapore',\n",
       "              'Slovakia',\n",
       "              'Slovenia',\n",
       "              'South Africa',\n",
       "              'South America',\n",
       "              'South Korea',\n",
       "              'Soviet Union',\n",
       "              'Spain',\n",
       "              'Split',\n",
       "              'St <UNK>',\n",
       "              'St. Louis',\n",
       "              'Steaua',\n",
       "              'Sudan',\n",
       "              'Sweden',\n",
       "              'Switzerland',\n",
       "              'Sydney',\n",
       "              'Syria',\n",
       "              'TALLINN',\n",
       "              'TIRANA',\n",
       "              'TOKYO',\n",
       "              'TORONTO',\n",
       "              'Taiwan',\n",
       "              'Tasmania',\n",
       "              'Technology',\n",
       "              'Texas',\n",
       "              'Thailand',\n",
       "              'Tianjin',\n",
       "              'Timisoara',\n",
       "              'Tirana',\n",
       "              'Tokyo',\n",
       "              'Toronto',\n",
       "              'Turkey',\n",
       "              'U.S',\n",
       "              'U.S.',\n",
       "              'UAE',\n",
       "              'UK',\n",
       "              'US',\n",
       "              'USA',\n",
       "              'Ukraine',\n",
       "              'Union',\n",
       "              'Union Bank',\n",
       "              'United Arab Emirates',\n",
       "              'United States',\n",
       "              'Uruguay <UNK>',\n",
       "              'VANCOUVER',\n",
       "              'VIENNA',\n",
       "              'Vancouver',\n",
       "              'Vatican',\n",
       "              'Venezuela',\n",
       "              'Victoria',\n",
       "              'Vietnam',\n",
       "              'WARSAW',\n",
       "              'WASHINGTON',\n",
       "              'WELLINGTON',\n",
       "              'WEST',\n",
       "              'WEST <UNK>',\n",
       "              'WESTERN HEMISPHERE',\n",
       "              'WINNIPEG',\n",
       "              'Wales',\n",
       "              'Wall St',\n",
       "              'Wall Street',\n",
       "              'Warsaw',\n",
       "              'Washington',\n",
       "              'Washington <UNK>',\n",
       "              'Wellington',\n",
       "              'West',\n",
       "              'West Coast',\n",
       "              'West Indies',\n",
       "              'White House',\n",
       "              'Wimbledon',\n",
       "              'Wis',\n",
       "              'Yugoslavia',\n",
       "              'Zaire',\n",
       "              'Zambia',\n",
       "              'Zimbabwe'},\n",
       "             'MISC': {'<UNK>',\n",
       "              '<UNK> <UNK>',\n",
       "              '<UNK> <UNK> <UNK>',\n",
       "              '<UNK> <UNK> CUP',\n",
       "              '<UNK> CLASSIC',\n",
       "              '<UNK> CUP',\n",
       "              '<UNK> CUP <UNK>',\n",
       "              '<UNK> Classic',\n",
       "              '<UNK> Cup',\n",
       "              '<UNK> DIVISION',\n",
       "              '<UNK> Day',\n",
       "              '<UNK> East',\n",
       "              '<UNK> International',\n",
       "              '<UNK> Price',\n",
       "              '<UNK> Trophy',\n",
       "              '<UNK> Turkish',\n",
       "              '<UNK> Winter Olympics Championships',\n",
       "              'ADRs',\n",
       "              'AFRICAN CUP WINNERS',\n",
       "              'AMERICAN',\n",
       "              'AMERICAN <UNK>',\n",
       "              'AMERICAN <UNK> <UNK>',\n",
       "              'ATLANTIC DIVISION',\n",
       "              'AUSTRALIAN',\n",
       "              'African',\n",
       "              \"African Cup Winners ' Cup\",\n",
       "              'Africans',\n",
       "              'Albanian',\n",
       "              'Algerian',\n",
       "              'Algerian Moslem',\n",
       "              'Algerians',\n",
       "              'American',\n",
       "              'Americans',\n",
       "              'Arab <UNK>',\n",
       "              'Argentine',\n",
       "              'Asian',\n",
       "              'Asian Cup',\n",
       "              'Asian Games',\n",
       "              'Australian',\n",
       "              'Australian Capital <UNK>',\n",
       "              'Austrian',\n",
       "              'BRAZILIAN',\n",
       "              'BRITISH',\n",
       "              'Basque',\n",
       "              'Belgian',\n",
       "              'Belgian <UNK>',\n",
       "              'Brazilian',\n",
       "              'British',\n",
       "              'British <UNK>',\n",
       "              'Bulgarian',\n",
       "              'Burmese',\n",
       "              'C$',\n",
       "              'CENTRAL DIVISION',\n",
       "              'CZECH',\n",
       "              'Cairns',\n",
       "              'Cambodian',\n",
       "              'Canadian',\n",
       "              'Canadian West Coast <UNK> <UNK>',\n",
       "              'Canadians',\n",
       "              'Catholic Church',\n",
       "              'Challenge Cup',\n",
       "              \"Champions ' League\",\n",
       "              'Chapman Golf Club',\n",
       "              'Chapter Seven',\n",
       "              'Chilean',\n",
       "              'Chinese',\n",
       "              'Christian',\n",
       "              'Christians',\n",
       "              'Communist',\n",
       "              'Croat',\n",
       "              'Croatian',\n",
       "              'Cup',\n",
       "              'Czech',\n",
       "              'DAX',\n",
       "              'DUTCH',\n",
       "              'Democratic',\n",
       "              'Democratic Convention',\n",
       "              'Dow',\n",
       "              'Dutch',\n",
       "              'EASTERN <UNK>',\n",
       "              'EASTERN DIVISION',\n",
       "              'ENGLISH',\n",
       "              'ENGLISH F.A. CUP',\n",
       "              'East <UNK>',\n",
       "              'Egyptian',\n",
       "              'English',\n",
       "              'English F.A. Challenge',\n",
       "              'Englishman',\n",
       "              'Estonian',\n",
       "              'Euro',\n",
       "              'European',\n",
       "              \"European Champions ' League\",\n",
       "              'European Cup',\n",
       "              'F.A.',\n",
       "              'FRENCH',\n",
       "              'Fair Play',\n",
       "              'Four African',\n",
       "              'French',\n",
       "              'Frenchman',\n",
       "              'GERMAN',\n",
       "              'GMT',\n",
       "              'GRAND SLAM CUP',\n",
       "              'General Agreement',\n",
       "              'German',\n",
       "              'German <UNK>',\n",
       "              'German Bunds',\n",
       "              'German Santa',\n",
       "              'Grand <UNK>',\n",
       "              'Grand Slam Cup',\n",
       "              'Greek',\n",
       "              'Hindu',\n",
       "              'Hungarian',\n",
       "              'ISRAELI',\n",
       "              'ITALIAN',\n",
       "              'Indian',\n",
       "              'Indonesian',\n",
       "              'Internet',\n",
       "              'Irish',\n",
       "              'Islam',\n",
       "              'Israeli',\n",
       "              'Israelis',\n",
       "              'Italian',\n",
       "              'Italian <UNK>',\n",
       "              'Italian <UNK> A',\n",
       "              'Italians',\n",
       "              'Japanese',\n",
       "              'Jewish',\n",
       "              'Jews',\n",
       "              'Jones',\n",
       "              'Korean',\n",
       "              'Kurd',\n",
       "              'Kurdish',\n",
       "              'Labor',\n",
       "              'League',\n",
       "              'Lebanese',\n",
       "              'Liberian',\n",
       "              'Major',\n",
       "              'Mauritian',\n",
       "              'Mediterranean',\n",
       "              'Mexican',\n",
       "              'Montenegrin',\n",
       "              'Moroccan',\n",
       "              'Moslem',\n",
       "              'Moslems',\n",
       "              'NATIONAL <UNK> <UNK>',\n",
       "              'NYC',\n",
       "              'National Football League',\n",
       "              'National Hockey League',\n",
       "              'Nazi German',\n",
       "              'New <UNK>',\n",
       "              'New Year',\n",
       "              'Nobel',\n",
       "              'Nobel Peace Prize',\n",
       "              'Norwegian',\n",
       "              'Office of Fair Trading',\n",
       "              'Olympic',\n",
       "              'PACIFIC DIVISION',\n",
       "              'PGA',\n",
       "              'Palestinian',\n",
       "              'Palestinians',\n",
       "              'Petroleum',\n",
       "              'Polish',\n",
       "              'Polish Jews',\n",
       "              'Pope',\n",
       "              'Portuguese',\n",
       "              'Price Index',\n",
       "              'Roman',\n",
       "              'Roman Catholic',\n",
       "              'Rose Bowl',\n",
       "              'Rules',\n",
       "              'Russian',\n",
       "              'Rwandan',\n",
       "              'SCOTTISH',\n",
       "              'SPANISH',\n",
       "              'Santa Claus',\n",
       "              'Scottish',\n",
       "              'Scottish Cup',\n",
       "              'Sheffield <UNK>',\n",
       "              'Slovak',\n",
       "              'Slovak <UNK>',\n",
       "              'Social Democrats',\n",
       "              'South African',\n",
       "              'South Korean',\n",
       "              'Soviet',\n",
       "              'Spanish',\n",
       "              'Super',\n",
       "              'Swede',\n",
       "              'Swiss',\n",
       "              'Syrian',\n",
       "              'Syrians',\n",
       "              'TOUR',\n",
       "              'Thai',\n",
       "              'Thai <UNK>',\n",
       "              'Tour',\n",
       "              'Turkish',\n",
       "              'Tutsi',\n",
       "              'UEFA Cup',\n",
       "              'US$',\n",
       "              'Uruguayan',\n",
       "              'Vancouver <UNK>',\n",
       "              'WESTERN <UNK>',\n",
       "              'WESTERN DIVISION',\n",
       "              'WORLD CUP',\n",
       "              'WORLD CUP <UNK>',\n",
       "              'WORLD CUP SPEED',\n",
       "              'WORLD CUP SUPER',\n",
       "              'WORLD GRAND PRIX',\n",
       "              'WORLD GRAND PRIX <UNK>',\n",
       "              'Welsh',\n",
       "              'Western',\n",
       "              'Wimbledon',\n",
       "              'World',\n",
       "              'World Cup',\n",
       "              'World Cup <UNK>',\n",
       "              'World Cup Super',\n",
       "              'World Cup standings',\n",
       "              'World Grand Prix',\n",
       "              'World Open',\n",
       "              'World Series',\n",
       "              'World War Two',\n",
       "              'Yugoslav',\n",
       "              'ZIMBABWE OPEN',\n",
       "              'Zairean',\n",
       "              'Zimbabwe Open'},\n",
       "             'ORG': {'<NUM> Munich',\n",
       "              '<UNK>',\n",
       "              '<UNK> <UNK>',\n",
       "              '<UNK> <UNK> <UNK>',\n",
       "              '<UNK> <UNK> AG',\n",
       "              '<UNK> <UNK> Farmers <UNK>',\n",
       "              '<UNK> <UNK> Inc',\n",
       "              '<UNK> <UNK> Ltd and <UNK> Marketing & <UNK> Inc',\n",
       "              '<UNK> <UNK> Party',\n",
       "              '<UNK> <UNK> Society',\n",
       "              '<UNK> <UNK> and Co Inc',\n",
       "              '<UNK> <UNK> of <UNK>',\n",
       "              '<UNK> Bank',\n",
       "              '<UNK> Bay',\n",
       "              '<UNK> Bilbao',\n",
       "              '<UNK> Board',\n",
       "              '<UNK> Board of India',\n",
       "              '<UNK> Bologna',\n",
       "              '<UNK> City',\n",
       "              '<UNK> Club of Houston',\n",
       "              '<UNK> Co Ltd',\n",
       "              '<UNK> Commission',\n",
       "              '<UNK> Company',\n",
       "              '<UNK> Consumer Project',\n",
       "              '<UNK> County Circuit Court',\n",
       "              '<UNK> Data Systems',\n",
       "              '<UNK> Finance <UNK>',\n",
       "              '<UNK> Freedom Party',\n",
       "              '<UNK> Full',\n",
       "              '<UNK> GIANTS',\n",
       "              '<UNK> Group',\n",
       "              '<UNK> Group of Suharto',\n",
       "              '<UNK> Honda',\n",
       "              '<UNK> Institute of Technology',\n",
       "              '<UNK> International',\n",
       "              '<UNK> LOUIS',\n",
       "              '<UNK> Milan',\n",
       "              '<UNK> Minerals Ltd',\n",
       "              '<UNK> Mining Co',\n",
       "              '<UNK> Mining Corp',\n",
       "              '<UNK> Mountain',\n",
       "              '<UNK> NV',\n",
       "              '<UNK> Putra',\n",
       "              '<UNK> ROMANIA <UNK>',\n",
       "              '<UNK> SA',\n",
       "              '<UNK> STATE',\n",
       "              '<UNK> SV',\n",
       "              '<UNK> San',\n",
       "              '<UNK> Society',\n",
       "              '<UNK> Street',\n",
       "              '<UNK> TBN',\n",
       "              '<UNK> Telegraph and <UNK> Corp',\n",
       "              '<UNK> Town',\n",
       "              '<UNK> Trust & Banking Co',\n",
       "              '<UNK> Vale',\n",
       "              '<UNK> Warsaw <UNK>',\n",
       "              '<UNK> Wood',\n",
       "              '<UNK> Workers Group',\n",
       "              '<UNK> and <UNK>',\n",
       "              '<UNK> and Trade ( <UNK>',\n",
       "              'AC Milan',\n",
       "              'AMR Corp.',\n",
       "              'ANC',\n",
       "              'AS Roma',\n",
       "              'ATLANTA',\n",
       "              'AZ Alkmaar',\n",
       "              'Aberdeen',\n",
       "              'Action <UNK>',\n",
       "              'Action <UNK> Cos Inc',\n",
       "              'African National Congress',\n",
       "              'Airdrieonians',\n",
       "              'Ajax',\n",
       "              'Ajax Amsterdam',\n",
       "              'Alba Berlin',\n",
       "              'Albanian Football Association',\n",
       "              'Albion',\n",
       "              'Allan <UNK>',\n",
       "              'Alloa',\n",
       "              'American <UNK> Medical Association',\n",
       "              'American Airlines',\n",
       "              'Arbroath',\n",
       "              'Arizona State',\n",
       "              'Arminia Bielefeld',\n",
       "              'Arsenal',\n",
       "              'Association',\n",
       "              'Association of <UNK> Asian Nations',\n",
       "              'Aston',\n",
       "              'Aston Villa',\n",
       "              'Atalanta',\n",
       "              'Atletico Madrid',\n",
       "              'Atletico Mineiro',\n",
       "              'Auxerre',\n",
       "              'Ayr',\n",
       "              'BALTIMORE',\n",
       "              'BARCELONA',\n",
       "              'BBC',\n",
       "              'BOJ',\n",
       "              'BOSTON',\n",
       "              'Bank of Japan',\n",
       "              'Barcelona',\n",
       "              'Barcelona Barcelona',\n",
       "              'Barcelona Draw',\n",
       "              'Barcelona Real Madrid',\n",
       "              'Barnet',\n",
       "              'Barnsley',\n",
       "              'Barrick',\n",
       "              'Barrick Gold Corp',\n",
       "              'Barrick Gold Corp and <UNK> Minerals Ltd',\n",
       "              'Basketball Association',\n",
       "              'Bastia',\n",
       "              'Bath',\n",
       "              'Bayer Leverkusen',\n",
       "              'Bayern Munich',\n",
       "              'Benfica',\n",
       "              'Berwick',\n",
       "              'Betar Jerusalem',\n",
       "              'Birmingham',\n",
       "              'Blackburn',\n",
       "              'Blackpool',\n",
       "              'Bochum',\n",
       "              'Bologna',\n",
       "              'Bolton',\n",
       "              'Bordeaux',\n",
       "              'Borussia <UNK>',\n",
       "              'Borussia Dortmund',\n",
       "              'Boston',\n",
       "              'Bournemouth',\n",
       "              'Bradford',\n",
       "              'Bradford Vaughan',\n",
       "              'Braga',\n",
       "              'Brechin',\n",
       "              'Brentford',\n",
       "              'Brighton',\n",
       "              'Bristol',\n",
       "              'Bristol City',\n",
       "              'Bristol Rovers',\n",
       "              'British Airways',\n",
       "              'British Airways /',\n",
       "              'British Airways Plc',\n",
       "              'Brussels Newsroom',\n",
       "              'Bucharest Newsroom',\n",
       "              'Buenos Aires Newsroom',\n",
       "              'Buffalo <UNK>',\n",
       "              'Bundesbank',\n",
       "              'Burnley',\n",
       "              'Bury',\n",
       "              'CALGARY',\n",
       "              'CHICAGO',\n",
       "              'CINCINNATI',\n",
       "              'CLEVELAND',\n",
       "              'CLOSE <UNK>',\n",
       "              'COLORADO',\n",
       "              'CSKA Moscow',\n",
       "              'CZECH <UNK>',\n",
       "              'Caen',\n",
       "              'Cagliari',\n",
       "              'Cambridge',\n",
       "              'Cambridge United',\n",
       "              'Canadian Wheat Board',\n",
       "              'Canberra Bureau',\n",
       "              'Cannes',\n",
       "              'Cardiff',\n",
       "              'Carlisle',\n",
       "              'Celtic',\n",
       "              'Celtic Glasgow',\n",
       "              'Chamber',\n",
       "              'Chamber of <UNK>',\n",
       "              'Charlton',\n",
       "              'Chelsea',\n",
       "              'Chester',\n",
       "              'Chesterfield',\n",
       "              'Chicago',\n",
       "              'Chicago Board of Trade',\n",
       "              'Chicago Newsdesk',\n",
       "              'Chilean Congress',\n",
       "              'China',\n",
       "              'China Steel',\n",
       "              'Cincinnati',\n",
       "              'Circuit U.S. Court of Appeals',\n",
       "              'Civil Aviation Administration',\n",
       "              'Civil Aviation Authority',\n",
       "              'Cleveland',\n",
       "              'Clyde',\n",
       "              'Clydebank',\n",
       "              'Colchester',\n",
       "              'Commission',\n",
       "              'Communications and Transportation Ministry',\n",
       "              'Congress',\n",
       "              'Conservative',\n",
       "              'Court',\n",
       "              'Coventry',\n",
       "              'Cowdenbeath',\n",
       "              'Credit Suisse',\n",
       "              'Crewe',\n",
       "              'Crystal Palace',\n",
       "              'Czech <UNK> Democratic Party',\n",
       "              'DALLAS',\n",
       "              'DENVER',\n",
       "              'DETROIT',\n",
       "              'DODGE CITY',\n",
       "              'Dallas <UNK>',\n",
       "              'Darlington',\n",
       "              'De Graafschap Doetinchem',\n",
       "              'Democratic <UNK> Alliance',\n",
       "              'Department of <UNK>',\n",
       "              'Deportivo <UNK>',\n",
       "              'Derby',\n",
       "              'Des <UNK>',\n",
       "              'Doncaster',\n",
       "              'Duma',\n",
       "              'Dumbarton',\n",
       "              'Dundee',\n",
       "              'Dundee United',\n",
       "              'Dunfermline',\n",
       "              'Dynamo Moscow',\n",
       "              'EPA',\n",
       "              'ETA',\n",
       "              'EU',\n",
       "              'EU <UNK>',\n",
       "              'East Fife',\n",
       "              'East Stirling',\n",
       "              'Economic Planning Agency',\n",
       "              'El Mundo',\n",
       "              'Elf',\n",
       "              'Energy Ministry',\n",
       "              'Estudiantes Madrid',\n",
       "              'European Commission',\n",
       "              'European Union',\n",
       "              'Everton',\n",
       "              'Exeter',\n",
       "              'Eyles',\n",
       "              'FBI',\n",
       "              'FC Cologne',\n",
       "              'FC Hansa Rostock',\n",
       "              'FC St. Pauli',\n",
       "              'FDP',\n",
       "              'FIFA',\n",
       "              'FLORIDA',\n",
       "              'FSA <UNK>',\n",
       "              'Falkirk',\n",
       "              'Fed',\n",
       "              'Federal Reserve',\n",
       "              'Feyenoord',\n",
       "              'Fife',\n",
       "              'Finance Ministry',\n",
       "              'Fiorentina',\n",
       "              'First Union Capital Markets Corp.',\n",
       "              'Florida Supreme Court',\n",
       "              'Foreign Affairs Department',\n",
       "              'Foreign Ministry',\n",
       "              'Forfar',\n",
       "              'Fortuna <UNK>',\n",
       "              'Fortuna Sittard',\n",
       "              'Frankfurt Newsroom',\n",
       "              'Freiburg',\n",
       "              'Fulham',\n",
       "              'GIANTS',\n",
       "              'Galatasaray',\n",
       "              'Genoa',\n",
       "              'Gillingham',\n",
       "              'Glentoran',\n",
       "              'Global <UNK> <UNK>',\n",
       "              'Goias',\n",
       "              'Goldman',\n",
       "              'Graafschap Doetinchem',\n",
       "              'Green Bay <UNK>',\n",
       "              'Greenock Morton',\n",
       "              'Gremio',\n",
       "              'Grimsby',\n",
       "              'Groningen',\n",
       "              'Guingamp',\n",
       "              'HAMBURG',\n",
       "              'HOUSTON',\n",
       "              'Hamilton',\n",
       "              'Hansa Rostock',\n",
       "              'Hapoel <UNK>',\n",
       "              \"Hapoel Beit She'an\",\n",
       "              'Hapoel Haifa',\n",
       "              'Hapoel Jerusalem',\n",
       "              'Hapoel Kfar Sava',\n",
       "              'Hapoel Petah Tikva',\n",
       "              'Hapoel Taibe',\n",
       "              'Hapoel Tel Aviv',\n",
       "              'Hartlepool',\n",
       "              'Hearts',\n",
       "              'Heerenveen',\n",
       "              'Hereford',\n",
       "              'Hibernian',\n",
       "              'Hindu',\n",
       "              'Honda',\n",
       "              'Honda <UNK>',\n",
       "              'Honda Motor Co Ltd',\n",
       "              'House of Commons',\n",
       "              'House of Representatives',\n",
       "              'Huddersfield',\n",
       "              'Hull',\n",
       "              'Hungarian Democratic Union',\n",
       "              'Hwang Sun Hong',\n",
       "              'Hyundai Heavy',\n",
       "              'Indiana',\n",
       "              'Indianapolis <UNK>',\n",
       "              'Indra',\n",
       "              'Information',\n",
       "              'Information Technology Association of America',\n",
       "              'Institute of <UNK> Studies ( <UNK>',\n",
       "              'Inter',\n",
       "              'Interfax',\n",
       "              'International <UNK> Federation',\n",
       "              'International Bonds',\n",
       "              'International Confederation of Free Trade <UNK>',\n",
       "              'International Finance Bureau',\n",
       "              'International Labour Organisation',\n",
       "              'International Monetary Fund',\n",
       "              'Internazionale',\n",
       "              'Inverness <UNK>',\n",
       "              'Ipswich',\n",
       "              'Ironi Rishon',\n",
       "              'Itar-Tass',\n",
       "              'JACKSONVILLE',\n",
       "              'Juventus',\n",
       "              'KANSAS CITY',\n",
       "              'Karlsruhe',\n",
       "              'Kilmarnock',\n",
       "              'Kurdistan Workers Party',\n",
       "              'LA <UNK>',\n",
       "              'LEEDS',\n",
       "              'LOS ANGELES',\n",
       "              'La <UNK>',\n",
       "              'Labour',\n",
       "              'Labour and National',\n",
       "              'Lazio',\n",
       "              'Le Havre',\n",
       "              'Lech and Tychy',\n",
       "              'Leeds',\n",
       "              'Leeds United',\n",
       "              'Leicester',\n",
       "              'Lens',\n",
       "              'Leyton Orient',\n",
       "              'Lille',\n",
       "              'Lincoln',\n",
       "              'Liverpool',\n",
       "              'Livingston',\n",
       "              'Ljubljana',\n",
       "              'Lloyd',\n",
       "              'Lloyds Shipping',\n",
       "              'London Irish',\n",
       "              'London Newsroom',\n",
       "              'London Stock Exchange',\n",
       "              'Lord <UNK>',\n",
       "              'Luton',\n",
       "              'Lyon',\n",
       "              'MIAMI',\n",
       "              'MILWAUKEE',\n",
       "              'MINNESOTA',\n",
       "              'MONTREAL',\n",
       "              \"MOODY 'S\",\n",
       "              'MSV Duisburg',\n",
       "              'Maccabi Haifa',\n",
       "              'Maccabi Herzliya',\n",
       "              'Maccabi Petah Tikva',\n",
       "              'Maccabi Tel Aviv',\n",
       "              'Madrid',\n",
       "              'Manchester City',\n",
       "              'Manchester United',\n",
       "              'Mansfield',\n",
       "              'Maracaibo',\n",
       "              'Marseille',\n",
       "              'Marshall',\n",
       "              'Metz',\n",
       "              'Miami <UNK>',\n",
       "              'Middlesbrough',\n",
       "              'Milan',\n",
       "              'Mills',\n",
       "              'Millwall',\n",
       "              'Mines and Energy Ministry for <UNK>',\n",
       "              'Ministry',\n",
       "              \"Ministry 's Umar\",\n",
       "              'Minnesota',\n",
       "              'Monaco',\n",
       "              'Montpellier',\n",
       "              'Montreal',\n",
       "              'Montrose',\n",
       "              'Moody',\n",
       "              'Moscow Newsroom',\n",
       "              'Motherwell',\n",
       "              'Movement',\n",
       "              'Munich Re',\n",
       "              'NAC Breda',\n",
       "              'NATO',\n",
       "              'NBA',\n",
       "              'NEC Nijmegen',\n",
       "              'NEW <UNK>',\n",
       "              'NEW ENGLAND',\n",
       "              'NEW YORK',\n",
       "              'Nancy',\n",
       "              'Nantes',\n",
       "              'Napoli',\n",
       "              'National <UNK> Control Association',\n",
       "              'National Air <UNK> Services Ltd',\n",
       "              'National Alliance',\n",
       "              'National Basketball',\n",
       "              'National Bucharest',\n",
       "              'National Hockey',\n",
       "              'National League for Democracy',\n",
       "              'National University of Singapore',\n",
       "              'National Weather Service',\n",
       "              'National and Labour',\n",
       "              'National and NZ First',\n",
       "              'New Jersey',\n",
       "              'New Mexico <UNK> Association',\n",
       "              'New South Wales Supreme Court',\n",
       "              'New York',\n",
       "              'New York <UNK>',\n",
       "              'New York Commodities Desk',\n",
       "              'New York Power Desk',\n",
       "              'New York Stock Exchange',\n",
       "              'New Zealand First',\n",
       "              'Newcastle',\n",
       "              'Newcastle / <UNK>',\n",
       "              'Nice',\n",
       "              'Northampton',\n",
       "              'Northern',\n",
       "              'Norwich',\n",
       "              'Nottingham Forest',\n",
       "              'Notts County',\n",
       "              'O Globo',\n",
       "              'OAKLAND',\n",
       "              'OIC',\n",
       "              'OTTAWA',\n",
       "              'Oldham',\n",
       "              'Olympiakos',\n",
       "              'Organisation of the Islamic Conference',\n",
       "              'Organisation of the Islamic Conference .',\n",
       "              'Otelul Galati',\n",
       "              'Ottawa',\n",
       "              'Oxford',\n",
       "              'PF',\n",
       "              'PHILADELPHIA',\n",
       "              'PHOENIX',\n",
       "              'PITTSBURGH',\n",
       "              'PKK',\n",
       "              'PLO',\n",
       "              'PSV',\n",
       "              'PSV Eindhoven',\n",
       "              'PSV HIT <UNK>',\n",
       "              'PT <UNK> <UNK>',\n",
       "              'PT <UNK> Duta',\n",
       "              'PT <UNK> Indonesia',\n",
       "              'Palestine Liberation Organisation',\n",
       "              'Palestinian Authority',\n",
       "              'Paris Saint-Germain',\n",
       "              'Paris St Germain',\n",
       "              'Parma',\n",
       "              'Partick',\n",
       "              'Partick , Stirling',\n",
       "              'Partizan',\n",
       "              'Partizan Belgrade',\n",
       "              'Paulo <UNK>',\n",
       "              'Perugia',\n",
       "              'Peterborough',\n",
       "              'Philadelphia',\n",
       "              'Philadelphia <UNK>',\n",
       "              'Philippines',\n",
       "              'Piacenza',\n",
       "              'Pittsburgh',\n",
       "              'Plymouth',\n",
       "              'Port <UNK>',\n",
       "              'Port Vale',\n",
       "              'Porto',\n",
       "              'Portsmouth',\n",
       "              'Portuguesa',\n",
       "              'Posts',\n",
       "              'Prague Newsroom',\n",
       "              'Preston',\n",
       "              'Prudential Securities <UNK>',\n",
       "              \"Queen 's Park\",\n",
       "              'Queen of South',\n",
       "              'Queens Park Rangers',\n",
       "              'RAI',\n",
       "              'RAO <UNK> <UNK>',\n",
       "              'RKC Waalwijk',\n",
       "              'RTRS',\n",
       "              'RUGBY UNION',\n",
       "              'Racing Santander',\n",
       "              'Radical Democrats',\n",
       "              'Raith',\n",
       "              'Rangers',\n",
       "              'Rapid Vienna',\n",
       "              'Reading',\n",
       "              'Real',\n",
       "              'Real <UNK>',\n",
       "              'Real Madrid',\n",
       "              'Real Madrid Barcelona',\n",
       "              'Real Madrid Real Madrid',\n",
       "              'Red Cross',\n",
       "              'Reggiana',\n",
       "              'Rennes',\n",
       "              'Representatives',\n",
       "              'Resistance',\n",
       "              'Reuter',\n",
       "              'Reuters',\n",
       "              'Riga Newsroom',\n",
       "              'Rochdale',\n",
       "              'Roda JC Kerkrade',\n",
       "              'Roma',\n",
       "              'Ronny <UNK>',\n",
       "              'Rosenborg',\n",
       "              'Ross County',\n",
       "              'Rotherham',\n",
       "              'Royal <UNK>',\n",
       "              'Russian Weather Service',\n",
       "              'S&P',\n",
       "              'SAN <UNK>',\n",
       "              'SAN DIEGO',\n",
       "              'SAN FRANCISCO',\n",
       "              'SAN JOSE',\n",
       "              'SC Freiburg',\n",
       "              'SEATTLE',\n",
       "              'SOUTH',\n",
       "              'ST LOUIS',\n",
       "              'SV <NUM> Munich',\n",
       "              'Salomon',\n",
       "              'Salomon Brothers',\n",
       "              'Sampdoria',\n",
       "              'Santa <UNK>',\n",
       "              'Santa <UNK> Pacific Gold Corp',\n",
       "              'Scarborough',\n",
       "              'Schalke',\n",
       "              'Scunthorpe',\n",
       "              'Security Council',\n",
       "              'Senate',\n",
       "              'Senate Banking Committee',\n",
       "              'Sheffield <UNK>',\n",
       "              'Sheffield United',\n",
       "              'Sheffield Wednesday',\n",
       "              'Shrewsbury',\n",
       "              'Singapore',\n",
       "              'Singapore Newsroom',\n",
       "              'Social Democratic Union',\n",
       "              'Social Movement',\n",
       "              'Sokol <UNK>',\n",
       "              'South African <UNK> Ltd',\n",
       "              'South Korea',\n",
       "              'South Lebanon Army',\n",
       "              'Southampton',\n",
       "              'Southend',\n",
       "              'Sparta Rotterdam',\n",
       "              'Sport',\n",
       "              'Sporting',\n",
       "              'Sporting <UNK>',\n",
       "              'St Albans',\n",
       "              'St Johnstone',\n",
       "              'St Louis',\n",
       "              'St Mirren',\n",
       "              'St. Louis',\n",
       "              'St. Louis <UNK> Exchange',\n",
       "              'State',\n",
       "              'State Council',\n",
       "              \"State Council 's Port Office\",\n",
       "              'State Department',\n",
       "              'State Law and Order <UNK> Council',\n",
       "              'State Street Bank and Trust Company',\n",
       "              'Statistics',\n",
       "              'Statistics Canada',\n",
       "              'Steaua Bucharest',\n",
       "              'Stenhousemuir',\n",
       "              'Stirling',\n",
       "              'Stockport',\n",
       "              'Stoke',\n",
       "              'Stranraer',\n",
       "              'Strasbourg',\n",
       "              'Sumitomo',\n",
       "              'Sumitomo Bank',\n",
       "              'Sun',\n",
       "              'Sunderland',\n",
       "              'Super <UNK>',\n",
       "              'Swansea',\n",
       "              'Swindon',\n",
       "              'Sydney Cricket <UNK>',\n",
       "              'Sydney Newsroom',\n",
       "              'TORONTO',\n",
       "              'TWA',\n",
       "              'Tallinna <UNK>',\n",
       "              'Tass',\n",
       "              'Tiger <UNK>',\n",
       "              'Toronto',\n",
       "              'Torquay',\n",
       "              'Tottenham',\n",
       "              'Tranmere',\n",
       "              'Treasuries',\n",
       "              'Treasury',\n",
       "              'Twente Enschede',\n",
       "              'U.N.',\n",
       "              'U.N. General Assembly',\n",
       "              'U.S.',\n",
       "              'U.S. Municipal Desk',\n",
       "              'U.S. Supreme Court',\n",
       "              'U.S.-based <UNK> Communications Corporation',\n",
       "              'UEFA',\n",
       "              'UEFA <UNK>',\n",
       "              'UK Department of Transport',\n",
       "              'UNITED NATIONS',\n",
       "              'USDA',\n",
       "              'Udinese',\n",
       "              'United Arab Emirates',\n",
       "              'United City Bank',\n",
       "              'United Nations',\n",
       "              'United Province',\n",
       "              'University',\n",
       "              'University of <UNK>',\n",
       "              'Utrecht',\n",
       "              'VANCOUVER',\n",
       "              'Valencia',\n",
       "              'Vancouver',\n",
       "              'Verona',\n",
       "              'VfB Stuttgart',\n",
       "              'VfL Bochum',\n",
       "              'Vicenza',\n",
       "              'Vitesse Arnhem',\n",
       "              'Volendam',\n",
       "              'WASHINGTON',\n",
       "              'WEST',\n",
       "              'Wall Street Desk',\n",
       "              'Walsall',\n",
       "              'Warsaw Newsroom',\n",
       "              'Watford',\n",
       "              'Werder Bremen',\n",
       "              'West Bromwich',\n",
       "              'West Ham',\n",
       "              'West Hartlepool',\n",
       "              'Wheat',\n",
       "              'Wigan',\n",
       "              'Willem II Tilburg',\n",
       "              'Wimbledon',\n",
       "              'Wolverhampton',\n",
       "              'World Trade Organisation ( <UNK>',\n",
       "              'Wrexham',\n",
       "              'Wycombe',\n",
       "              'Xinhua',\n",
       "              'York',\n",
       "              'Yorkshire',\n",
       "              'Zafririm Holon'}})"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_decode_ner_dict_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersection_stats(truly_decode_ner_dict_set, pred_decode_ner_dict_set):\n",
    "    print(\"skip {} in pred not contain in truly\".format(\"\".join(set(pred_decode_ner_dict_set.keys()).difference(set(truly_decode_ner_dict_set.keys())))))\n",
    "    from collections import defaultdict\n",
    "    intersection_set_dict = defaultdict(set)\n",
    "    intersection_ratio_to_truly_dict = defaultdict(float)\n",
    "    intersection_ratio_to_pred_dict = defaultdict(float)\n",
    "    for k, val_set in truly_decode_ner_dict_set.items():\n",
    "        intersection_set_dict[k] = val_set.intersection(pred_decode_ner_dict_set.get(k, set([])))\n",
    "        intersection_ratio_to_truly_dict[k] = float(len(intersection_set_dict[k])) / len(val_set)\n",
    "        intersection_ratio_to_pred_dict[k] = float(len(intersection_set_dict[k])) / len(pred_decode_ner_dict_set.get(k, set([])))\n",
    "    return intersection_ratio_to_truly_dict ,intersection_ratio_to_pred_dict ,intersection_set_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skip  in pred not contain in truly\n"
     ]
    }
   ],
   "source": [
    "ratio_to_truly_dict, ratio_to_pred_dict, intersection_dict = intersection_stats(truly_decode_ner_dict_set, pred_decode_ner_dict_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(float,\n",
       "            {'LOC': 0.8493150684931506,\n",
       "             'PER': 0.9385665529010239,\n",
       "             'MISC': 0.7676767676767676,\n",
       "             'ORG': 0.821656050955414})"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratio_to_truly_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(float,\n",
       "            {'LOC': 0.8201058201058201,\n",
       "             'PER': 0.9166666666666666,\n",
       "             'MISC': 0.6785714285714286,\n",
       "             'ORG': 0.8037383177570093})"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratio_to_pred_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
